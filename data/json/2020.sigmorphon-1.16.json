{
  "id": "2020.sigmorphon-1.16",
  "title": "One Model to Pronounce Them All: Multilingual Grapheme-to-Phoneme Conversion With a Transformer Ensemble",
  "authors": [
    "Vesik, Kaili  and\nAbdul-Mageed, Muhammad  and\nSilfverberg, Miikka"
  ],
  "year": "2020",
  "venue": "Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",
  "abstract": "The task of grapheme-to-phoneme (G2P) conversion is important for both speech recognition and synthesis. Similar to other speech and language processing tasks, in a scenario where only small-sized training data are available, learning G2P models is challenging. We describe a simple approach of exploiting model ensembles, based on multilingual Transformers and self-training, to develop a highly effective G2P solution for 15 languages. Our models are developed as part of our participation in the SIGMORPHON 2020 Shared Task 1 focused at G2P. Our best models achieve 14.99 word error rate (WER) and 3.30 phoneme error rate (PER), a sizeable improvement over the shared task competitive baselines.",
  "keywords": [
    "model ensembles",
    "transformer",
    "ensembles",
    "transformers",
    "processing",
    "language",
    "model",
    "rate",
    "wer",
    "self",
    "word",
    "we",
    "multilingual transformers",
    "a transformer",
    "training"
  ],
  "url": "https://aclanthology.org/2020.sigmorphon-1.16/",
  "provenance": {
    "collected_at": "2025-06-05 07:58:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}