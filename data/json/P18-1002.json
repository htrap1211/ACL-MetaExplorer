{
  "id": "P18-1002",
  "title": "A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors",
  "authors": [
    "Khodak, Mikhail  and\nSaunshi, Nikunj  and\nLiang, Yingyu  and\nMa, Tengyu  and\nStewart, Brandon  and\nArora, Sanjeev"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Motivations like domain adaptation, transfer learning, and feature learning have fueled interest in inducing embeddings for rare or unseen words, n-grams, synsets, and other textual features. This paper introduces a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings. Our method relies mainly on a linear transformation that is efficiently learnable using pretrained word vectors and linear regression. This transform is applicable on the fly in the future when a new text feature or rare word is encountered, even if only a single usage example is available. We introduce a new dataset showing how the a la carte method requires fewer examples of words in context to learn high-quality embeddings and we obtain state-of-the-art results on a nonce task and some unsupervised document classification tasks.",
  "keywords": [
    "glove",
    "glove-like embeddings",
    "semantic",
    "we",
    "classification",
    "pretrained word vectors",
    "word",
    "learning",
    "transfer",
    "high-quality embeddings",
    "text",
    "semantic feature vectors motivations",
    "embeddings",
    "general",
    "domain adaptation transfer learning"
  ],
  "url": "https://aclanthology.org/P18-1002/",
  "provenance": {
    "collected_at": "2025-06-05 00:08:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}