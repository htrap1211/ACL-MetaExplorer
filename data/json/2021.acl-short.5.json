{
  "id": "2021.acl-short.5",
  "title": "Difficulty-Aware Machine Translation Evaluation",
  "authors": [
    "Zhan, Runzhe  and\nLiu, Xuebo  and\nWong, Derek F.  and\nChao, Lidia S."
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "The high-quality translation results produced by machine translation (MT) systems still pose a huge challenge for automatic evaluation. Current MT evaluation pays the same attention to each sentence component, while the questions of real-world examinations (e.g., university examinations) have different difficulties and weightings. In this paper, we propose a novel difficulty-aware MT evaluation metric, expanding the evaluation dimension by taking translation difficulty into consideration. A translation that fails to be predicted by most MT systems will be treated as a difficult one and assigned a large weight in the final score function, and conversely. Experimental results on the WMT19 English-German Metrics shared tasks show that our proposed method outperforms commonly used MT metrics in terms of human correlation. In particular, our proposed method performs well even when all the MT systems are very competitive, which is when most existing metrics fail to distinguish between them. The source code is freely available athttps://github.com/NLP2CT/Difficulty-Aware-MT-Evaluation.",
  "keywords": [
    "code",
    "different difficulties",
    "the same attention",
    "the high-quality translation results",
    "most existing metrics",
    "we",
    "difficulty-aware machine translation evaluation",
    "nlp2ct",
    "current",
    "translation",
    "mt metrics",
    "machine translation mt systems",
    "difficulties",
    "metric",
    "metrics"
  ],
  "url": "https://aclanthology.org/2021.acl-short.5/",
  "provenance": {
    "collected_at": "2025-06-05 08:07:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}