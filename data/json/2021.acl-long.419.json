{
  "id": "2021.acl-long.419",
  "title": "On Sample Based Explanation Methods for {NLP}: Faithfulness, Efficiency and Semantic Evaluation",
  "authors": [
    "Zhang, Wei  and\nHuang, Ziming  and\nZhu, Yada  and\nYe, Guangnan  and\nCui, Xiaodong  and\nZhang, Fan"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "In the recent advances of natural language processing, the scale of the state-of-the-art models and datasets is usually extensive, which challenges the application of sample-based explanation methods in many aspects, such as explanation interpretability, efficiency, and faithfulness. In this work, for the first time, we can improve the interpretability of explanations by allowing arbitrary text sequences as the explanation unit. On top of this, we implement a hessian-free method with a model faithfulness guarantee. Finally, to compare our method with the others, we propose a semantic-based evaluation metric that can better align with humans’ judgment of explanations than the widely adopted diagnostic or re-training measures. The empirical results on multiple real data sets demonstrate the proposed method’s superior performance to popular explanation techniques such as Influence Function or TracIn on semantic evaluation.",
  "keywords": [
    "top",
    "nlp faithfulness efficiency",
    "efficiency",
    "semantic",
    "we",
    "training",
    "natural",
    "a semantic-based evaluation metric",
    "natural language",
    "explanation interpretability efficiency",
    "metric",
    "text",
    "semantic evaluation",
    "function",
    "work"
  ],
  "url": "https://aclanthology.org/2021.acl-long.419/",
  "provenance": {
    "collected_at": "2025-06-05 08:05:03",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}