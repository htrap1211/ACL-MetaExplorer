{
  "id": "2021.semeval-1.2",
  "title": "OCHADAI}-{KYOTO} at {S}em{E}val-2021 Task 1: Enhancing Model Generalization and Robustness for Lexical Complexity Prediction",
  "authors": [
    "Taya, Yuki  and\nKanashiro Pereira, Lis  and\nCheng, Fei  and\nKobayashi, Ichiro"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "We propose an ensemble model for predicting the lexical complexity of words and multiword expressions (MWEs). The model receives as input a sentence with a target word or MWE and outputs its complexity score. Given that a key challenge with this task is the limited size of annotated data, our model relies on pretrained contextual representations from different state-of-the-art transformer-based language models (i.e., BERT and RoBERTa), and on a variety of training methods for further enhancing model generalization and robustness: multi-step fine-tuning and multi-task learning, and adversarial training. Additionally, we propose to enrich contextual representations by adding hand-crafted features during training. Our model achieved competitive results and ranked among the top-10 systems in both sub-tasks.",
  "keywords": [
    "variety",
    "roberta",
    "model generalization",
    "we",
    "training",
    "ensemble",
    "word",
    "learning",
    "a variety",
    "tuning",
    "i",
    "bert",
    "-",
    "generalization",
    "an ensemble model"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.2/",
  "provenance": {
    "collected_at": "2025-06-05 08:19:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}