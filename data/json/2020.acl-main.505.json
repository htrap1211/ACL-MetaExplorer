{
  "id": "2020.acl-main.505",
  "title": "Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering",
  "authors": [
    "Li, Changmao  and\nChoi, Jinho D."
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token- and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multi-task learning between the utterance prediction and the token span prediction is applied to fine-tune for span-based question answering (QA). Our approach is evaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively.",
  "keywords": [
    "embeddings",
    "transformer",
    "hierarchical",
    "transformers",
    "the friendsqa dataset",
    "roberta",
    "language",
    "hierarchical representations",
    "bert",
    "qa",
    "three language modeling tasks",
    "token",
    "modeling",
    "question",
    "multiparty dialogue"
  ],
  "url": "https://aclanthology.org/2020.acl-main.505/",
  "provenance": {
    "collected_at": "2025-06-05 07:48:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}