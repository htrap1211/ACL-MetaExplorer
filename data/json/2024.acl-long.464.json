{
  "id": "2024.acl-long.464",
  "title": "Bypassing {LLM} Watermarks with Color-Aware Substitutions",
  "authors": [
    "Wu, Qilong  and\nChandrasekaran, Varun"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Watermarking approaches are proposed to identify if text being circulated is human- or large language model- (LLM) generated. The state-of-the-art watermarking strategy of Kirchenbauer et al. (2023a) biases the LLM to generate specific (“green”) tokens. However, determining the robustness of this watermarking method under finite (low) edit budgets is an open problem. Additionally, existing attack methods failto evade detection for longer text segments. We overcome these limitations, and propose Self Color Testing-based Substitution (SCTS), thefirst “color-aware” attack. SCTS obtains color information by strategically prompting the watermarked LLM and comparing output tokensfrequencies. It uses this information to determine token colors, and substitutes green tokens with non-green ones. In our experiments, SCTS successfully evades watermark detection using fewer number of edits than related work. Additionally, we show both theoretically and empirically that SCTS can remove the watermark for arbitrarily long watermarked text.",
  "keywords": [
    "output tokensfrequencies",
    "we",
    "llm",
    "llm watermarks",
    "it",
    "self",
    "token",
    "information",
    "text",
    "the llm",
    "work",
    "language",
    "tokensfrequencies",
    "the watermarked llm",
    "green"
  ],
  "url": "https://aclanthology.org/2024.acl-long.464/",
  "provenance": {
    "collected_at": "2025-06-05 10:40:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}