{
  "id": "2021.acl-short.116",
  "title": "Entity Enhancement for Implicit Discourse Relation Classification in the Biomedical Domain",
  "authors": [
    "Shi, Wei  and\nDemberg, Vera"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Implicit discourse relation classification is a challenging task, in particular when the text domain is different from the standard Penn Discourse Treebank (PDTB; Prasad et al., 2008) training corpus domain (Wall Street Journal in 1990s). We here tackle the task of implicit discourse relation classification on the biomedical domain, for which the Biomedical Discourse Relation Bank (BioDRB; Prasad et al., 2011) is available. We show that entity information can be used to improve discourse relational argument representation. In a first step, we show that explicitly marked instances that are content-wise similar to the target relations can be used to achieve good performance in the cross-domain setting using a simple unsupervised voting pipeline. As a further step, we show that with the linked entity information from the first step, a transformer which is augmented with entity-related information (KBERT; Liu et al., 2020) sets the new state of the art performance on the dataset, outperforming the large pre-trained BioBERT (Lee et al., 2020) model by 2% points.",
  "keywords": [
    "al",
    "we",
    "biobert",
    "a transformer",
    "training",
    "classification",
    "cross",
    "entity-related information kbert liu",
    "information",
    "kbert",
    "et",
    "text",
    "transformer",
    "model",
    "implicit discourse relation classification"
  ],
  "url": "https://aclanthology.org/2021.acl-short.116/",
  "provenance": {
    "collected_at": "2025-06-05 08:08:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}