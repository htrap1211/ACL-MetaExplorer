{
  "id": "2022.acl-long.531",
  "title": "How Do {S}eq2{S}eq Models Perform on End-to-End Data-to-Text Generation?",
  "authors": [
    "Yin, Xunjian  and\nWan, Xiaojun"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "With the rapid development of deep learning, Seq2Seq paradigm has become prevalent for end-to-end data-to-text generation, and the BLEU scores have been increasing in recent years. However, it is widely recognized that there is still a gap between the quality of the texts generated by models and the texts written by human. In order to better understand the ability of Seq2Seq models, evaluate their performance and analyze the results, we choose to use Multidimensional Quality Metric(MQM) to evaluate several representative Seq2Seq models on end-to-end data-to-text generation. We annotate the outputs of five models on four datasets with eight error types and find that 1) copy mechanism is helpful for the improvement in Omission and Inaccuracy Extrinsic errors but it increases other types of errors such as Addition; 2) pre-training techniques are highly effective, and pre-training strategy and model size are very significant; 3) the structure of the dataset also influences the modelâ€™s performance greatly; 4) some specific types of errors are generally challenging for seq2seq models.",
  "keywords": [
    "deep",
    "end",
    "bleu",
    "the bleu scores",
    "we",
    "training",
    "several representative seq2seq models",
    "it",
    "deep learning seq2seq paradigm",
    "learning",
    "seq2seq",
    "pre-training strategy",
    "metric",
    "text",
    "inaccuracy"
  ],
  "url": "https://aclanthology.org/2022.acl-long.531/",
  "provenance": {
    "collected_at": "2025-06-05 08:31:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}