{
  "id": "2021.acl-short.83",
  "title": "QA}-Driven Zero-shot Slot Filling with Weak Supervision Pretraining",
  "authors": [
    "Du, Xinya  and\nHe, Luheng  and\nLi, Qi  and\nYu, Dian  and\nPasupat, Panupong  and\nZhang, Yuan"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Slot-filling is an essential component for building task-oriented dialog systems. In this work, we focus on the zero-shot slot-filling problem, where the model needs to predict slots and their values, given utterances from new domains without training on the target domain. Prior methods directly encode slot descriptions to generalize to unseen slot types. However, raw slot descriptions are often ambiguous and do not encode enough semantic information, limiting the modelsâ€™ zero-shot capability. To address this problem, we introduce QA-driven slot filling (QASF), which extracts slot-filler spans from utterances with a span-based QA model. We use a linguistically motivated questioning strategy to turn descriptions into questions, allowing the model to generalize to unseen slot types. Moreover, our QASF model can benefit from weak supervision signals from QA pairs synthetically generated from unlabeled conversations. Our full system substantially outperforms baselines by over 5% on the SNIPS benchmark.",
  "keywords": [
    "zero-shot capability",
    "encode",
    "conversations",
    "semantic",
    "we",
    "task-oriented dialog systems",
    "shot",
    "training",
    "unlabeled conversations",
    "qa pairs",
    "information",
    "our qasf model",
    "the zero-shot slot-filling problem",
    "qasf",
    "enough semantic information"
  ],
  "url": "https://aclanthology.org/2021.acl-short.83/",
  "provenance": {
    "collected_at": "2025-06-05 08:08:13",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}