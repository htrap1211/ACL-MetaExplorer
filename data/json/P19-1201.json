{
  "id": "P19-1201",
  "title": "Jointly Learning Semantic Parser and Natural Language Generator via Dual Information Maximization",
  "authors": [
    "Ye, Hai  and\nLi, Wenjie  and\nWang, Lu"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Semantic parsing aims to transform natural language (NL) utterances into formal meaning representations (MRs), whereas an NL generator achieves the reverse: producing an NL description for some given MRs. Despite this intrinsic connection, the two tasks are often studied separately in prior work. In this paper, we model the duality of these two tasks via a joint learning framework, and demonstrate its effectiveness of boosting the performance on both tasks. Concretely, we propose a novel method of dual information maximization (DIM) to regularize the learning process, where DIM empirically maximizes the variational lower bounds of expected joint distributions of NL and MRs. We further extend DIM to a semi-supervision setup (SemiDIM), which leverages unlabeled data of both tasks. Experiments on three datasets of dialogue management and code generation (and summarization) show that performance on both semantic parsing and NL generation can be consistently improved by DIM, in both supervised and semi-supervised setups.",
  "keywords": [
    "code",
    "parsing",
    "nl generation",
    "an nl generator",
    "semantic",
    "summarization",
    "we",
    "dialogue",
    "natural",
    "nl",
    "information",
    "learning",
    "semantic parser",
    "dialogue management",
    "both semantic parsing"
  ],
  "url": "https://aclanthology.org/P19-1201/",
  "provenance": {
    "collected_at": "2025-06-05 00:34:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}