{
  "id": "2023.findings-acl.164",
  "title": "Focusing, Bridging and Prompting for Few-shot Nested Named Entity Recognition",
  "authors": [
    "Xu, Yuanyuan  and\nYang, Zeng  and\nZhang, Linhai  and\nZhou, Deyu  and\nWu, Tiandeng  and\nZhou, Rong"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Few-shot named entity recognition (NER), identifying named entities with a small number of labeled data, has attracted much attention. Frequently, entities are nested within each other. However, most of the existing work on few-shot NER addresses flat entities instead of nested entities. To tackle nested NER in a few-shot setting, it is crucial to utilize the limited labeled data to mine unique features of nested entities, such as the relationship between inner and outer entities and contextual position information. Therefore, in this work, we propose a novel method based on focusing, bridging and prompting for few-shot nested NER without using source domain data. Both focusing and bridging components provide accurate candidate spans for the prompting component. The prompting component leverages the unique features of nested entities to classify spans based on soft prompts and contrastive learning. Experimental results show that the proposed approach achieves state-of-the-art performance consistently on the four benchmark datasets (ACE2004, ACE2005, GENIA and KBP2017) and outperforms several competing baseline models on F1-score by 9.33% on ACE2004, 6.17% on ACE2005, 9.40% on GENIA and 5.12% on KBP2017 on the 5-shot setting.",
  "keywords": [
    "much attention",
    "we",
    "inner and outer entities",
    "nested ner",
    "shot",
    "few-shot",
    "it",
    "f1-score",
    "information",
    "inner",
    "the prompting component leverages",
    "learning",
    "nested entities",
    "ner",
    "few-shot nested ner"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.164/",
  "provenance": {
    "collected_at": "2025-06-05 09:55:31",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}