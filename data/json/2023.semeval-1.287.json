{
  "id": "2023.semeval-1.287",
  "title": "UIRISC} at {S}em{E}val-2023 Task 10: Explainable Detection of Online Sexism by Ensembling Fine-tuning Language Models",
  "authors": [
    "Zhong, Tianyun  and\nSong, Runhui  and\nLiu, Xunyuan  and\nWang, Juelin  and\nWang, Boya  and\nLi, Binyang"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "Under the umbrella of anonymous social networks, many women have suffered from abuse, discrimination, and other sexist expressions online. However, exsiting methods based on keyword filtering and matching performed poorly on online sexism detection, which lacked the capability to identify implicit stereotypes and discrimination. Therefore, this paper proposes a System of Ensembling Fine-tuning Models (SEFM) at SemEval-2023 Task 10: Explainable Detection of Online Sexism. We firstly use four task-adaptive pre-trained language models to flag all texts. Secondly, we alleviate the data imbalance from two perspectives: over-sampling the labelled data and adjusting the loss function. Thirdly, we add indicators and feedback modules to enhance the overall performance. Our system attained macro F1 scores of 0.8538, 0.6619, and 0.4641 for Subtask A, B, and C, respectively. Our system exhibited strong performance across multiple tasks, with particularly noteworthy performance in Subtask B. Comparison experiments and ablation studies demonstrate the effectiveness of our system.",
  "keywords": [
    "fine-tuning language models",
    "feedback",
    "ablation studies",
    "we",
    "c",
    "loss",
    "macro f1 scores",
    "tuning",
    "the loss function",
    "fine",
    "function",
    "language",
    "studies",
    "ensembling fine-tuning models",
    "pre"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.287/",
  "provenance": {
    "collected_at": "2025-06-05 10:30:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}