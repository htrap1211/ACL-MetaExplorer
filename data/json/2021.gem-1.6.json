{
  "id": "2021.gem-1.6",
  "title": "A Review of Human Evaluation for Style Transfer",
  "authors": [
    "Briakou, Eleftheria  and\nAgrawal, Sweta  and\nZhang, Ke  and\nTetreault, Joel  and\nCarpuat, Marine"
  ],
  "year": "2021",
  "venue": "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
  "abstract": "This paper reviews and summarizes human evaluation practices described in 97 style transfer papers with respect to three main evaluation aspects: style transfer, meaning preservation, and fluency. In principle, evaluations by human raters should be the most reliable. However, in style transfer papers, we find that protocols for human evaluations are often underspecified and not standardized, which hampers the reproducibility of research in this field and progress toward better human and automatic evaluation methods.",
  "keywords": [
    "principle evaluations",
    "human evaluation",
    "this paper reviews",
    "underspecified",
    "human",
    "evaluations",
    "a review",
    "field",
    "this field",
    "human evaluations",
    "we",
    "human evaluation practices",
    "transfer",
    "review",
    "evaluation"
  ],
  "url": "https://aclanthology.org/2021.gem-1.6/",
  "provenance": {
    "collected_at": "2025-06-05 08:17:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}