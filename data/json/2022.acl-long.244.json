{
  "id": "2022.acl-long.244",
  "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
  "authors": [
    "Mishra, Swaroop  and\nKhashabi, Daniel  and\nBaral, Chitta  and\nHajishirzi, Hannaneh"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19% better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.",
  "keywords": [
    "encode",
    "question",
    "we",
    "generative pre-trained language models",
    "training",
    "classification",
    "cross",
    "classification tasks",
    "natural",
    "it",
    "a unified schema",
    "unified",
    "learning",
    "generative",
    "generalization"
  ],
  "url": "https://aclanthology.org/2022.acl-long.244/",
  "provenance": {
    "collected_at": "2025-06-05 08:27:35",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}