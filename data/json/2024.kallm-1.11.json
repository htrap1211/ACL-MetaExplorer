{
  "id": "2024.kallm-1.11",
  "title": "Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs",
  "authors": [
    "Yuan, Moy  and\nVlachos, Andreas"
  ],
  "year": "2024",
  "venue": "Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)",
  "abstract": "Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets.",
  "keywords": [
    "previous zero-shot approaches",
    "knowledge",
    "language",
    "natural",
    "a novel zero-shot method",
    "it",
    "semantic triples",
    "large language models",
    "knowledge graphs",
    "semantic",
    "we",
    "shot",
    "training",
    "external knowledge graphs",
    "that"
  ],
  "url": "https://aclanthology.org/2024.kallm-1.11/",
  "provenance": {
    "collected_at": "2025-06-05 11:07:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}