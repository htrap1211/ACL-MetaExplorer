{
  "id": "2022.ltedi-1.11",
  "title": "Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in {E}nglish, {S}panish, and {A}rabic",
  "authors": [
    "C{\\^a}mara, Ant{\\'o}nio  and\nTaneja, Nina  and\nAzad, Tamjeed  and\nAllaway, Emily  and\nZemel, Richard"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",
  "abstract": "As natural language processing systems become more widespread, it is necessary to address fairness issues in their implementation and deployment to ensure that their negative impacts on society are understood and minimized. However, there is limited work that studies fairness using a multilingual and intersectional framework or on downstream tasks. In this paper, we introduce four multilingual Equity Evaluation Corpora, supplementary test sets designed to measure social biases, and a novel statistical framework for studying unisectional and intersectional social biases in natural language processing. We use these tools to measure gender, racial, ethnic, and intersectional social biases across five models trained on emotion regression tasks in English, Spanish, and Arabic. We find that many systems demonstrate statistically significant unisectional and intersectional social biases. We make our code and datasets available for download.",
  "keywords": [
    "code",
    "natural language processing systems",
    "social biases",
    "we",
    "natural",
    "it",
    "intersectional biases",
    "natural language processing",
    "analysis",
    "processing",
    "sentiment analysis systems",
    "biases",
    "society",
    "sentiment",
    "work"
  ],
  "url": "https://aclanthology.org/2022.ltedi-1.11/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}