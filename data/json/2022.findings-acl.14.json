{
  "id": "2022.findings-acl.14",
  "title": "Investigating Data Variance in Evaluations of Automatic Machine Translation Metrics",
  "authors": [
    "Xiang, Jiannan  and\nLi, Huayang  and\nLiu, Yahui  and\nLiu, Lemao  and\nHuang, Guoping  and\nLian, Defu  and\nShi, Shuming"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Current practices in metric evaluation focus on one single dataset, e.g., Newstest dataset in each yearâ€™s WMT Metrics Shared Task. However, in this paper, we qualitatively and quantitatively show that the performances of metrics are sensitive to data. The ranking of metrics varies when the evaluation is conducted on different datasets. Then this paper further investigates two potential hypotheses, i.e., insignificant data points and the deviation of i.i.d assumption, which may take responsibility for the issue of data variance. In conclusion, our findings suggest that when evaluating automatic translation metrics, researchers should take data variance into account and be cautious to report the results on unreliable datasets, because it may leads to inconsistent results with most of the other datasets.",
  "keywords": [
    "i",
    "automatic translation metrics researchers",
    "translation",
    "machine",
    "metric",
    "evaluations",
    "it",
    "data variance",
    "metrics",
    "we",
    "evaluation",
    "current",
    "variance",
    "metric evaluation focus",
    "the evaluation"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.14/",
  "provenance": {
    "collected_at": "2025-06-05 08:35:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}