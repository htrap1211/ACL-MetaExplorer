{
  "id": "2020.acl-main.93",
  "title": "Improving Image Captioning Evaluation by Considering Inter References Variance",
  "authors": [
    "Yi, Yanzhi  and\nDeng, Hangyu  and\nHu, Jinglu"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Evaluating image captions is very challenging partially due to the fact that there are multiple correct captions for every single image. Most of the existing one-to-one metrics operate by penalizing mismatches between reference and generative caption without considering the intrinsic variance between ground truth captions. It usually leads to over-penalization and thus a bad correlation to human judgment. Recently, the latest one-to-one metric BERTScore can achieve high human correlation in system-level tasks while some issues can be fixed for better performance. In this paper, we propose a novel metric based on BERTScore that could handle such a challenge and extend BERTScore with a few new features appropriately for image captioning evaluation. The experimental results show that our metric achieves state-of-the-art human judgment correlation.",
  "keywords": [
    "generative",
    "reference",
    "bertscore",
    "image captioning evaluation",
    "metric",
    "it",
    "human",
    "the existing one-to-one metrics",
    "generative caption",
    "the intrinsic variance",
    "metrics",
    "we",
    "evaluation",
    "variance",
    "that"
  ],
  "url": "https://aclanthology.org/2020.acl-main.93/",
  "provenance": {
    "collected_at": "2025-06-05 07:43:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}