{
  "id": "2023.semeval-1.125",
  "title": "IRIT}{\\_}{IRIS}{\\_}{A} at {S}em{E}val-2023 Task 6: Legal Rhetorical Role Labeling Supported by Dynamic-Filled Contextualized Sentence Chunks",
  "authors": [
    "Lima, Alexandre Gomes de  and\nMoreno, Jose G.  and\nH. da S. Aranha, Eduardo"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "This work presents and evaluates an approach to efficiently leverage the context exploitation ability of pre-trained Transformer models as a way of boosting the performance of models tackling the Legal Rhetorical Role Labeling task. The core idea is to feed the model with sentence chunks that are assembled in a way that avoids the insertion of padding tokens and the truncation of sentences and, hence, obtain better sentence embeddings. The achieved results show that our proposal is efficient, despite its simplicity, since models based on it overcome strong baselines by 3.76% in the worst case and by 8.71% in the best case.",
  "keywords": [
    "work",
    "embeddings",
    "transformer",
    "em",
    "model",
    "it",
    "efficient",
    "the achieved results",
    "better sentence embeddings",
    "pre-trained transformer models",
    "pre",
    "a",
    "core",
    "that",
    "its simplicity"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.125/",
  "provenance": {
    "collected_at": "2025-06-05 10:28:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}