{
  "id": "2024.sighan-1.3",
  "title": "Few-shot Question Generation for Reading Comprehension",
  "authors": [
    "Poon, Yin  and\nLee, John Sie Yuen  and\nLam, Yu Yan  and\nSuen, Wing Lam  and\nOng, Elsie Li Chen  and\nChu, Samuel Kai Wah"
  ],
  "year": "2024",
  "venue": "Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)",
  "abstract": "According to the internationally recognized PIRLS (Progress in International Reading Literacy Study) assessment standards, reading comprehension questions should require not only information retrieval, but also higher-order processes such as inferencing, interpreting and evaluation. However, these kinds of questions are often not available in large quantities for training question generation models. This paper investigates whether pre-trained Large Language Models (LLMs) can produce higher-order questions. Human assessment on a Chinese dataset shows that few-shot LLM prompting generates more usable and higher-order questions than two competitive neural baselines.",
  "keywords": [
    "generation",
    "language",
    "neural",
    "human",
    "retrieval",
    "large quantities",
    "question",
    "information",
    "few-shot question generation",
    "evaluation",
    "pre",
    "not only information retrieval",
    "quantities",
    "llm",
    "shot"
  ],
  "url": "https://aclanthology.org/2024.sighan-1.3/",
  "provenance": {
    "collected_at": "2025-06-05 11:10:03",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}