{
  "id": "2023.findings-acl.242",
  "title": "A Simple Yet Strong Domain-Agnostic De-bias Method for Zero-Shot Sentiment Classification",
  "authors": [
    "Zhao, Yang  and\nNasukawa, Tetsuya  and\nMuraoka, Masayasu  and\nBhattacharjee, Bishwaranjan"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Zero-shot prompt-based learning has made much progress in sentiment analysis, and considerable effort has been dedicated to designing high-performing prompt templates. However, two problems exist; First, large language models are often biased to their pre-training data, leading to poor performance in prompt templates that models have rarely seen. Second, in order to adapt to different domains, re-designing prompt templates is usually required, which is time-consuming and inefficient. To remedy both shortcomings, we propose a simple yet strong data construction method to de-bias a given prompt template, yielding a large performance improvement in sentiment analysis tasks across different domains, pre-trained language models, and prompt templates. Also, we demonstrate the advantage of using domain-agnostic generic responses over the in-domain ground-truth data.",
  "keywords": [
    "-designing prompt templates",
    "a given prompt template",
    "bias",
    "de",
    "prompt",
    "language",
    "prompt templates",
    "sentiment analysis",
    "inefficient",
    "generic",
    "domain-agnostic generic responses",
    "high-performing prompt templates",
    "we",
    "learning",
    "pre"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.242/",
  "provenance": {
    "collected_at": "2025-06-05 09:56:36",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}