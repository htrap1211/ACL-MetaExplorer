{
  "id": "2024.acl-long.779",
  "title": "P}sycho{GAT}: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with {LLM} Agents",
  "authors": [
    "Yang, Qisen  and\nWang, Zekun  and\nChen, Honghui  and\nWang, Shenzhi  and\nPu, Yifan  and\nGao, Xin  and\nHuang, Wenhao  and\nSong, Shiji  and\nHuang, Gao"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment. The main insight is that powerful LLMs can function both as adept psychologists and innovative game designers. By incorporating LLM agents into designated roles and carefully managing their interactions, PsychoGAT can transform any standardized scales into personalized and engaging interactive fiction games. To validate the proposed method, we conduct psychometric evaluations to assess its effectiveness and employ human evaluators to examine the generated content across various psychological constructs, including depression, cognitive distortions, and personality traits. Results demonstrate that PsychoGAT serves as an effective assessment tool, achieving statistically significant excellence in psychometric metrics such as reliability, convergent validity, and discriminant validity. Moreover, human evaluations confirm PsychoGATâ€™s enhancements in content coherence, interactivity, interest, immersion, and satisfaction.",
  "keywords": [
    "powerful llms",
    "llm agents psychological measurement",
    "we",
    "interviews",
    "generalizability",
    "llm agents",
    "llm",
    "self",
    "game-based and llm-based tools",
    "psychologist interviews",
    "a generic gamification",
    "llms",
    "psychometric evaluations",
    "metrics",
    "generic"
  ],
  "url": "https://aclanthology.org/2024.acl-long.779/",
  "provenance": {
    "collected_at": "2025-06-05 10:45:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}