{
  "id": "2023.trustnlp-1.13",
  "title": "Debunking Biases in Attention",
  "authors": [
    "Chen, Shijing  and\nNaseem, Usman  and\nRazzak, Imran"
  ],
  "year": "2023",
  "venue": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)",
  "abstract": "Despite the remarkable performances in various applications, machine learning (ML) models could potentially discriminate. They may result in biasness in decision-making, leading to an impact negatively on individuals and society. Recently, various methods have been developed to mitigate biasness and achieve significant performance. Attention mechanisms are a fundamental component of many state-of-the-art ML models and may potentially impact the fairness of ML models. However, how they explicitly influence fairness has yet to be thoroughly explored. In this paper, we investigate how different attention mechanisms affect the fairness of ML models, focusing on models used in Natural Language Processing (NLP) models. We evaluate the performance of fairness of several models with and without different attention mechanisms on widely used benchmark datasets. Our results indicate that the majority of attention mechanisms that have been assessed can improve the fairness performance of Bidirectional Gated Recurrent Unit (BiGRU) and Bidirectional Long Short-Term Memory (BiLSTM) in all three datasets regarding religious and gender-sensitive groups, however, with varying degrees of trade-offs in accuracy measures. Our findings highlight the possibility of fairness being affected by adopting specific attention mechanisms in machine learning models for certain datasets",
  "keywords": [
    "biasness",
    "attention mechanisms",
    "we",
    "how different attention mechanisms",
    "natural",
    "bilstm",
    "machine learning models",
    "bigru",
    "specific attention mechanisms",
    "significant performance attention mechanisms",
    "learning",
    "various applications machine learning",
    "recurrent",
    "processing",
    "different attention mechanisms"
  ],
  "url": "https://aclanthology.org/2023.trustnlp-1.13/",
  "provenance": {
    "collected_at": "2025-06-05 10:32:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}