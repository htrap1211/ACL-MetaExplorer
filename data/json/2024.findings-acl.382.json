{
  "id": "2024.findings-acl.382",
  "title": "TRAM}: Benchmarking Temporal Reasoning for Large Language Models",
  "authors": [
    "Wang, Yuqing  and\nZhao, Yun"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the TeR capabilities of large language models (LLMs). We evaluate popular LLMs like GPT-4 and Llama2 in zero-shot and few-shot scenarios, and establish baselines with BERT-based and domain-specific models. Our findings indicate that the best-performing model lags significantly behind human performance. It is our aspiration that TRAM will spur further progress in enhancing the TeR capabilities of LLMs.",
  "keywords": [
    "we",
    "bert-based and domain-specific models",
    "shot",
    "natural",
    "it",
    "the ter capabilities",
    "consistent evaluations",
    "a comprehensive evaluation",
    "ter",
    "llms",
    "bert",
    "topic",
    "large language models llms",
    "popular llms",
    "gpt-4"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.382/",
  "provenance": {
    "collected_at": "2025-06-05 10:53:49",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}