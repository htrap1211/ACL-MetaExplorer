{
  "id": "2020.acl-srw.40",
  "title": "Inducing Grammar from Long Short-Term Memory Networks by Shapley Decomposition",
  "authors": [
    "Zhang, Yuhui  and\nNie, Allen"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
  "abstract": "The principle of compositionality has deep roots in linguistics: the meaning of an expression is determined by its structure and the meanings of its constituents. However, modern neural network models such as long short-term memory network process expressions in a linear fashion and do not seem to incorporate more complex compositional patterns. In this work, we show that we can explicitly induce grammar by tracing the computational process of a long short-term memory network. We show: (i) the multiplicative nature of long short-term memory network allows complex interaction beyond sequential linear combination; (ii) we can generate compositional trees from the network without external linguistic knowledge; (iii) we evaluate the syntactic difference between the generated trees, randomly generated trees and gold reference trees produced by constituency parsers; (iv) we evaluate whether the generated trees contain the rich semantic information.",
  "keywords": [
    "deep",
    "semantic",
    "we",
    "the rich semantic information",
    "neural",
    "information",
    "rich",
    "the generated trees",
    "i",
    "work",
    "reference",
    "process",
    "knowledge",
    "network",
    "term"
  ],
  "url": "https://aclanthology.org/2020.acl-srw.40/",
  "provenance": {
    "collected_at": "2025-06-05 07:53:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}