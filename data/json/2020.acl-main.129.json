{
  "id": "2020.acl-main.129",
  "title": "L}earning {D}ialog {P}olicies from {W}eak {D}emonstrations",
  "authors": [
    "Gordon-Hall, Gabriel  and\nGorinski, Philip John  and\nCohen, Shay B."
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a userâ€™s requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on out-of-domain data.",
  "keywords": [
    "deep",
    "reinforcement",
    "deep reinforcement learning",
    "dialog",
    "us",
    "fine",
    "we",
    "learning",
    "action",
    "current",
    "p olicies",
    "ialog",
    "olicies",
    "promising",
    "multi-domain dialog systems building"
  ],
  "url": "https://aclanthology.org/2020.acl-main.129/",
  "provenance": {
    "collected_at": "2025-06-05 07:43:57",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}