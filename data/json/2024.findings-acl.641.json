{
  "id": "2024.findings-acl.641",
  "title": "Decomposition for Enhancing Attention: Improving {LLM}-based Text-to-{SQL} through Workflow Paradigm",
  "authors": [
    "Xie, Yuanzhen  and\nJin, Xinzhou  and\nXie, Tao  and\nMatrixmxlin, Matrixmxlin  and\nChen, Liang  and\nYu, Chenyun  and\nLei, Cheng  and\nZhuo, Chengxiang  and\nHu, Bo  and\nLi, Zang"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "In-context learning of large-language models (LLMs) has achieved remarkable success in the field of natural language processing, while extensive case studies reveal that the single-step chain-of-thought prompting approach faces challenges such as attention diffusion and inadequate performance in complex tasks like text-to-SQL. To improve the contextual learning capabilities of LLMs in text-to-SQL, a workflow paradigm method is proposed, aiming to enhance the attention and problem-solving scope of LLMs through decomposition. Specifically, the information determination module for eliminating redundant information and the brand-new prompt structure based on problem classification greatly enhance the modelâ€™s attention. Additionally, the inclusion of self-correction and active learning modules greatly expands the problem-solving scope of LLMs, hence improving the upper limit of LLM-based approaches. Extensive experiments conducted on three datasets demonstrate that our approach outperforms other methods by a significant margin. About 2-3 percentage point improvements compared to the existing baseline on the Spider Dev, Spider-Realistic, and Bird Dev datasets and new SOTA results on the Spider Test dataset are achieved. Our code is available on GitHub:https://github.com/FlyingFeather/DEA-SQL.",
  "keywords": [
    "code",
    "large-language models llms",
    "chain",
    "field",
    "problem classification",
    "classification",
    "natural",
    "the field",
    "llm -based text-to- sql",
    "self",
    "the model s attention",
    "information",
    "learning",
    "natural language processing",
    "llms"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.641/",
  "provenance": {
    "collected_at": "2025-06-05 10:57:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}