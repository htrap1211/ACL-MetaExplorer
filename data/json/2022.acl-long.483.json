{
  "id": "2022.acl-long.483",
  "title": "Prototypical Verbalizer for Prompt-based Few-shot Tuning",
  "authors": [
    "Cui, Ganqu  and\nHu, Shengding  and\nDing, Ning  and\nHuang, Longtao  and\nLiu, Zhiyuan"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Prompt-based tuning for pre-trained language models (PLMs) has shown its effectiveness in few-shot learning. Typically, prompt-based tuning wraps the input text into a cloze question. To make predictions, the model maps the output words to labels via a verbalizer, which is either manually designed or automatically built. However, manual verbalizers heavily depend on domain-specific prior knowledge and human efforts, while finding appropriate label words automatically still remains challenging. In this work, we propose the prototypical verbalizer (ProtoVerb) which is built directly from training data. Specifically, ProtoVerb learns prototype vectors as verbalizers by contrastive learning. In this way, the prototypes summarize training instances and are able to enclose rich class-level semantics. We conduct experiments on both topic classification and entity typing tasks, and the results demonstrate that ProtoVerb significantly outperforms current automatic verbalizers, especially when training data is extremely scarce. More surprisingly, ProtoVerb consistently boosts prompt-based tuning even on untuned PLMs, indicating an elegant non-tuning way to utilize PLMs. Our codes are avaliable athttps://github.com/thunlp/OpenPrompt.",
  "keywords": [
    "rich class-level semantics",
    "few-shot learning",
    "question",
    "we",
    "current",
    "shot",
    "training",
    "classification",
    "semantics",
    "both topic classification",
    "pre-trained language models plms",
    "rich",
    "learning",
    "tuning",
    "prompt"
  ],
  "url": "https://aclanthology.org/2022.acl-long.483/",
  "provenance": {
    "collected_at": "2025-06-05 08:30:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}