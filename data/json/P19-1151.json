{
  "id": "P19-1151",
  "title": "Soft Representation Learning for Sparse Transfer",
  "authors": [
    "Park, Haeju  and\nYeo, Jinyoung  and\nWang, Gengyu  and\nHwang, Seung-won"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Transfer learning is effective for improving the performance of tasks that are related, and Multi-task learning (MTL) and Cross-lingual learning (CLL) are important instances. This paper argues that hard-parameter sharing, of hard-coding layers shared across different tasks or languages, cannot generalize well, when sharing with a loosely related task. Such case, which we call sparse transfer, might actually hurt performance, a phenomenon known as negative transfer. Our contribution is using adversarial training across tasks, to “soft-code” shared and private spaces, to avoid the shared space gets too sparse. In CLL, our proposed architecture considers another challenge of dealing with low-quality input.",
  "keywords": [
    "cross",
    "code",
    "sparse transfer transfer learning",
    "we",
    "learning",
    "transfer",
    "soft",
    "training",
    "parameter",
    "that",
    "a loosely related task",
    "multi",
    "cll",
    "our proposed architecture",
    "a phenomenon"
  ],
  "url": "https://aclanthology.org/P19-1151/",
  "provenance": {
    "collected_at": "2025-06-05 00:33:31",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}