{
  "id": "2020.acl-main.331",
  "title": "MIND}: A Large-scale Dataset for News Recommendation",
  "authors": [
    "Wu, Fangzhao  and\nQiao, Ying  and\nChen, Jiun-Hung  and\nWu, Chuhan  and\nQi, Tao  and\nLian, Jianxun  and\nLiu, Danyang  and\nXie, Xing  and\nGao, Jianfeng  and\nWu, Winnie  and\nZhou, Ming"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available athttps://msnews.github.io.",
  "keywords": [
    "we",
    "pre-trained language models",
    "natural",
    "product and movie recommendations",
    "rich",
    "processing",
    "different proprietary datasets",
    "text",
    "language",
    "movie",
    "pre",
    "proprietary",
    "mind",
    "the quality",
    "state"
  ],
  "url": "https://aclanthology.org/2020.acl-main.331/",
  "provenance": {
    "collected_at": "2025-06-05 07:46:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}