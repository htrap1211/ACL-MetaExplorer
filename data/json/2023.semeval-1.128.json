{
  "id": "2023.semeval-1.128",
  "title": "Lazybob at {S}em{E}val-2023 Task 9: Quantifying Intimacy of Multilingual Tweets with Multi-Task Learning",
  "authors": [
    "Yuan, Mengfei  and\nChen, Cheng"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "This study presents a systematic method for analyzing the level of intimacy in tweets across ten different languages, using multi-task learning for SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis. The system begins with the utilization of the official training data, and then we experiment with different fine-tuning tricks and effective strategies, such as data augmentation, multi-task learning, etc. Through additional experiments, the approach is shown to be effective for the task. To enhance the modelâ€™s robustness, different transformer-based language models and some widely-used plug-and-play priors are incorporated into our system. Our final submission achieved a Pearson R of 0.6160 for the intimacy score on the official test set, placing us at the top of the leader board among 45 teams.",
  "keywords": [
    "transformer",
    "language",
    "model",
    "strategies",
    "-",
    "us",
    "fine",
    "we",
    "learning",
    "effective strategies",
    "different fine-tuning tricks",
    "analysis",
    "training",
    "multi",
    "approach"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.128/",
  "provenance": {
    "collected_at": "2025-06-05 10:28:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}