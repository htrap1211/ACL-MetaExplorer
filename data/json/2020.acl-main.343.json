{
  "id": "2020.acl-main.343",
  "title": "CH}-{SIMS}: A {C}hinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality",
  "authors": [
    "Yu, Wenmeng  and\nXu, Hua  and\nMeng, Fanyang  and\nZhu, Yilin  and\nMa, Yixiao  and\nWu, Jiele  and\nZou, Jiyun  and\nYang, Kaicheng"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Previous studies in multimodal sentiment analysis have used limited datasets, which only contain unified multimodal annotations. However, the unified annotations do not always reflect the independent sentiment of single modalities and limit the model to capture the difference between modalities. In this paper, we introduce a Chinese single- and multi-modal sentiment analysis dataset, CH-SIMS, which contains 2,281 refined video segments in the wild with both multimodal and independent unimodal annotations. It allows researchers to study the interaction between modalities or use independent unimodal annotations for unimodal sentiment analysis. Furthermore, we propose a multi-task learning framework based on late fusion as the baseline. Extensive experiments on the CH-SIMS show that our methods achieve state-of-the-art performance and learn more distinctive unimodal representations. The full dataset and codes are available for use athttps://github.com/thuiar/MMSA.",
  "keywords": [
    "single modalities",
    "we",
    "fusion",
    "it",
    "unified",
    "multimodal sentiment analysis",
    "the unified annotations",
    "modality previous studies",
    "analysis",
    "unimodal sentiment analysis",
    "-",
    "sentiment",
    "late",
    "model",
    "studies"
  ],
  "url": "https://aclanthology.org/2020.acl-main.343/",
  "provenance": {
    "collected_at": "2025-06-05 07:46:49",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}