{
  "id": "P19-1624",
  "title": "Exploiting Sentential Context for Neural Machine Translation",
  "authors": [
    "Wang, Xing  and\nTu, Zhaopeng  and\nWang, Longyue  and\nShi, Shuming"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "In this work, we present novel approaches to exploit sentential context for neural machine translation (NMT). Specifically, we show that a shallow sentential context extracted from the top encoder layer only, can improve translation performance via contextualizing the encoding representations of individual words. Next, we introduce a deep sentential context, which aggregates the sentential context representations from all of the internal layers of the encoder to form a more comprehensive context representation. Experimental results on the WMT14 English-German and English-French benchmarks show that our model consistently improves performance over the strong Transformer model, demonstrating the necessity and effectiveness of exploiting sentential context for NMT.",
  "keywords": [
    "work",
    "deep",
    "transformer",
    "the encoder",
    "the top encoder layer",
    "neural",
    "model",
    "machine",
    "the strong transformer model",
    "neural machine translation",
    "encoder",
    "layer",
    "all",
    "we",
    "neural machine translation nmt"
  ],
  "url": "https://aclanthology.org/P19-1624/",
  "provenance": {
    "collected_at": "2025-06-05 00:46:46",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}