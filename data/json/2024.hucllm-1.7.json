{
  "id": "2024.hucllm-1.7",
  "title": "Aligning to Adults Is Easy, Aligning to Children Is Hard: A Study of Linguistic Alignment in Dialogue Systems",
  "authors": [
    "French, Dorothea  and\nD{'}Mello, Sidney  and\nvon der Wense, Katharina"
  ],
  "year": "2024",
  "venue": "Proceedings of the 1st Human-Centered Large Language Modeling Workshop",
  "abstract": "During conversations, people align to one another over time, by using similar words, concepts, and syntax. This helps form a shared understanding of the conversational content and is associated with increased engagement and satisfaction. It also affects conversation outcomes: e.g., when talking to language learners, an above normal level of linguistic alignment of parents or language teachers is correlated with faster language acquisition. These benefits make human-like alignment an important property of dialogue systems, which has often been overlooked by the NLP community. In order to fill this gap, we ask: (RQ1) Due to the importance for engagement and satisfaction, to what degree do state-of-the-art dialogue systems align to adult users? (RQ2) With a potential application to child language acquisition in mind, do systems, similar to parents, show high levels of alignment during conversations with children? Our experiments show that ChatGPT aligns to adults at roughly human levels, while Llama2 shows elevated alignment. However, when responding to a child, both systemsâ€™ alignment is below human levels.",
  "keywords": [
    "conversations",
    "the nlp community",
    "we",
    "dialogue",
    "syntax",
    "language learners",
    "it",
    "dialogue systems",
    "chatgpt",
    "normal",
    "conversation outcomes e g",
    "linguistic alignment",
    "elevated alignment",
    "the conversational content",
    "alignment"
  ],
  "url": "https://aclanthology.org/2024.hucllm-1.7/",
  "provenance": {
    "collected_at": "2025-06-05 11:06:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}