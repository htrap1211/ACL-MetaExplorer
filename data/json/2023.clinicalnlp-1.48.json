{
  "id": "2023.clinicalnlp-1.48",
  "title": "A Survey of Evaluation Methods of Generated Medical Textual Reports",
  "authors": [
    "Zhou, Yongxin  and\nRingeval, Fabien  and\nPortet, Fran{\\c{c}}ois"
  ],
  "year": "2023",
  "venue": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
  "abstract": "Medical Report Generation (MRG) is a sub-task of Natural Language Generation (NLG) and aims to present information from various sources in textual form and synthesize salient information, with the goal of reducing the time spent by domain experts in writing medical reports and providing support information for decision-making. Given the specificity of the medical domain, the evaluation of automatically generated medical reports is of paramount importance to the validity of these systems. Therefore, in this paper, we focus on the evaluation of automatically generated medical reports from the perspective of automatic and human evaluation. We present evaluation methods for general NLG evaluation and how they have been applied to domain-specific medical tasks. The study shows that MRG evaluation methods are very diverse, and that further work is needed to build shared evaluation methods. The state of the art also emphasizes that such an evaluation must be task specific and include human assessments, requesting the participation of experts in the field.",
  "keywords": [
    "automatically generated medical reports",
    "such an evaluation",
    "support",
    "field",
    "form",
    "shared evaluation methods",
    "we",
    "salient information",
    "automatic and human evaluation",
    "general nlg evaluation",
    "medical report generation mrg",
    "natural",
    "the field",
    "information",
    "natural language generation"
  ],
  "url": "https://aclanthology.org/2023.clinicalnlp-1.48/",
  "provenance": {
    "collected_at": "2025-06-05 10:23:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}