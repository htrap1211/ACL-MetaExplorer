{
  "id": "2024.wassa-1.49",
  "title": "TEII}: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection",
  "authors": [
    "Cheng, Long  and\nShao, Qihao  and\nZhao, Christine  and\nBi, Sheng  and\nLevow, Gina-Anne"
  ],
  "year": "2024",
  "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis",
  "abstract": "Cross-lingual emotion detection allows us to analyze global trends, public opinion, and social phenomena at scale. We participated in the Explainability of Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score of 0.6046 on the evaluation set for the emotion detection sub-task. Our system outperformed the baseline by more than 0.16 F1-score absolute, and ranked second amongst competing systems. We conducted experiments using fine-tuning, zero-shot learning, and few-shot learning for Large Language Model (LLM)-based models as well as embedding-based BiLSTM and KNN for non-LLM-based techniques. Additionally, we introduced two novel methods: the Multi-Iteration Agentic Workflow and the Multi-Binary-Classifier Agentic Workflow. We found that LLM-based approaches provided good performance on multilingual emotion detection. Furthermore, ensembles combining all our experimented models yielded higher F1-scores than any single approach alone.",
  "keywords": [
    "non-llm-based techniques",
    "classifier",
    "few-shot learning",
    "large language model",
    "we",
    "llm",
    "shot",
    "cross",
    "bilstm",
    "llm -based models",
    "learning",
    "an f1-score",
    "-",
    "embedding-based bilstm",
    "higher f1-scores"
  ],
  "url": "https://aclanthology.org/2024.wassa-1.49/",
  "provenance": {
    "collected_at": "2025-06-05 11:12:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}