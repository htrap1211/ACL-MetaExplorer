{
  "id": "P19-1349",
  "title": "Multi-grained Attention with Object-level Grounding for Visual Question Answering",
  "authors": [
    "Huang, Pingping  and\nHuang, Jianhui  and\nGuo, Yuqing  and\nQiao, Min  and\nZhu, Yong"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Attention mechanisms are widely used in Visual Question Answering (VQA) to search for visual clues related to the question. Most approaches train attention models from a coarse-grained association between sentences and images, which tends to fail on small objects or uncommon concepts. To address this problem, this paper proposes a multi-grained attention method. It learns explicit word-object correspondence by two types of word-level attention complementary to the sentence-image association. Evaluated on the VQA benchmark, the multi-grained attention model achieves competitive performance with state-of-the-art models. And the visualized attention maps demonstrate that addition of object-level groundings leads to a better understanding of the images and locates the attended objects more precisely.",
  "keywords": [
    "multi-grained attention",
    "a multi-grained attention method",
    "answering attention mechanisms",
    "the multi-grained attention model",
    "object",
    "model",
    "it",
    "the vqa benchmark",
    "the visualized attention maps",
    "question",
    "attention",
    "word",
    "visual",
    "vqa",
    "train attention models"
  ],
  "url": "https://aclanthology.org/P19-1349/",
  "provenance": {
    "collected_at": "2025-06-05 00:39:02",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}