{
  "id": "2022.acl-long.94",
  "title": "A Well-Composed Text is Half Done! Composition Sampling for Diverse Conditional Generation",
  "authors": [
    "Narayan, Shashi  and\nSim{\\~o}es, Gon{\\c{c}}alo  and\nZhao, Yao  and\nMaynez, Joshua  and\nDas, Dipanjan  and\nCollins, Michael  and\nLapata, Mirella"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We propose Composition Sampling, a simple but effective method to generate diverse outputs for conditional generation of higher quality compared to previous stochastic decoding strategies. It builds on recently proposed plan-based neural generation models (FROST, Narayan et al, 2021) that are trained to first create a composition of the output and then generate by conditioning on it and the input. Our approach avoids text degeneration by first sampling a composition in the form of an entity chain and then using beam search to generate the best possible text grounded to this entity chain. Experiments on summarization (CNN/DailyMail and XSum) and question generation (SQuAD), using existing and newly proposed automaticmetrics together with human-based evaluation, demonstrate that Composition Sampling is currently the best available decoding strategy for generating diverse meaningful outputs.",
  "keywords": [
    "generation",
    "text degeneration",
    "neural",
    "cnn",
    "text",
    "it",
    "human",
    "chain",
    "strategies",
    "conditional generation",
    "summarization cnn dailymail",
    "question",
    "form",
    "summarization",
    "we"
  ],
  "url": "https://aclanthology.org/2022.acl-long.94/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}