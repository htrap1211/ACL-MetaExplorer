{
  "id": "2022.acl-long.59",
  "title": "De-Bias for Generative Extraction in Unified {NER} Task",
  "authors": [
    "Zhang, Shuai  and\nShen, Yongliang  and\nTan, Zeqi  and\nWu, Yiquan  and\nLu, Weiming"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Named entity recognition (NER) is a fundamental task to recognize specific types of entities from a given sentence. Depending on how the entities appear in the sentence, it can be divided into three subtasks, namely, Flat NER, Nested NER, and Discontinuous NER. Among the existing approaches, only the generative model can be uniformly adapted to these three subtasks. However, when the generative model is applied to NER, its optimization objective is not consistent with the task, which makes the model vulnerable to the incorrect biases. In this paper, we analyze the incorrect biases in the generation process from a causality perspective and attribute them to two confounders: pre-context confounder and entity-order confounder. Furthermore, we design Intra- and Inter-entity Deconfounding Data Augmentation methods to eliminate the above confounders according to the theory of backdoor adjustment. Experiments show that our method can improve the performance of the generative NER model in various datasets.",
  "keywords": [
    "bias",
    "generative extraction",
    "extraction",
    "the incorrect biases",
    "we",
    "the entities",
    "de",
    "it",
    "its optimization objective",
    "unified ner task",
    "unified",
    "vulnerable",
    "generative",
    "ner",
    "only the generative model"
  ],
  "url": "https://aclanthology.org/2022.acl-long.59/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}