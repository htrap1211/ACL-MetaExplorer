{
  "id": "2022.ltedi-1.43",
  "title": "gini{U}s @{LT}-{EDI}-{ACL}2022: Aasha: Transformers based Hope-{EDI",
  "authors": [
    "Chinagundi, Basavraj  and\nSurana, Harshul"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",
  "abstract": "This paper describes team giniUsâ€™ submission to the Hope Speech Detection for Equality, Diversity and Inclusion Shared Task organised by LT-EDI ACL 2022. We have fine-tuned the Roberta-large pre-trained model and extracted the last four decoder layers to build a classifier. Our best result on the leaderboard achieve a weighted F1 score of 0.86 and a Macro F1 score of 0.51 for English. We have secured a rank of 4 for the English task. We have open-sourced our code implementations on GitHub to facilitate easy reproducibility by the scientific community.",
  "keywords": [
    "the scientific community",
    "code",
    "transformers",
    "roberta",
    "model",
    "classifier",
    "a weighted f1 score",
    "decoder",
    "the roberta-large pre-trained model",
    "we",
    "a classifier",
    "pre",
    "scientific",
    "a macro f1 score",
    "speech"
  ],
  "url": "https://aclanthology.org/2022.ltedi-1.43/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}