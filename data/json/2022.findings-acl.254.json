{
  "id": "2022.findings-acl.254",
  "title": "Type-Driven Multi-Turn Corrections for Grammatical Error Correction",
  "authors": [
    "Lai, Shaopeng  and\nZhou, Qingyu  and\nZeng, Jiali  and\nLi, Zhongli  and\nLi, Chao  and\nCao, Yunbo  and\nSu, Jinsong"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Grammatical Error Correction (GEC) aims to automatically detect and correct grammatical errors. In this aspect, dominant models are trained by one-iteration learning while performing multiple iterations of corrections during inference. Previous studies mainly focus on the data augmentation approach to combat the exposure bias, which suffers from two drawbacks. First, they simply mix additionally-constructed training instances and original ones to train models, which fails to help models be explicitly aware of the procedure of gradual corrections. Second, they ignore the interdependence between different types of corrections. In this paper, we propose a Type-Driven Multi-Turn Corrections approach for GEC. Using this approach, from each training instance, we additionally construct multiple training instances, each of which involves the correction of a specific type of errors. Then, we use these additionally-constructed training instances and the original one to train the model in turn. Experimental results and in-depth analysis show that our approach significantly benefits the model training. Particularly, our enhanced model achieves state-of-the-art single-model performance on English GEC benchmarks. We release our code at Github.",
  "keywords": [
    "code",
    "bias",
    "we",
    "training",
    "learning",
    "analysis",
    "the exposure bias",
    "previous studies",
    "model",
    "studies",
    "multi",
    "approach",
    "original",
    "state",
    "error"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.254/",
  "provenance": {
    "collected_at": "2025-06-05 08:38:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}