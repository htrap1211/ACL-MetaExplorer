{
  "id": "2021.acl-long.219",
  "title": "A Neural Transition-based Joint Model for Disease Named Entity Recognition and Normalization",
  "authors": [
    "Ji, Zongcheng  and\nXia, Tian  and\nHan, Mei  and\nXiao, Jing"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Disease is one of the fundamental entities in biomedical research. Recognizing such entities from biomedical text and then normalizing them to a standardized disease vocabulary offer a tremendous opportunity for many downstream applications. Previous studies have demonstrated that joint modeling of the two sub-tasks has superior performance than the pipelined counterpart. Although the neural joint model based on multi-task learning framework has achieved state-of-the-art performance, it suffers from the boundary inconsistency problem due to the separate decoding procedures. Moreover, it ignores the rich information (e.g., the text surface form) of each candidate concept in the vocabulary, which is quite essential for entity normalization. In this work, we propose a neural transition-based joint model to alleviate these two issues. We transform the end-to-end disease recognition and normalization task as an action sequence prediction task, which not only jointly learns the model with shared representations of the input, but also jointly searches the output by state transitions in one search space. Moreover, we introduce attention mechanisms to take advantage of the text surface form of each candidate concept for better normalization performance. Experimental results conducted on two publicly available datasets show the effectiveness of the proposed method.",
  "keywords": [
    "end",
    "attention mechanisms",
    "form",
    "we",
    "neural",
    "it",
    "information",
    "rich",
    "sequence",
    "such entities",
    "normalization",
    "previous studies",
    "text",
    "-",
    "action"
  ],
  "url": "https://aclanthology.org/2021.acl-long.219/",
  "provenance": {
    "collected_at": "2025-06-05 08:02:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}