{
  "id": "P19-1283",
  "title": "Correlating Neural and Symbolic Representations of Language",
  "authors": [
    "Chrupa{\\l}a, Grzegorz  and\nAlishahi, Afra"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Analysis methods which enable us to better understand the representations and functioning of neural models of language are increasingly needed as deep learning becomes the dominant approach in NLP. Here we present two methods based on Representational Similarity Analysis (RSA) and Tree Kernels (TK) which allow us to directly quantify how strongly the information encoded in neural activation patterns corresponds to information represented by symbolic structures such as syntax trees. We first validate our methods on the case of a simple synthetic language for arithmetic expressions with clearly defined syntax and semantics, and show that they exhibit the expected pattern of results. We then our methods to correlate neural representations of English sentences with their constituency parse trees.",
  "keywords": [
    "deep",
    "language",
    "neural",
    "nlp",
    "syntax trees",
    "semantics",
    "deep learning",
    "clearly defined syntax",
    "activation",
    "information",
    "us",
    "we",
    "learning",
    "neural activation patterns corresponds",
    "kernels"
  ],
  "url": "https://aclanthology.org/P19-1283/",
  "provenance": {
    "collected_at": "2025-06-05 00:37:12",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}