{
  "id": "2022.acl-long.135",
  "title": "Sense Embeddings are also Biased {--} Evaluating Social Biases in Static and Contextualised Sense Embeddings",
  "authors": [
    "Zhou, Yi  and\nKaneko, Masahiro  and\nBollegala, Danushka"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Sense embedding learning methods learn different embeddings for the different senses of an ambiguous word. One sense of an ambiguous word might be socially biased while its other senses remain unbiased. In comparison to the numerous prior work evaluating the social biases in pretrained word embeddings, the biases in sense embeddings have been relatively understudied. We create a benchmark dataset for evaluating the social biases in sense embeddings and propose novel sense-specific bias evaluation measures. We conduct an extensive evaluation of multiple static and contextualised sense embeddings for various types of social biases using the proposed measures. Our experimental results show that even in cases where no biases are found at word-level, there still exist worrying levels of social biases at sense-level, which are often ignored by the word-level bias evaluation measures.",
  "keywords": [
    "embeddings",
    "work",
    "bias",
    "unbiased",
    "pretrained word embeddings",
    "social biases",
    "sense embeddings",
    "the biases",
    "no biases",
    "an extensive evaluation",
    "different embeddings",
    "understudied",
    "word",
    "we",
    "learning"
  ],
  "url": "https://aclanthology.org/2022.acl-long.135/",
  "provenance": {
    "collected_at": "2025-06-05 08:26:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}