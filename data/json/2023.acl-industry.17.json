{
  "id": "2023.acl-industry.17",
  "title": "Entity Contrastive Learning in a Large-Scale Virtual Assistant System",
  "authors": [
    "Rubin, Jonathan  and\nCrowley, Jason  and\nLeung, George  and\nZiyadi, Morteza  and\nMinakova, Maria"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
  "abstract": "Conversational agents are typically made up of domain (DC) and intent classifiers (IC) that identify the general subject an utterance belongs to and the specific action a user wishes to achieve. In addition, named entity recognition (NER) performs per token labeling to identify specific entities of interest in a spoken utterance. We investigate improving joint IC and NER models using entity contrastive learning that attempts to cluster similar entities together in a learned representation space. We compare a full virtual assistant system trained using entity contrastive learning to a production baseline system that does not use contrastive learning. We present both offline results, using retrospective test sets, as well as live online results from an A/B test that compared the two systems. In both the offline and online settings, entity contrastive training improved overall performance against production baselines. Furthermore, we provide a detailed analysis of learned entity embeddings, including both qualitative analysis via dimensionality-reduced visualizations and quantitative analysis by computing alignment and uniformity metrics. We show that entity contrastive learning improves alignment metrics and produces well-formed embedding clusters in representation space.",
  "keywords": [
    "learned entity embeddings",
    "dimensionality",
    "classifiers",
    "well-formed embedding clusters",
    "alignment metrics",
    "we",
    "uniformity metrics",
    "training",
    "token",
    "similar entities",
    "learning",
    "analysis",
    "ner",
    "metrics",
    "the general subject"
  ],
  "url": "https://aclanthology.org/2023.acl-industry.17/",
  "provenance": {
    "collected_at": "2025-06-05 09:52:13",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}