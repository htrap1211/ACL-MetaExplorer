{
  "id": "2022.ltedi-1.30",
  "title": "SSNCSE}{\\_}{NLP}@{LT}-{EDI}-{ACL}2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers",
  "authors": [
    "B, Bharathi  and\nSrinivasan, Dhanya  and\nVarsha, Josephine  and\nDurairaj, Thenmozhi  and\nB, Senthil Kumar"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",
  "abstract": "In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political & religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into ‘Hope Speech’ and ‘Non-Hope Speech’. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don’t. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM_MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1- score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.",
  "keywords": [
    "transformers",
    "support",
    "we",
    "m-bert mlnet bert xlmroberta",
    "m",
    "bert",
    "text",
    "the bert",
    "transformer",
    "work",
    "nlp",
    "machine",
    "us",
    "f1-",
    "sentence transformers"
  ],
  "url": "https://aclanthology.org/2022.ltedi-1.30/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:45",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}