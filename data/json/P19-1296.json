{
  "id": "P19-1296",
  "title": "Sentence-Level Agreement for Neural Machine Translation",
  "authors": [
    "Yang, Mingming  and\nWang, Rui  and\nChen, Kehai  and\nUtiyama, Masao  and\nSumita, Eiichiro  and\nZhang, Min  and\nZhao, Tiejun"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "The training objective of neural machine translation (NMT) is to minimize the loss between the words in the translated sentences and those in the references. In NMT, there is a natural correspondence between the source sentence and the target sentence. However, this relationship has only been represented using the entire neural network and the training objective is computed in word-level. In this paper, we propose a sentence-level agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance.",
  "keywords": [
    "translation",
    "neural",
    "natural",
    "machine",
    "objective",
    "neural machine translation",
    "the entire neural network",
    "loss",
    "the training objective",
    "network",
    "word",
    "we",
    "neural machine translation nmt",
    "training",
    "function"
  ],
  "url": "https://aclanthology.org/P19-1296/",
  "provenance": {
    "collected_at": "2025-06-05 00:37:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}