{
  "id": "2024.findings-acl.66",
  "title": "C}o{LL}a{VO}: Crayon Large Language and Vision m{O}del",
  "authors": [
    "Lee, Byung-Kwan  and\nPark, Beomchan  and\nKim, Chae Won  and\nRo, Yong Man"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "The remarkable success of Large Language Models (LLMs) and instruction tuning drives the evolution of Vision Language Models (VLMs) towards a versatile general-purpose model. Yet, it remains unexplored whether current VLMs genuinely possess quality object-level image understanding capabilities determined from ‘what objects are in the image?’ or ‘which object corresponds to a specified bounding box?’. Our findings reveal that the image understanding capabilities of current VLMs are strongly correlated with their zero-shot performance on vision language (VL) tasks. This suggests that prioritizing basic image understanding is crucial for VLMs to excel at VL tasks. To enhance object-level image understanding, we propose Crayon Large Language and Vision mOdel (CoLLaVO), which incorporates instruction tuning with Crayon Prompt as a new visual prompt tuning scheme based on panoptic color maps. Furthermore, we present a learning strategy of Dual QLoRA to preserve object-level image understanding without forgetting it during visual instruction tuning, thereby achieving a significant leap in numerous VL benchmarks in a zero-shot setting.",
  "keywords": [
    "visual instruction tuning",
    "we",
    "current",
    "shot",
    "instruction",
    "it",
    "visual",
    "a specified bounding box",
    "crayon prompt",
    "llms",
    "instruction tuning",
    "tuning",
    "prompt",
    "object",
    "large language models llms"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.66/",
  "provenance": {
    "collected_at": "2025-06-05 10:49:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}