{
  "id": "2024.findings-acl.926",
  "title": "From Tarzan to {T}olkien: Controlling the Language Proficiency Level of {LLM}s for Content Generation",
  "authors": [
    "Malik, Ali  and\nMayhew, Stephen  and\nPiech, Christopher  and\nBicknell, Klinton"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end-users are not fully proficient, such as language learners. Using a novel framework, we evaluate the effectiveness of several key approaches for this task, including few-shot prompting, supervised finetuning, and reinforcement learning (RL), utilising both GPT-4 and open source alternatives like LLama2-7B and Mistral-7B.Our findings reveal a large performance gap between GPT-4 and the open source models when using prompt-based strategies. However, we show how to bridge this gap with a careful combination of finetuning and RL alignment. Our best model, CALM (CEFR-Aligned Language Model), surpasses the performance of GPT-4 and other strategies, at only a fraction of the cost. We further validate the quality of our results through a small-scale human study.",
  "keywords": [
    "prompt-based strategies",
    "end",
    "llm s",
    "we",
    "olkien",
    "language learners",
    "llm",
    "shot",
    "learning",
    "both gpt-4",
    "prompt",
    "the language proficiency level",
    "text",
    "strategies",
    "gpt-4"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.926/",
  "provenance": {
    "collected_at": "2025-06-05 11:01:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}