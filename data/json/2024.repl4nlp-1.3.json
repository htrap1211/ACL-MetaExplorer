{
  "id": "2024.repl4nlp-1.3",
  "title": "Relevance-aware Diverse Query Generation for Out-of-domain Text Ranking",
  "authors": [
    "Ju, Jia-Huei  and\nYang, Huck Chao-Han  and\nFu, Szu-Wei  and\nTsai, Ming-Feng  and\nWang, Chuan-Ju"
  ],
  "year": "2024",
  "venue": "Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)",
  "abstract": "Domain adaptation presents significant challenges for out-of-domain text ranking, especially when supervised data is limited. In this paper, we present ReadQG (Relevance-Aware Diverse Query Generation), a method to generate informative synthetic queries to facilitate the adaptation process of text ranking models. Unlike previous approaches focusing solely on relevant query generation, our ReadQG generates diverse queries with continuous relevance scores. Specifically, we propose leveraging soft-prompt tuning and diverse generation objectives to control query generation according to the given relevance. Our experiments show that integrating negative queries into the learning process enhances the effectiveness of text ranking models in out-of-domain information retrieval (IR) benchmarks. Furthermore, we measure the quality of query generation, highlighting the underlying beneficial characteristics of negative queries. Our empirical results and analysis also shed light on potential directions for more advanced data augmentation in IR. The data and code have been released.",
  "keywords": [
    "code",
    "diverse queries",
    "process",
    "tuning",
    "soft-prompt tuning",
    "objectives",
    "prompt",
    "generation",
    "diverse generation objectives",
    "text",
    "queries",
    "retrieval",
    "relevant query generation",
    "information",
    "informative synthetic queries"
  ],
  "url": "https://aclanthology.org/2024.repl4nlp-1.3/",
  "provenance": {
    "collected_at": "2025-06-05 11:09:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}