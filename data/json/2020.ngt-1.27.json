{
  "id": "2020.ngt-1.27",
  "title": "Improving Document-Level Neural Machine Translation with Domain Adaptation",
  "authors": [
    "Ul Haq, Sami  and\nAbdul Rauf, Sadaf  and\nShoukat, Arslan  and\nHira, Noor-e-"
  ],
  "year": "2020",
  "venue": "Proceedings of the Fourth Workshop on Neural Generation and Translation",
  "abstract": "Recent studies have shown that translation quality of NMT systems can be improved by providing document-level contextual information. In general sentence-based NMT models are extended to capture contextual information from large-scale document-level corpora which are difficult to acquire. Domain adaptation on the other hand promises adapting components of already developed systems by exploiting limited in-domain data. This paper presents FJWUâ€™s system submission at WNGT, we specifically participated in Document level MT task for German-English translation. Our system is based on context-aware Transformer model developed on top of original NMT architecture by integrating contextual information using attention networks. Our experimental results show providing previous sentences as context significantly improves the BLEU score as compared to a strong NMT baseline. We also studied the impact of domain adaptation on document level translationand were able to improve results by adaptingthe systems according to the testing domain.",
  "keywords": [
    "top",
    "the bleu score",
    "bleu",
    "we",
    "translation",
    "neural",
    "context-aware transformer model",
    "information",
    "general sentence-based nmt models",
    "document level translationand",
    "recent studies",
    "transformer",
    "translationand",
    "general",
    "attention networks"
  ],
  "url": "https://aclanthology.org/2020.ngt-1.27/",
  "provenance": {
    "collected_at": "2025-06-05 07:57:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}