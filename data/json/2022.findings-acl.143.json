{
  "id": "2022.findings-acl.143",
  "title": "Modality-specific Learning Rates for Effective Multimodal Additive Late-fusion",
  "authors": [
    "Yao, Yiqun  and\nMihalcea, Rada"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "In multimodal machine learning, additive late-fusion is a straightforward approach to combine the feature representations from different modalities, in which the final prediction can be formulated as the sum of unimodal predictions. While it has been found that certain late-fusion models can achieve competitive performance with lower computational costs compared to complex multimodal interactive models, how to effectively search for a good late-fusion model is still an open question. Moreover, for different modalities, the best unimodal models may work under significantly different learning rates due to the nature of the modality and the computational flow of the model; thus, selecting a global learning rate for late-fusion models can result in a vanishing gradient for some modalities. To help address these issues, we propose a Modality-Specific Learning Rate (MSLR) method to effectively build late-fusion multimodal models from fine-tuned unimodal models. We investigate three different strategies to assign learning rates to different modalities. Our experiments show that MSLR outperforms global learning rates on multiple tasks and settings, and enables the models to effectively learn each modality.",
  "keywords": [
    "a vanishing gradient",
    "rate",
    "question",
    "we",
    "fusion",
    "three different strategies",
    "it",
    "modality-specific learning rates",
    "learning",
    "different modalities",
    "a global learning rate",
    "strategies",
    "sum",
    "significantly different learning rates",
    "late"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.143/",
  "provenance": {
    "collected_at": "2025-06-05 08:36:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}