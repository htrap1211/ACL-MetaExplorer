{
  "id": "W19-5325",
  "title": "The {N}iu{T}rans Machine Translation Systems for {WMT}19",
  "authors": [
    "Li, Bei  and\nLi, Yinqiao  and\nXu, Chen  and\nLin, Ye  and\nLiu, Jiqiang  and\nLiu, Hui  and\nWang, Ziyang  and\nZhang, Yuhao  and\nXu, Nuo  and\nWang, Zeyang  and\nFeng, Kai  and\nChen, Hexuan  and\nLiu, Tengbo  and\nLi, Yanyang  and\nWang, Qiang  and\nXiao, Tong  and\nZhu, Jingbo"
  ],
  "year": "2019",
  "venue": "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
  "abstract": "This paper described NiuTrans neural machine translation systems for the WMT 2019 news translation tasks. We participated in 13 translation directions, including 11 supervised tasks, namely EN↔{ZH, DE, RU, KK, LT}, GU→EN and the unsupervised DE↔CS sub-track. Our systems were built on Deep Transformer and several back-translation methods. Iterative knowledge distillation and ensemble+reranking were also employed to obtain stronger models. Our unsupervised submissions were based on NMT enhanced by SMT. As a result, we achieved the highest BLEU scores in {KK↔EN, GU→EN} directions, ranking 2nd in {RU→EN, DE↔CS} and 3rd in {ZH→EN, LT→EN, EN→RU, EN↔DE} among all constrained submissions.",
  "keywords": [
    "deep",
    "t",
    "transformer",
    "ensemble",
    "knowledge",
    "neural",
    "13 translation directions",
    "machine",
    "neural machine translation systems",
    "several back-translation methods",
    "bleu",
    "machine translation systems",
    "ensemble reranking",
    "we",
    "the highest bleu scores"
  ],
  "url": "https://aclanthology.org/W19-5325/",
  "provenance": {
    "collected_at": "2025-06-05 02:07:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}