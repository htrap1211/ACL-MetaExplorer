{
  "id": "2023.findings-acl.316",
  "title": "Fusion or Defusion? Flexible Vision-and-Language Pre-Training",
  "authors": [
    "Sun, Rongyi  and\nLi, Ziran  and\nDing, Yifeng  and\nWang, Qifan  and\nWang, Jingang  and\nZheng, Haitao  and\nWu, Wei  and\nXian, Yunsen"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Existing approaches in the vision-and-language pre-training (VLP) paradigm mainly deploy either fusion-based encoders or dual-encoders, failing to achieve both effectiveness and efficiency in downstream multimodal tasks. In this paper, we build a flexible VLP model by incorporating cross-modal fusions into a dual-encoder architecture, where the introduced fusion modules can be easily decoupled from the dual encoder so as to switch the model to a fusion-free one. To better absorb cross-modal features from the fusion modules, we design a cross-modal knowledge transfer strategy along with other comprehensive pre-training tasks to guide the training process, which can further strengthen both the fusion-based and fusion-free representation learning. Extensive experiments conducted on various downstream vision-language tasks show that our proposed model is well-equipped with effectiveness as well as efficiency, demonstrating a superior performance compared with other strong VLP models.",
  "keywords": [
    "cross",
    "dual-encoders",
    "process",
    "knowledge",
    "language",
    "model",
    "either fusion-based encoders",
    "encoder",
    "efficiency",
    "we",
    "transfer",
    "pre",
    "a dual-encoder architecture",
    "fusion",
    "encoders"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.316/",
  "provenance": {
    "collected_at": "2025-06-05 09:57:40",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}