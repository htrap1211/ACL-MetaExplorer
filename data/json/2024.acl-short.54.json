{
  "id": "2024.acl-short.54",
  "title": "PR}ewrite: Prompt Rewriting with Reinforcement Learning",
  "authors": [
    "Kong, Weize  and\nHombaiah, Spurthi  and\nZhang, Mingyang  and\nMei, Qiaozhu  and\nBendersky, Michael"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a “trial and error” fashion that can be time consuming, ineffective, and sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the prompts be made better with further modifications?To address these problems, we investigate automated prompt engineering in this paper. Specifically, we propose PRewrite, an automated method to rewrite an under-optimized prompt to a more effective prompt. We instantiate the prompt rewriter using an LLM. The rewriter LLM is trained using reinforcement learning to optimize the performance on a given downstream task. We conduct experiments on diverse benchmark datasets, which demonstrates the effectiveness of PRewrite.",
  "keywords": [
    "prompts",
    "automated prompt engineering",
    "reinforcement",
    "prompt",
    "it",
    "an llm",
    "llm-based applications",
    "question",
    "a more effective prompt",
    "we",
    "learning",
    "reinforcement learning prompt engineering",
    "the prompt rewriter",
    "the prompts",
    "time"
  ],
  "url": "https://aclanthology.org/2024.acl-short.54/",
  "provenance": {
    "collected_at": "2025-06-05 10:46:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}