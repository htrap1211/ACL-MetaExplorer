{
  "id": "2023.semeval-1.212",
  "title": "DN} at {S}em{E}val-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning",
  "authors": [
    "Homskiy, Daniil  and\nMaloyan, Narek"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "In our work, a model is implemented that solves the task, based on multilingual pre-trained models. We also consider various methods of data preprocessing",
  "keywords": [
    "work",
    "tuning",
    "language",
    "model",
    "text",
    "multilingual pretrained language model",
    "fine",
    "we",
    "pre",
    "classification",
    "that",
    "multilingual pre-trained models",
    "task",
    "low",
    "data"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.212/",
  "provenance": {
    "collected_at": "2025-06-05 10:29:31",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}