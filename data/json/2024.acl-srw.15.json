{
  "id": "2024.acl-srw.15",
  "title": "Demystifying Instruction Mixing for Fine-tuning Large Language Models",
  "authors": [
    "Wang, Renxi  and\nLi, Haonan  and\nWu, Minghao  and\nWang, Yuxia  and\nHan, Xudong  and\nZhang, Chiyu  and\nBaldwin, Timothy"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
  "abstract": "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advantageous for specific applications but can negatively impact other areas. This work provides insights into instruction mixtures, laying the foundations for future research.",
  "keywords": [
    "instruction",
    "work",
    "llm fine-tuning",
    "instruction tuning",
    "tuning",
    "general",
    "language",
    "llm performance",
    "large language models",
    "fine",
    "we",
    "llm",
    "applications",
    "this work",
    "insights"
  ],
  "url": "https://aclanthology.org/2024.acl-srw.15/",
  "provenance": {
    "collected_at": "2025-06-05 10:47:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}