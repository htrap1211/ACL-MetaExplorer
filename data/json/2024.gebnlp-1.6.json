{
  "id": "2024.gebnlp-1.6",
  "title": "On Shortcuts and Biases: How Finetuned Language Models Distinguish Audience-Specific Instructions in {I}talian and {E}nglish",
  "authors": [
    "Fanton, Nicola  and\nRoth, Michael"
  ],
  "year": "2024",
  "venue": "Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
  "abstract": "Instructional texts for different audience groups can help to address specific needs, but at the same time run the risk of perpetrating biases. In this paper, we extend previous findings on disparate social norms and subtle stereotypes in wikiHow in two directions: We explore the use of fine-tuned language models to determine how audience-specific instructional texts can be distinguished and we transfer the methodology to another language, Italian, to identify cross-linguistic patterns. We find that language models mostly rely on group terms, gender markings, and attributes reinforcing stereotypes.",
  "keywords": [
    "cross",
    "audience-specific instructional texts",
    "language",
    "how finetuned language models",
    "different audience groups",
    "audience",
    "language models",
    "fine-tuned language models",
    "we",
    "audience-specific instructions",
    "time",
    "perpetrating biases",
    "biases",
    "nglish",
    "social"
  ],
  "url": "https://aclanthology.org/2024.gebnlp-1.6/",
  "provenance": {
    "collected_at": "2025-06-05 11:06:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}