{
  "id": "2021.acl-short.68",
  "title": "Improving {A}rabic Diacritization with Regularized Decoding and Adversarial Training",
  "authors": [
    "Qin, Han  and\nChen, Guimin  and\nTian, Yuanhe  and\nSong, Yan"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Arabic diacritization is a fundamental task for Arabic language processing. Previous studies have demonstrated that automatically generated knowledge can be helpful to this task. However, these studies regard the auto-generated knowledge instances as gold references, which limits their effectiveness since such knowledge is not always accurate and inferior instances can lead to incorrect predictions. In this paper, we propose to use regularized decoding and adversarial training to appropriately learn from such noisy knowledge for diacritization. Experimental results on two benchmark datasets show that, even with quite flawed auto-generated knowledge, our model can still learn adequate diacritics and outperform all previous studies, on both datasets.",
  "keywords": [
    "knowledge",
    "previous studies",
    "language",
    "model",
    "all previous studies",
    "studies",
    "these studies",
    "the auto-generated knowledge instances",
    "we",
    "quite flawed auto-generated knowledge",
    "automatically generated knowledge",
    "training",
    "a fundamental task",
    "adequate diacritics",
    "helpful"
  ],
  "url": "https://aclanthology.org/2021.acl-short.68/",
  "provenance": {
    "collected_at": "2025-06-05 08:08:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}