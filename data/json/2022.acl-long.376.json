{
  "id": "2022.acl-long.376",
  "title": "Systematic Inequalities in Language Technology Performance across the World{'}s Languages",
  "authors": [
    "Blasi, Damian  and\nAnastasopoulos, Antonios  and\nNeubig, Graham"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world’s≈6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as foundational NLP tasks (dependency parsing, morphological inflection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies. Data and code to reproduce the findings discussed in this paper areavailable on GitHub (https://github.com/neubig/globalutility).",
  "keywords": [
    "code",
    "language technologies",
    "disparities",
    "field",
    "question",
    "we",
    "current",
    "translation",
    "natural",
    "the field",
    "nlp methods",
    "technologies",
    "systematic inequalities",
    "processing",
    "text"
  ],
  "url": "https://aclanthology.org/2022.acl-long.376/",
  "provenance": {
    "collected_at": "2025-06-05 08:29:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}