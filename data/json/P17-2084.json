{
  "id": "P17-2084",
  "title": "Salience Rank: Efficient Keyphrase Extraction with Topic Modeling",
  "authors": [
    "Teneva, Nedelina  and\nCheng, Weiwei"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Topical PageRank (TPR) uses latent topic distribution inferred by Latent Dirichlet Allocation (LDA) to perform ranking of noun phrases extracted from documents. The ranking procedure consists of running PageRank K times, where K is the number of topics used in the LDA model. In this paper, we propose a modification of TPR, called Salience Rank. Salience Rank only needs to run PageRank once and extracts comparable or better keyphrases on benchmark datasets. In addition to quality and efficiency benefit, our method has the flexibility to extract keyphrases with varying tradeoffs between topic specificity and corpus specificity.",
  "keywords": [
    "allocation",
    "salience rank salience rank",
    "extraction",
    "model",
    "lda",
    "efficient",
    "the lda model",
    "latent dirichlet allocation lda",
    "topic",
    "modeling",
    "latent",
    "salience",
    "k",
    "efficiency",
    "we"
  ],
  "url": "https://aclanthology.org/P17-2084/",
  "provenance": {
    "collected_at": "2025-06-05 00:04:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}