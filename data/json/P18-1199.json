{
  "id": "P18-1199",
  "title": "Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning",
  "authors": [
    "Qin, Pengda  and\nXu, Weiran  and\nWang, William Yang"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Distant supervision has become the standard method for relation extraction. However, even though it is an efficient method, it does not come at no cost—The resulted distantly-supervised training samples are often very noisy. To combat the noise, most of the recent state-of-the-art approaches focus on selecting one-best sentence or calculating soft attention weights over the set of the sentences of one specific entity pair. However, these methods are suboptimal, and the false positive problem is still a key stumbling bottleneck for the performance. We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights. To do this, our paper describes a radical solution—We explore a deep reinforcement learning strategy to generate the false-positive indicator, where we automatically recognize false positives for each relation type without any supervised information. Unlike the removal operation in the previous studies, we redistribute them into the negative examples. The experimental results show that the proposed strategy significantly improves the performance of distant supervision comparing to state-of-the-art systems.",
  "keywords": [
    "deep",
    "extraction",
    "efficient",
    "we",
    "an efficient method",
    "training",
    "it",
    "information",
    "learning",
    "soft",
    "the previous studies",
    "reinforcement",
    "studies",
    "soft attention weights",
    "attention"
  ],
  "url": "https://aclanthology.org/P18-1199/",
  "provenance": {
    "collected_at": "2025-06-05 00:14:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}