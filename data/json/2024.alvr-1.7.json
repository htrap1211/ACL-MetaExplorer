{
  "id": "2024.alvr-1.7",
  "title": "E}nglish-to-{J}apanese Multimodal Machine Translation Based on Image-Text Matching of Lecture Videos",
  "authors": [
    "Teramen, Ayu  and\nOhtsuka, Takumi  and\nKondo, Risa  and\nKajiwara, Tomoyuki  and\nNinomiya, Takashi"
  ],
  "year": "2024",
  "venue": "Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)",
  "abstract": "We work on a multimodal machine translation of the audio contained in English lecture videos to generate Japanese subtitles. Image-guided multimodal machine translation is promising for error correction in speech recognition and for text disambiguation. In our situation, lecture videos provide a variety of images. Images of presentation materials can complement information not available from audio and may help improve translation quality. However, images of speakers or audiences would not directly affect the translation quality. We construct a multimodal parallel corpus with automatic speech recognition text and multiple images for a transcribed parallel corpus of lecture videos, and propose a method to select the most relevant ones from the multiple images with the speech text for improving the performance of image-guided multimodal machine translation. Experimental results on translating automatic speech recognition or transcribed English text into Japanese show the effectiveness of our method to select a relevant image.",
  "keywords": [
    "variety",
    "translation",
    "machine",
    "text",
    "the translation quality",
    "information",
    "translation quality",
    "we",
    "a variety",
    "a multimodal machine translation",
    "audiences",
    "speech",
    "nglish",
    "speech recognition",
    "a relevant image"
  ],
  "url": "https://aclanthology.org/2024.alvr-1.7/",
  "provenance": {
    "collected_at": "2025-06-05 11:02:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}