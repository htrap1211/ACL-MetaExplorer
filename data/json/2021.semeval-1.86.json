{
  "id": "2021.semeval-1.86",
  "title": "B}ig{G}reen at {S}em{E}val-2021 Task 1: Lexical Complexity Prediction with Assembly Models",
  "authors": [
    "Islam, Aadil  and\nMa, Weicheng  and\nVosoughi, Soroush"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes a system submitted by team BigGreen to LCP 2021 for predicting the lexical complexity of English words in a given context. We assemble a feature engineering-based model with a deep neural network model founded on BERT. While BERT itself performs competitively, our feature engineering-based model helps in extreme cases, eg. separating instances of easy and neutral difficulty. Our handcrafted features comprise a breadth of lexical, semantic, syntactic, and novel phonological measures. Visualizations of BERT attention maps offer insight into potential features that Transformers models may learn when fine-tuned for lexical complexity prediction. Our ensembled predictions score reasonably well for the single word subtask, and we demonstrate how they can be harnessed to perform well on the multi word expression subtask too.",
  "keywords": [
    "deep",
    "visualizations",
    "transformers",
    "our ensembled predictions",
    "neural",
    "bert",
    "model",
    "transformers models",
    "semantic",
    "network",
    "we",
    "attention",
    "word",
    "g",
    "bert attention maps"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.86/",
  "provenance": {
    "collected_at": "2025-06-05 08:20:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}