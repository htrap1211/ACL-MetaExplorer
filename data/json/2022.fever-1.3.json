{
  "id": "2022.fever-1.3",
  "title": "Distilling Salient Reviews with Zero Labels",
  "authors": [
    "Huang, Chieh-Yang  and\nLi, Jinfeng  and\nBhutani, Nikita  and\nWhedon, Alexander  and\nHruschka, Estevam  and\nSuhara, Yoshi"
  ],
  "year": "2022",
  "venue": "Proceedings of the Fifth Fact Extraction and VERification Workshop (FEVER)",
  "abstract": "Many people read online reviews to learn about real-world entities of their interest. However, majority of reviews only describes general experiences and opinions of the customers, and may not reveal facts that are specific to the entity being reviewed. In this work, we focus on a novel task of mining from a review corpus sentences that are unique for each entity. We refer to this task as Salient Fact Extraction. Salient facts are extremely scarce due to their very nature. Consequently, collecting labeled examples for training supervised models is tedious and cost-prohibitive. To alleviate this scarcity problem, we develop an unsupervised method, ZL-Distiller, which leverages contextual language representations of the reviews and their distributional patterns to identify salient sentences about entities. Our experiments on multiple domains (hotels, products, and restaurants) show that ZL-Distiller achieves state-of-the-art performance and further boosts the performance of other supervised/unsupervised algorithms for the task. Furthermore, we show that salient sentences mined by ZL-Distiller provide unique and detailed information about entities, which benefit downstream NLP applications including question answering and summarization.",
  "keywords": [
    "extraction",
    "question",
    "salient sentences",
    "summarization",
    "we",
    "salient reviews",
    "training",
    "downstream nlp applications",
    "general experiences",
    "question answering",
    "information",
    "reviews",
    "answering",
    "-",
    "the reviews"
  ],
  "url": "https://aclanthology.org/2022.fever-1.3/",
  "provenance": {
    "collected_at": "2025-06-05 08:42:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}