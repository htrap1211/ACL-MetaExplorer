{
  "id": "2023.bea-1.59",
  "title": "Enhancing Educational Dialogues: A Reinforcement Learning Approach for Generating {AI} Teacher Responses",
  "authors": [
    "Huber, Thomas  and\nNiklaus, Christina  and\nHandschuh, Siegfried"
  ],
  "year": "2023",
  "venue": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
  "abstract": "Reinforcement Learning remains an underutilized method of training and fine-tuning Language Models (LMs) despite recent successes. This paper presents a simple approach of fine-tuning a language model with Reinforcement Learning to achieve competitive performance on the BEA 2023 Shared Task whose goal is to automatically generate teacher responses in educational dialogues. We utilized the novel NLPO algorithm that masks out tokens during generation to direct the model towards generations that maximize a reward function. We show results for both the t5-base model with 220 million parameters from the HuggingFace repository submitted to the leaderboard that, despite its comparatively small size, has achieved a good performance on both test and dev set, as well as GPT-2 with 124 million parameters. The presented results show that despite maximizing only one of the metrics used in the evaluation as a reward function our model scores highly in the other metrics as well.",
  "keywords": [
    "nlpo",
    "we",
    "training",
    "educational dialogues",
    "the novel nlpo algorithm",
    "learning",
    "the metrics",
    "a language model",
    "metrics",
    "generations",
    "a reinforcement learning approach",
    "fine",
    "function",
    "reinforcement",
    "generation"
  ],
  "url": "https://aclanthology.org/2023.bea-1.59/",
  "provenance": {
    "collected_at": "2025-06-05 10:22:02",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}