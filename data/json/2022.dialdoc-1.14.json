{
  "id": "2022.dialdoc-1.14",
  "title": "A Knowledge storage and semantic space alignment Method for Multi-documents dialogue generation",
  "authors": [
    "Zhu, Minjun  and\nLi, Bin  and\nWeng, Yixuan  and\nXia, Fei"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",
  "abstract": "Question Answering (QA) is a Natural Language Processing (NLP) task that can measure language and semantics understanding ability, it requires a system not only to retrieve relevant documents from a large number of articles but also to answer corresponding questions according to documents. However, various language styles and sources of human questions and evidence documents form the different embedding semantic spaces, which may bring some errors to the downstream QA task. To alleviate these problems, we propose a framework for enhancing downstream evidence retrieval by generating evidence, aiming at improving the performance of response generation. Specifically, we take the pre-training language model as a knowledge base, storing documentsâ€™ information and knowledge into model parameters. With the Child-Tuning approach being designed, the knowledge storage and evidence generation avoid catastrophic forgetting for response generation. Extensive experiments carried out on the multi-documents dataset show that the proposed method can improve the final performance, which demonstrates the effectiveness of the proposed framework.",
  "keywords": [
    "the downstream qa task",
    "question",
    "semantic",
    "we",
    "dialogue",
    "multi-documents dialogue generation question",
    "training",
    "semantic space alignment method",
    "natural",
    "semantics",
    "it",
    "retrieval",
    "response generation extensive experiments",
    "information",
    "the pre-training language model"
  ],
  "url": "https://aclanthology.org/2022.dialdoc-1.14/",
  "provenance": {
    "collected_at": "2025-06-05 08:41:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}