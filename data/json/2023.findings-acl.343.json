{
  "id": "2023.findings-acl.343",
  "title": "Language Anisotropic Cross-Lingual Model Editing",
  "authors": [
    "Xu, Yang  and\nHou, Yutai  and\nChe, Wanxiang  and\nZhang, Min"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Multilingual pre-trained language models can learn task-specific abilities or memorize facts across multiple languages but inevitably make undesired predictions with specific inputs. Under similar observation, model editing aims to post-hoc calibrate a model targeted to specific inputs with keeping the modelâ€™s raw behavior. However, existing work only studies the monolingual scenario, which lacks the cross-lingual transferability to perform editing simultaneously across languages. In this work, we focus on cross-lingual model editing. Firstly, we define the cross-lingual model editing task and corresponding metrics, where an edit in one language propagates to the others. Next, we propose a framework to naturally adapt monolingual model editing approaches to the cross-lingual scenario using parallel corpus. Further, we propose language anisotropic editing to improve cross-lingual editing by amplifying different subsets of parameters for each language. On the newly defined cross-lingual model editing task, we empirically demonstrate the failure of monolingual baselines in propagating the edit to multiple languages and the effectiveness of the proposed language anisotropic model editing. Our code is publicly available athttps://github.com/franklear/LiME.",
  "keywords": [
    "code",
    "corresponding metrics",
    "we",
    "cross",
    "multilingual pre-trained language models",
    "abilities",
    "metrics",
    "task-specific abilities",
    "work",
    "language",
    "model",
    "pre",
    "franklear",
    "scenario",
    "monolingual model"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.343/",
  "provenance": {
    "collected_at": "2025-06-05 09:58:04",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}