{
  "id": "W19-4307",
  "title": "M}o{RT}y: Unsupervised Learning of Task-specialized Word Embeddings by Autoencoding",
  "authors": [
    "Rethmeier, Nils  and\nPlank, Barbara"
  ],
  "year": "2019",
  "venue": "Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)",
  "abstract": "Word embeddings have undoubtedly revolutionized NLP. However, pretrained embeddings do not always work for a specific task (or set of tasks), particularly in limited resource setups. We introduce a simple yet effective, self-supervised post-processing method that constructs task-specialized word representations by picking from a menu of reconstructing transformations to yield improved end-task performance (MORTY). The method is complementary to recent state-of-the-art approaches to inductive transfer via fine-tuning, and forgoes costly model architectures and annotation. We evaluate MORTY on a broad range of setups, including different word embedding methods, corpus sizes and end-task semantics. Finally, we provide a surprisingly simple recipe to obtain specialized embeddings that better fit end-tasks.",
  "keywords": [
    "embeddings",
    "tuning",
    "processing",
    "end",
    "nlp",
    "model",
    "end-task semantics",
    "semantics",
    "fit",
    "self",
    "specialized embeddings",
    "task-specialized word embeddings",
    "word",
    "we",
    "learning"
  ],
  "url": "https://aclanthology.org/W19-4307/",
  "provenance": {
    "collected_at": "2025-06-05 01:02:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}