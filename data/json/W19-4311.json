{
  "id": "W19-4311",
  "title": "Composing Noun Phrase Vector Representations",
  "authors": [
    "Kalouli, Aikaterini-Lida  and\nde Paiva, Valeria  and\nCrouch, Richard"
  ],
  "year": "2019",
  "venue": "Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)",
  "abstract": "Vector representations of words have seen an increasing success over the past years in a variety of NLP tasks. While there seems to be a consensus about the usefulness of word embeddings and how to learn them, it is still unclear which representations can capture the meaning of phrases or even whole sentences. Recent work has shown that simple operations outperform more complex deep architectures. In this work, we propose two novel constraints for computing noun phrase vector representations. First, we propose that the semantic and not the syntactic contribution of each component of a noun phrase should be considered, so that the resulting composed vectors express more of the phrase meaning. Second, the composition process of the two phrase vectors should apply suitable dimensions’ selection in a way that specific semantic features captured by the phrase’s meaning become more salient. Our proposed methods are compared to 11 other approaches, including popular baselines and a neural net architecture, and are evaluated across 6 tasks and 2 datasets. Our results show that these constraints lead to more expressive phrase representations and can be applied to other state-of-the-art methods to improve their performance.",
  "keywords": [
    "deep",
    "variety",
    "semantic",
    "we",
    "neural",
    "net",
    "it",
    "specific semantic features",
    "word",
    "a variety",
    "nlp tasks",
    "the two phrase vectors",
    "vector",
    "more salient",
    "word embeddings"
  ],
  "url": "https://aclanthology.org/W19-4311/",
  "provenance": {
    "collected_at": "2025-06-05 01:02:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}