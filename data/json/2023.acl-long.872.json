{
  "id": "2023.acl-long.872",
  "title": "U}nit{Y}: Two-pass Direct Speech-to-speech Translation with Discrete Units",
  "authors": [
    "Inaguma, Hirofumi  and\nPopuri, Sravya  and\nKulikov, Ilia  and\nChen, Peng-Jen  and\nWang, Changhan  and\nChung, Yu-An  and\nTang, Yun  and\nLee, Ann  and\nWatanabe, Shinji  and\nPino, Juan"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Direct speech-to-speech translation (S2ST), in which all components can be optimized jointly, is advantageous over cascaded approaches to achieve fast inference with a simplified pipeline. We present a novel two-pass direct S2ST architecture, UnitY, which first generates textual representations and predicts discrete acoustic units subsequently. We enhance the model performance by subword prediction in the first-pass decoder, advanced two-pass decoder architecture design and search strategy, and better training regularization. To leverage large amounts of unlabeled text data, we pre-train the first-pass text decoder based on the self-supervised denoising auto-encoding task. Experimental evaluations on benchmark datasets at various data scales demonstrate that UnitY outperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up. We show that the proposed methods boost the performance even when predicting spectrogram in the second pass. However, predicting discrete units achieves 2.51x decoding speed-up compared to that case.",
  "keywords": [
    "bleu",
    "we",
    "training",
    "translation",
    "self",
    "decoder",
    "u",
    "asr-bleu",
    "two-pass decoder architecture design",
    "text",
    "the first-pass decoder",
    "simplified",
    "fast",
    "a simplified pipeline",
    "model"
  ],
  "url": "https://aclanthology.org/2023.acl-long.872/",
  "provenance": {
    "collected_at": "2025-06-05 09:47:37",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}