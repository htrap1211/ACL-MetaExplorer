{
  "id": "2023.findings-acl.23",
  "title": "$G^3R$: A Graph-Guided Generate-and-Rerank Framework for Complex and Cross-domain Text-to-{SQL} Generation",
  "authors": [
    "Xiang, Yanzheng  and\nZhang, Qian-Wen  and\nZhang, Xu  and\nLiu, Zejie  and\nCao, Yunbo  and\nZhou, Deyu"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "We present a framework called G3R for complex and cross-domain Text-to-SQL generation. G3R aims to address two limitations of current approaches: (1) The structure of the abstract syntax tree (AST) is not fully explored during the decoding process which is crucial for complex SQL generation; (2) Domain knowledge is not incorporated to enhance their ability to generalise to unseen domains. G3R consists of a graph-guided SQL generator and a knowledge-enhanced re-ranking mechanism. Firstly, during the decoding process, An AST-Grammar bipartite graph is constructed for both the AST and corresponding grammar rules of the generated partial SQL query. The graph-guided SQL generator captures its structural information and fuses heterogeneous information to predict the action sequence which can construct the AST for the corresponding SQL query uniquely. Then, in the inference stage, a knowledge-enhanced re-ranking mechanism is proposed to introduce domain knowledge to re-rank candidate SQL queries from the beam output and choose the final answer. The SQL ranker is based on pre-trained language models (PLM) and contrastive learning with hybrid prompt tuning is incorporated to stimulate the knowledge of PLMs and make it more discriminative. The proposed approach achieves state-of-the-art results on the Spider and Spider-DK benchmarks, which are challenging complex and cross-domain benchmarks for Text-to-SQL semantic analysis.",
  "keywords": [
    "ast",
    "semantic",
    "we",
    "hybrid prompt tuning",
    "graph",
    "syntax",
    "current",
    "cross",
    "answer",
    "it",
    "pre-trained language models plm",
    "information",
    "sequence",
    "learning",
    "analysis"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.23/",
  "provenance": {
    "collected_at": "2025-06-05 09:53:31",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}