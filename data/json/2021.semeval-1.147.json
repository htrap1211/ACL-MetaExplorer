{
  "id": "2021.semeval-1.147",
  "title": "NLPIITR} at {S}em{E}val-2021 Task 6: {R}o{BERT}a Model with Data Augmentation for Persuasion Techniques Detection",
  "authors": [
    "Gupta, Vansh  and\nSharma, Raksha"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes and examines different systems to address Task 6 of SemEval-2021: Detection of Persuasion Techniques In Texts And Images, Subtask 1. The task aims to build a model for identifying rhetorical and psycho- logical techniques (such as causal oversimplification, name-calling, smear) in the textual content of a meme which is often used in a disinformation campaign to influence the users. The paper provides an extensive comparison among various machine learning systems as a solution to the task. We elaborate on the pre-processing of the text data in favor of the task and present ways to overcome the class imbalance. The results show that fine-tuning a RoBERTa model gave the best results with an F1-Micro score of 0.51 on the development set.",
  "keywords": [
    "roberta",
    "an f1-micro score",
    "we",
    "a roberta model",
    "nlpiitr",
    "processing",
    "bert",
    "various machine learning systems",
    "text",
    "6 r o bert",
    "-",
    "fine",
    "model",
    "machine",
    "class"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.147/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:43",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}