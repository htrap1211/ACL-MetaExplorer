{
  "id": "2023.iwslt-1.42",
  "title": "NVIDIA} {N}e{M}o Offline Speech Translation Systems for {IWSLT} 2023",
  "authors": [
    "Hrinchuk, Oleksii  and\nBataev, Vladimir  and\nBakhturina, Evelina  and\nGinsburg, Boris"
  ],
  "year": "2023",
  "venue": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
  "abstract": "This paper provides an overview of NVIDIA NeMoâ€™s speech translation systems for the IWSLT 2023 Offline Speech Translation Task. This year, we focused on end-to-end system which capitalizes on pre-trained models and synthetic data to mitigate the problem of direct speech translation data scarcity. When trained on IWSLT 2022 constrained data, our best En->De end-to-end model achieves the average score of 31 BLEU on 7 test sets from IWSLT 2010-2020 which improves over our last year cascade (28.4) and end-to-end (25.7) submissions. When trained on IWSLT 2023 constrained data, the average score drops to 29.5 BLEU.",
  "keywords": [
    "end",
    "n",
    "model",
    "29 5 bleu",
    "an overview",
    "bleu",
    "31 bleu",
    "overview",
    "we",
    "pre",
    "translation",
    "speech",
    "our last year",
    "task",
    "the problem"
  ],
  "url": "https://aclanthology.org/2023.iwslt-1.42/",
  "provenance": {
    "collected_at": "2025-06-05 10:25:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}