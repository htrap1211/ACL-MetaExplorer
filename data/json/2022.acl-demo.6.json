{
  "id": "2022.acl-demo.6",
  "title": "A}dapter{H}ub Playground: Simple and Flexible Few-Shot Learning with Adapters",
  "authors": [
    "Beck, Tilman  and\nBohlender, Bela  and\nViehmann, Christina  and\nHane, Vincent  and\nAdamson, Yanik  and\nKhuri, Jaber  and\nBrossmann, Jonas  and\nPfeiffer, Jonas  and\nGurevych, Iryna"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "The open-access dissemination of pretrained language models through online repositories has led to a democratization of state-of-the-art natural language processing (NLP) research. This also allows people outside of NLP to use such models and adapt them to specific use-cases. However, a certain amount of technical proficiency is still required which is an entry barrier for users who want to apply these models to a certain task but lack the necessary knowledge or resources. In this work, we aim to overcome this gap by providing a tool which allows researchers to leverage pretrained models without writing a single line of code. Built upon the parameter-efficient adapter modules for transfer learning, our AdapterHub Playground provides an intuitive interface, allowing the usage of adapters for prediction, training and analysis of textual data for a variety of NLP tasks. We present the toolâ€™s architecture and demonstrate its advantages with prototypical use-cases, where we show that predictive performance can easily be increased in a few-shot learning scenario. Finally, we evaluate its usability in a user study. We provide the code and a live interface athttps://adapter-hub.github.io/playground.",
  "keywords": [
    "online repositories",
    "variety",
    "code",
    "a few-shot learning scenario",
    "efficient",
    "we",
    "shot",
    "barrier",
    "parameter",
    "training",
    "repositories",
    "natural",
    "an entry barrier",
    "learning",
    "transfer"
  ],
  "url": "https://aclanthology.org/2022.acl-demo.6/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:23",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}