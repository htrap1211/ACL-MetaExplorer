{
  "id": "2024.acl-long.470",
  "title": "RAVEL}: Evaluating Interpretability Methods on Disentangling Language Model Representations",
  "authors": [
    "Huang, Jing  and\nWu, Zhengxuan  and\nPotts, Christopher  and\nGeva, Mor  and\nGeiger, Atticus"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Individual neurons participate in the representation of multiple high-level concepts. To what extent can different interpretability methods successfully disentangle these roles? To help address this question, we introduce RAVEL (Resolving Attribute-Value Entanglements in Language Models), a dataset that enables tightly controlled, quantitative comparisons between a variety of existing interpretability methods. We use the resulting conceptual framework to define the new method of Multi-task Distributed Alignment Search (MDAS), which allows us to find distributed representations satisfying multiple causal criteria. With Llama2-7B as the target language model, MDAS achieves state-of-the-art results on RAVEL, demonstrating the importance of going beyond neuron-level analyses to identify features distributed across activations. We release our benchmark at https://github.com/explanare/ravel.",
  "keywords": [
    "variety",
    "question",
    "we",
    "activations",
    "a variety",
    "the target language model",
    "language models",
    "language model representations",
    "alignment",
    "language",
    "model",
    "us",
    "multi",
    "explanare",
    "state"
  ],
  "url": "https://aclanthology.org/2024.acl-long.470/",
  "provenance": {
    "collected_at": "2025-06-05 10:40:46",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}