{
  "id": "2023.acl-long.770",
  "title": "Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation",
  "authors": [
    "Guerreiro, Nuno M.  and\nColombo, Pierre  and\nPiantanida, Pablo  and\nMartins, Andr{\\'e}"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Neural machine translation (NMT) has become the de-facto standard in real-world machine translation applications. However, NMT models can unpredictably produce severely pathological translations, known as hallucinations, that seriously undermine user trust. It becomes thus crucial to implement effective preventive strategies to guarantee their proper functioning. In this paper, we address the problem of hallucination detection in NMT by following a simple intuition: as hallucinations are detached from the source content, they exhibit encoder-decoder attention patterns that are statistically different from those of good quality translations. We frame this problem with an optimal transport formulation and propose a fully unsupervised, plug-in detector that can be used with any attention-based NMT model. Experimental results show that our detector not only outperforms all previous model-based detectors, but is also competitive with detectors that employ external models trained on millions of samples for related tasks such as quality estimation and cross-lingual sentence similarity.",
  "keywords": [
    "we",
    "effective preventive strategies",
    "translation",
    "cross",
    "neural",
    "it",
    "decoder",
    "good quality translations",
    "encoder-decoder attention patterns",
    "strategies",
    "real-world machine translation applications",
    "severely pathological translations",
    "model",
    "machine",
    "encoder"
  ],
  "url": "https://aclanthology.org/2023.acl-long.770/",
  "provenance": {
    "collected_at": "2025-06-05 09:46:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}