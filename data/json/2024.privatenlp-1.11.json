{
  "id": "2024.privatenlp-1.11",
  "title": "Smart Lexical Search for Label Flipping Adversial Attack",
  "authors": [
    "Guti{\\'e}rrez-Meg{\\'i}as, Alberto  and\nJim{\\'e}nez-Zafra, Salud Mar{\\'i}a  and\nUre{\\~n}a, L. Alfonso  and\nMart{\\'i}nez-C{\\'a}mara, Eugenio"
  ],
  "year": "2024",
  "venue": "Proceedings of the Fifth Workshop on Privacy in Natural Language Processing",
  "abstract": "Language models are susceptible to vulnerability through adversarial attacks, using manipulations of the input data to disrupt their performance. Accordingly, it represents a cibersecurity leak. Data manipulations are intended to be unidentifiable by the learning model and by humans, small changes can disturb the final label of a classification task. Hence, we propose a novel attack built upon explainability methods to identify the salient lexical units to alter in order to flip the classification label. We asses our proposal on a disinformation dataset, and we show that our attack reaches high balance among stealthiness and efficiency.",
  "keywords": [
    "language",
    "a classification task",
    "model",
    "it",
    "salient",
    "the classification label",
    "the salient lexical units",
    "efficiency",
    "we",
    "vulnerability",
    "classification",
    "the final label",
    "a novel attack",
    "susceptible",
    "task"
  ],
  "url": "https://aclanthology.org/2024.privatenlp-1.11/",
  "provenance": {
    "collected_at": "2025-06-05 11:09:09",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}