{
  "id": "2024.findings-acl.490",
  "title": "Deciphering Digital Detectives: Understanding {LLM} Behaviors and Capabilities in Multi-Agent Mystery Games",
  "authors": [
    "Wu, Dekun  and\nShi, Haochen  and\nSun, Zhiyuan  and\nLiu, Bang"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "In this study, we explore the application of Large Language Models (LLMs) in Jubensha, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in Jubensha games. To evaluate the gaming performance of these AI agents, we developed novel methods measuring their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in prompting engineering to enhance the agentsâ€™ performance in information gathering, murderer identification, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a novel perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents.",
  "keywords": [
    "we",
    "llm",
    "llm capabilities",
    "information",
    "llms",
    "work",
    "language",
    "model",
    "capabilities",
    "llm behaviors",
    "large language model-based agents",
    "area",
    "multi",
    "engineering",
    "interaction"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.490/",
  "provenance": {
    "collected_at": "2025-06-05 10:55:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}