{
  "id": "2020.acl-main.222",
  "title": "The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents",
  "authors": [
    "Shuster, Kurt  and\nJu, Da  and\nRoller, Stephen  and\nDinan, Emily  and\nBoureau, Y-Lan  and\nWeston, Jason"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "We introduce dodecaDialogue: a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad large-scale set of data, we hope to both move towards and measure progress in producing a single unified agent that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking improves over a BERT pre-trained baseline, largely due to multi-tasking with very large dialogue datasets in a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the fine-tune and task transfer settings. We obtain state-of-the-art results on many of the tasks, providing a strong baseline for this challenge.",
  "keywords": [
    "general",
    "knowledge",
    "answer",
    "very large dialogue datasets",
    "bert",
    "text",
    "metrics",
    "a single unified agent",
    "unified",
    "conversational",
    "fine",
    "a conversational agent",
    "dodecadialogue",
    "we",
    "transfer"
  ],
  "url": "https://aclanthology.org/2020.acl-main.222/",
  "provenance": {
    "collected_at": "2025-06-05 07:45:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}