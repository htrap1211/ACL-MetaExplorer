{
  "id": "2020.acl-main.441",
  "title": "Adversarial {NLI}: A New Benchmark for Natural Language Understanding",
  "authors": [
    "Nie, Yixin  and\nWilliams, Adina  and\nDinan, Emily  and\nBansal, Mohit  and\nWeston, Jason  and\nKiela, Douwe"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.",
  "keywords": [
    "variety",
    "language",
    "natural",
    "model",
    "human",
    "we",
    "a variety",
    "current",
    "analysis",
    "training",
    "that",
    "scenario",
    "popular nli benchmarks",
    "training models",
    "the-art"
  ],
  "url": "https://aclanthology.org/2020.acl-main.441/",
  "provenance": {
    "collected_at": "2025-06-05 07:48:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}