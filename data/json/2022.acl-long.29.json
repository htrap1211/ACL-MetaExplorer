{
  "id": "2022.acl-long.29",
  "title": "Hypergraph {T}ransformer: {W}eakly-Supervised Multi-hop Reasoning for Knowledge-based Visual Question Answering",
  "authors": [
    "Heo, Yu-Jung  and\nKim, Eun-Sol  and\nChoi, Woo Suk  and\nZhang, Byoung-Tak"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Knowledge-based visual question answering (QA) aims to answer a question which requires visually-grounded external knowledge beyond image content itself. Answering complex questions that require multi-hop reasoning under weak supervision is considered as a challenging problem since i) no supervision is given to the reasoning process and ii) high-order semantics of multi-hop knowledge facts need to be captured. In this paper, we introduce a concept of hypergraph to encode high-level semantics of a question and a knowledge base, and to learn high-order associations between them. The proposed model, Hypergraph Transformer, constructs a question hypergraph and a query-aware knowledge hypergraph, and infers an answer by encoding inter-associations between two hypergraphs and intra-associations in both hypergraph itself. Extensive experiments on two knowledge-based visual QA and two knowledge-based textual QA demonstrate the effectiveness of our method, especially for multi-hop reasoning problem. Our source code is available athttps://github.com/yujungheo/kbvqa-public.",
  "keywords": [
    "code",
    "encode",
    "question",
    "two knowledge-based visual qa",
    "we",
    "answer",
    "semantics",
    "ransformer",
    "visual",
    "two knowledge-based textual qa",
    "i",
    "-",
    "com yujungheo kbvqa",
    "ii high-order semantics",
    "transformer"
  ],
  "url": "https://aclanthology.org/2022.acl-long.29/",
  "provenance": {
    "collected_at": "2025-06-05 08:24:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}