{
  "id": "2023.findings-acl.749",
  "title": "Race, Gender, and Age Biases in Biomedical Masked Language Models",
  "authors": [
    "Kim, Michelle  and\nKim, Junghwan  and\nJohnson, Kristen"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Biases cause discrepancies in healthcare services. Race, gender, and age of a patient affect interactions with physicians and the medical treatments one receives. These biases in clinical practices can be amplified following the release of pre-trained language models trained on biomedical corpora. To bring awareness to such repercussions, we examine social biases present in the biomedical masked language models. We curate prompts based on evidence-based practice and compare generated diagnoses based on biases. For a case study, we measure bias in diagnosing coronary artery disease and using cardiovascular procedures based on bias. Our study demonstrates that biomedical models are less biased than BERT in gender, while the opposite is true for race and age.",
  "keywords": [
    "prompts",
    "a patient",
    "bias",
    "language",
    "these biases",
    "pre-trained language models",
    "bert",
    "social biases",
    "biomedical masked language models",
    "discrepancies",
    "patient",
    "we",
    "age biases",
    "age",
    "pre"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.749/",
  "provenance": {
    "collected_at": "2025-06-05 10:18:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}