{
  "id": "2022.findings-acl.256",
  "title": "Encoding and Fusing Semantic Connection and Linguistic Evidence for Implicit Discourse Relation Recognition",
  "authors": [
    "Xiang, Wei  and\nWang, Bang  and\nDai, Lu  and\nMo, Yijun"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Prior studies use one attention mechanism to improve contextual semantic representation learning for implicit discourse relation recognition (IDRR). However, diverse relation senses may benefit from different attention mechanisms. We also argue that some linguistic relation in between two words can be further exploited for IDRR. This paper proposes a Multi-Attentive Neural Fusion (MANF) model to encode and fuse both semantic connection and linguistic evidence for IDRR. In MANF, we design a Dual Attention Network (DAN) to learn and fuse two kinds of attentive representation for arguments as its semantic connection. We also propose an Offset Matrix Network (OMN) to encode the linguistic relations of word-pairs as linguistic evidence. Our MANF model achieves the state-of-the-art results on the PDTB 3.0 corpus.",
  "keywords": [
    "one attention mechanism",
    "both semantic connection",
    "different attention mechanisms",
    "neural",
    "model",
    "studies",
    "prior studies",
    "semantic connection",
    "contextual semantic representation learning",
    "semantic",
    "attention",
    "network",
    "we",
    "learning",
    "word"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.256/",
  "provenance": {
    "collected_at": "2025-06-05 08:38:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}