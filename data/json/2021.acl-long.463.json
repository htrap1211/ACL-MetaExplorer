{
  "id": "2021.acl-long.463",
  "title": "Automatic {ICD} Coding via Interactive Shared Representation Networks with Self-distillation Mechanism",
  "authors": [
    "Zhou, Tong  and\nCao, Pengfei  and\nChen, Yubo  and\nLiu, Kang  and\nZhao, Jun  and\nNiu, Kun  and\nChong, Weifeng  and\nLiu, Shengping"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "The ICD coding task aims at assigning codes of the International Classification of Diseases in clinical notes. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, existing works either ignore the long-tail of code frequency or the noisy clinical notes. To address the above issues, we propose an Interactive Shared Representation Network with Self-Distillation Mechanism. Specifically, an interactive shared representation network targets building connections among codes while modeling the co-occurrence, consequently alleviating the long-tail problem. Moreover, to cope with the noisy text issue, we encourage the model to focus on the clinical noteâ€™s noteworthy part and extract valuable information through a self-distillation learning mechanism. Experimental results on two MIMIC datasets demonstrate the effectiveness of our method.",
  "keywords": [
    "code",
    "model",
    "text",
    "self",
    "the international classification",
    "-",
    "information",
    "network",
    "we",
    "learning",
    "classification",
    "occurrence",
    "clinical notes",
    "targets",
    "noteworthy"
  ],
  "url": "https://aclanthology.org/2021.acl-long.463/",
  "provenance": {
    "collected_at": "2025-06-05 08:05:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}