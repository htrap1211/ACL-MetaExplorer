{
  "id": "2021.acl-long.362",
  "title": "A}da{T}ag: Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding",
  "authors": [
    "Yan, Jun  and\nZalmout, Nasser  and\nLiang, Yan  and\nGrant, Christan  and\nRen, Xiang  and\nDong, Xin Luna"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Automatic extraction of product attribute values is an important enabling technology in e-Commerce platforms. This task is usually modeled using sequence labeling architectures, with several extensions to handle multi-attribute extraction. One line of previous work constructs attribute-specific models, through separate decoders or entirely separate models. However, this approach constrains knowledge sharing across different attributes. Other contributions use a single multi-attribute model, with different techniques to embed attribute information. But sharing the entire network parameters across all attributes can limit the modelâ€™s capacity to capture attribute-specific characteristics. In this paper we present AdaTag, which uses adaptive decoding to handle extraction. We parameterize the decoder with pretrained attribute embeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This allows for separate, but semantically correlated, decoders to be generated on the fly for different attributes. This approach facilitates knowledge sharing, while maintaining the specificity of each attribute. Our experiments on a real-world e-Commerce dataset show marked improvements over previous methods.",
  "keywords": [
    "separate decoders",
    "extraction",
    "the decoder",
    "we",
    "decoder",
    "pretrained attribute embeddings",
    "information",
    "decoders",
    "sequence",
    "work",
    "embeddings",
    "knowledge",
    "model",
    "network",
    "multi"
  ],
  "url": "https://aclanthology.org/2021.acl-long.362/",
  "provenance": {
    "collected_at": "2025-06-05 08:04:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}