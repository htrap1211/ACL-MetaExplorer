{
  "id": "2021.case-1.11",
  "title": "Multilingual Protest News Detection - Shared Task 1, {CASE} 2021",
  "authors": [
    "H{\\\"u}rriyeto{\\u{g}}lu, Ali  and\nMutlu, Osman  and\nY{\\\"o}r{\\\"u}k, Erdem  and\nLiza, Farhana Ferdousi  and\nKumar, Ritesh  and\nRatan, Shyam"
  ],
  "year": "2021",
  "venue": "Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)",
  "abstract": "Benchmarking state-of-the-art text classification and information extraction systems in multilingual, cross-lingual, few-shot, and zero-shot settings for socio-political event information collection is achieved in the scope of the shared task Socio-political and Crisis Events Detection at the workshop CASE @ ACL-IJCNLP 2021. Socio-political event data is utilized for national and international policy- and decision-making. Therefore, the reliability and validity of these datasets are of the utmost importance. We split the shared task into three parts to address the three aspects of data collection (Task 1), fine-grained semantic classification (Task 2), and evaluation (Task 3). Task 1, which is the focus of this report, is on multilingual protest news detection and comprises four subtasks that are document classification (subtask 1), sentence classification (subtask 2), event sentence coreference identification (subtask 3), and event extraction (subtask 4). All subtasks had English, Portuguese, and Spanish for both training and evaluation data. Data in Hindi language was available only for the evaluation of subtask 1. The majority of the submissions, which are 238 in total, are created using multi- and cross-lingual approaches. Best scores are above 77.27 F1-macro for subtask 1, above 85.32 F1-macro for subtask 2, above 84.23 CoNLL 2012 average score for subtask 3, and above 66.20 F1-macro for subtask 4 in all evaluation settings. The performance of the best system for subtask 4 is above 66.20 F1 for all available languages. Although there is still a significant room for improvement in cross-lingual and zero-shot settings, the best submissions for each evaluation scenario yield remarkable results. Monolingual models outperformed the multilingual models in a few evaluation scenarios.",
  "keywords": [
    "extraction",
    "evaluation task",
    "document classification subtask",
    "semantic",
    "we",
    "shot",
    "training",
    "classification",
    "cross",
    "information",
    "all evaluation settings",
    "text",
    "66 20 f1",
    "85 32 f1-macro",
    "ijcnlp"
  ],
  "url": "https://aclanthology.org/2021.case-1.11/",
  "provenance": {
    "collected_at": "2025-06-05 08:16:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}