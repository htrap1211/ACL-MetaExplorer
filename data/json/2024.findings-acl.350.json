{
  "id": "2024.findings-acl.350",
  "title": "LJPC}heck: Functional Tests for Legal Judgment Prediction",
  "authors": [
    "Zhang, Yuan  and\nHuang, Wanhong  and\nFeng, Yi  and\nLi, Chuanyi  and\nFei, Zhiwei  and\nGe, Jidong  and\nLuo, Bin  and\nNg, Vincent"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Legal Judgment Prediction (LJP) refers to the task of automatically predicting judgment results (e.g., charges, law articles and term of penalty) given the fact description of cases. While SOTA models have achieved high accuracy and F1 scores on public datasets, existing datasets fail to evaluate specific aspects of these models (e.g., legal fairness, which significantly impact their applications in real scenarios). Inspired by functional testing in software engineering, we introduce LJPCHECK, a suite of functional tests for LJP models, to comprehend LJP modelsâ€™ behaviors and offer diagnostic insights. We illustrate the utility of LJPCHECK on five SOTA LJP models. Extensive experiments reveal vulnerabilities in these models, prompting an in-depth discussion into the underlying reasons of their shortcomings.",
  "keywords": [
    "e g",
    "we",
    "vulnerabilities",
    "accuracy",
    "term",
    "applications",
    "five sota ljp models",
    "legal judgment prediction ljp",
    "behaviors",
    "insights",
    "functional testing",
    "ljp models behaviors",
    "task",
    "ljp models",
    "engineering"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.350/",
  "provenance": {
    "collected_at": "2025-06-05 10:53:23",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}