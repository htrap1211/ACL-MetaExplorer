{
  "id": "2023.semeval-1.180",
  "title": "Nonet at {S}em{E}val-2023 Task 6: Methodologies for Legal Evaluation",
  "authors": [
    "Nigam, Shubham Kumar  and\nDeroy, Aniket  and\nShallum, Noel  and\nMishra, Ayush Kumar  and\nRoy, Anup  and\nMishra, Shubham Kumar  and\nBhattacharya, Arnab  and\nGhosh, Saptarshi  and\nGhosh, Kripabandhu"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "This paper describes our submission to the SemEval-2023 for Task 6 on LegalEval: Understanding Legal Texts. Our submission concentrated on three subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation (CJPE) for Task-C2. We conducted various experiments on these subtasks and presented the results in detail, including data statistics and methodology. It is worth noting that legal tasks, such as those tackled in this research, have been gaining importance due to the increasing need to automate legal analysis and support. Our team obtained competitive rankings of 15th, 11th, and 1st in Task-B, Task-C1, and Task-C2, respectively, as reported on the leaderboard.",
  "keywords": [
    "ner",
    "legal evaluation",
    "methodologies",
    "it",
    "6 methodologies",
    "we",
    "evaluation",
    "entity",
    "analysis",
    "recognition",
    "legal judgment prediction ljp",
    "competitive rankings",
    "15th 11th",
    "this research",
    "task-b"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.180/",
  "provenance": {
    "collected_at": "2025-06-05 10:29:04",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}