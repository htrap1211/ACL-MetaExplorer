{
  "id": "2024.iwslt-1.21",
  "title": "HW}-{TSC}{'}s Submissions To the {IWSLT}2024 Low-resource Speech Translation Tasks",
  "authors": [
    "Jiawei, Zheng  and\nShang, Hengchao  and\nLi, Zongyao  and\nWu, Zhanglin  and\nWei, Daimeng  and\nRao, Zhiqiang  and\nLi, Shaojun  and\nGuo, Jiaxin  and\nWei, Bin  and\nLuo, Yuanchang  and\nYang, Hao"
  ],
  "year": "2024",
  "venue": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
  "abstract": "In this work, we submitted our systems to the low-resource track of the IWSLT 2024 Speech Translation Campaign. Our systems tackled the unconstrained condition of the Dialectal Arabic North Levantine (ISO-3 code: apc) to English language pair. We proposed a cascaded solution consisting of an automatic speech recognition (ASR) model and a machine translation (MT) model. It was noted that the ASR model employed the pre-trained Whisper-large-v3 model to process the speech data, while the MT model adopted the Transformer architecture. To improve the quality of the MT model, it was stated that our system utilized not only the data provided by the competition but also an additional 54 million parallel sentences. Ultimately, we reported that our final system achieved a BLEU score of 24.7 for apc-to-English translation.",
  "keywords": [
    "work",
    "code",
    "transformer",
    "language",
    "a bleu score",
    "model",
    "machine",
    "it",
    "apc-to-english translation",
    "bleu",
    "we",
    "pre",
    "the transformer architecture",
    "a machine translation",
    "translation"
  ],
  "url": "https://aclanthology.org/2024.iwslt-1.21/",
  "provenance": {
    "collected_at": "2025-06-05 11:06:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}