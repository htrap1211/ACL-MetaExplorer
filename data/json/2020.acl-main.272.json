{
  "id": "2020.acl-main.272",
  "title": "Zero-shot Text Classification via Reinforced Self-training",
  "authors": [
    "Ye, Zhiquan  and\nGeng, Yuxia  and\nChen, Jiaoyan  and\nChen, Jingmin  and\nXu, Xiaoxiao  and\nZheng, SuHang  and\nWang, Feng  and\nZhang, Jun  and\nChen, Huajun"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Zero-shot learning has been a tough problem since no labeled data is available for unseen classes during training, especially for classes with low similarity. In this situation, transferring from seen classes to unseen classes is extremely hard. To tackle this problem, in this paper we propose a self-training based method to efficiently leverage unlabeled data. Traditional self-training methods use fixed heuristics to select instances from unlabeled data, whose performance varies among different datasets. We propose a reinforcement learning framework to learn data selection strategy automatically and provide more reliable selection. Experimental results on both benchmarks and a real-world e-commerce dataset show that our approach significantly outperforms previous methods in zero-shot text classification",
  "keywords": [
    "reinforcement",
    "reinforced self-training zero-shot learning",
    "text",
    "self",
    "a reinforcement learning framework",
    "zero-shot text classification",
    "we",
    "learning",
    "shot",
    "training",
    "classification",
    "strategy",
    "traditional",
    "approach",
    "situation"
  ],
  "url": "https://aclanthology.org/2020.acl-main.272/",
  "provenance": {
    "collected_at": "2025-06-05 07:45:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}