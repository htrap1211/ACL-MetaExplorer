{
  "id": "P19-1608",
  "title": "Large-Scale Transfer Learning for Natural Language Generation",
  "authors": [
    "Golovanov, Sergey  and\nKurbanov, Rauf  and\nNikolenko, Sergey  and\nTruskovskyi, Kyryl  and\nTselousov, Alexander  and\nWolf, Thomas"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Large-scale pretrained language models define state of the art in natural language processing, achieving outstanding performance on a variety of tasks. We study how these architectures can be applied and adapted for natural language generation, comparing a number of architectural and training schemes. We focus in particular on open-domain dialog as a typical high entropy generation task, presenting and comparing different architectures for adapting pretrained models with state of the art results.",
  "keywords": [
    "variety",
    "processing",
    "language",
    "generation",
    "natural",
    "dialog",
    "we",
    "natural language generation",
    "transfer",
    "learning",
    "a variety",
    "natural language processing",
    "training",
    "large-scale transfer learning",
    "entropy"
  ],
  "url": "https://aclanthology.org/P19-1608/",
  "provenance": {
    "collected_at": "2025-06-05 00:46:19",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}