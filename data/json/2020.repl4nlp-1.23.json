{
  "id": "2020.repl4nlp-1.23",
  "title": "Supertagging with {CCG} primitives",
  "authors": [
    "Bhargava, Aditya  and\nPenn, Gerald"
  ],
  "year": "2020",
  "venue": "Proceedings of the 5th Workshop on Representation Learning for NLP",
  "abstract": "In CCG and other highly lexicalized grammars, supertagging a sentenceâ€™s words with their lexical categories is a critical step for efficient parsing. Because of the high degree of lexicalization in these grammars, the lexical categories can be very complex. Existing approaches to supervised CCG supertagging treat the categories as atomic units, even when the categories are not simple; when they encounter words with categories unseen during training, their guesses are accordingly unsophisticated. In this paper, we make use of the primitives and operators that constitute the lexical categories of categorial grammars. Instead of opaque labels, we treat lexical categories themselves as linear sequences. We present an LSTM-based model that replaces standard word-level classification with prediction of a sequence of primitives, similarly to LSTM decoders. Our model obtains state-of-the-art word accuracy for single-task English CCG supertagging, increases parser coverage and F1, and is able to produce novel categories. Analysis shows a synergistic effect between this decomposed view and incorporation of prediction history.",
  "keywords": [
    "parsing",
    "f1",
    "efficient",
    "the categories",
    "we",
    "lstm",
    "classification",
    "this decomposed view",
    "an lstm-based model",
    "decoders",
    "word",
    "sequence",
    "a synergistic effect",
    "analysis",
    "standard word-level classification"
  ],
  "url": "https://aclanthology.org/2020.repl4nlp-1.23/",
  "provenance": {
    "collected_at": "2025-06-05 07:58:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}