{
  "id": "2024.findings-acl.437",
  "title": "Penetrative {AI}: Making {LLM}s Comprehend the Physical World",
  "authors": [
    "Xu, Huatao  and\nHan, Liying  and\nYang, Qirui  and\nLi, Mo  and\nSrivastava, Mani"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term “Penetrative AI”. The paper explores such an extension at two levels of LLMs’ ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.",
  "keywords": [
    "we",
    "llm",
    "information",
    "chatgpt",
    "their remarkable capabilities",
    "llms",
    "processing",
    "text",
    "large language models llms",
    "proficiency",
    "llms ability",
    "knowledge",
    "language",
    "human",
    "capabilities"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.437/",
  "provenance": {
    "collected_at": "2025-06-05 10:54:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}