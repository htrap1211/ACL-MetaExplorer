{
  "id": "2021.wat-1.6",
  "title": "NECTEC}{'}s Participation in {WAT}-2021",
  "authors": [
    "Hlaing, Zar Zar  and\nThu, Ye Kyaw  and\nMyint Oo, Thazin  and\nEi San, Mya  and\nUsanavasin, Sasiporn  and\nNetisopakul, Ponrudee  and\nSupnithi, Thepchai"
  ],
  "year": "2021",
  "venue": "Proceedings of the 8th Workshop on Asian Translation (WAT2021)",
  "abstract": "In this paper, we report the experimental results of Machine Translation models conducted by a NECTEC team for the translation tasks of WAT-2021. Basically, our models are based on neural methods for both directions of English-Myanmar and Myanmar-English language pairs. Most of the existing Neural Machine Translation (NMT) models mainly focus on the conversion of sequential data and do not directly use syntactic information. However, we conduct multi-source neural machine translation (NMT) models using the multilingual corpora such as string data corpus, tree data corpus, or POS-tagged data corpus. The multi-source translation is an approach to exploit multiple inputs (e.g. in two different formats) to increase translation accuracy. The RNN-based encoder-decoder model with attention mechanism and transformer architectures have been carried out for our experiment. The experimental results showed that the proposed models of RNN-based architecture outperform the baseline model for English-to-Myanmar translation task, and the multi-source and shared-multi-source transformer models yield better translation results than the baseline.",
  "keywords": [
    "we",
    "machine translation models",
    "translation",
    "shared-multi-source transformer models",
    "neural",
    "the rnn-based encoder-decoder model",
    "attention mechanism",
    "decoder",
    "information",
    "translation accuracy",
    "pos",
    "-",
    "transformer architectures",
    "better translation results",
    "the translation tasks"
  ],
  "url": "https://aclanthology.org/2021.wat-1.6/",
  "provenance": {
    "collected_at": "2025-06-05 08:23:35",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}