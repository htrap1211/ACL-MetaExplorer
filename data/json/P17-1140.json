{
  "id": "P17-1140",
  "title": "Incorporating Word Reordering Knowledge into Attention-based Neural Machine Translation",
  "authors": [
    "Zhang, Jinchao  and\nWang, Mingxuan  and\nLiu, Qun  and\nZhou, Jie"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "This paper proposes three distortion models to explicitly incorporate the word reordering knowledge into attention-based Neural Machine Translation (NMT) for further improving translation performance. Our proposed models enable attention mechanism to attend to source words regarding both the semantic requirement and the word reordering penalty. Experiments on Chinese-English translation show that the approaches can improve word alignment quality and achieve significant translation improvements over a basic attention-based NMT by large margins. Compared with previous works on identical corpora, our system achieves the state-of-the-art performance on translation quality.",
  "keywords": [
    "alignment",
    "knowledge",
    "both the semantic requirement",
    "neural",
    "machine",
    "significant translation improvements",
    "further improving translation performance",
    "attention mechanism",
    "chinese-english translation",
    "translation quality",
    "semantic",
    "attention",
    "word",
    "attention-based neural machine translation",
    "a basic attention-based nmt"
  ],
  "url": "https://aclanthology.org/P17-1140/",
  "provenance": {
    "collected_at": "2025-06-05 00:00:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}