{
  "id": "2024.findings-acl.758",
  "title": "Argument-Aware Approach To Event Linking",
  "authors": [
    "Hsu, I-Hung  and\nXue, Zihan  and\nPochhi, Nilay  and\nBansal, Sahil  and\nNatarajan, Prem  and\nSrinivasa, Jayanth  and\nPeng, Nanyun"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Event linking connects event mentions in text with relevant nodes in a knowledge base (KB). Prior research in event linking has mainly borrowed methods from entity linking, overlooking the distinct features of events. Compared to the extensively explored entity linking task, events have more complex structures and can be more effectively distinguished by examining their associated arguments. Moreover, the information-rich nature of events leads to the scarcity of event KBs. This emphasizes the need for event linking models to identify and classify event mentions not in the KB as “out-of-KB,” an area that has received limited attention. In this work, we tackle these challenges by introducing an argument-aware approach. First, we improve event linking models by augmenting input text with tagged event argument information, facilitating the recognition of key information about event mentions. Subsequently, to help the model handle “out-of-KB” scenarios, we synthesize out-of-KB training examples from in-KB instances through controlled manipulation of event arguments. Our experiment across two test datasets showed significant enhancements in both in-KB and out-of-KB scenarios, with a notable 22% improvement in out-of-KB evaluations.",
  "keywords": [
    "we",
    "training",
    "limited attention",
    "information",
    "rich",
    "text",
    "work",
    "knowledge",
    "model",
    "evaluations",
    "attention",
    "entity",
    "area",
    "approach",
    "notable"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.758/",
  "provenance": {
    "collected_at": "2025-06-05 10:58:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}