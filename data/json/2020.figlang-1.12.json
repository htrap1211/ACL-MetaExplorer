{
  "id": "2020.figlang-1.12",
  "title": "Context-Aware Sarcasm Detection Using {BERT",
  "authors": [
    "Baruah, Arup  and\nDas, Kaushik  and\nBarbhuiya, Ferdous  and\nDey, Kuntal"
  ],
  "year": "2020",
  "venue": "Proceedings of the Second Workshop on Figurative Language Processing",
  "abstract": "In this paper, we present the results obtained by BERT, BiLSTM and SVM classifiers on the shared task on Sarcasm Detection held as part of The Second Workshop on Figurative Language Processing. The shared task required the use of conversational context to detect sarcasm. We experimented by varying the amount of context used along with the response (response is the text to be classified). The amount of context used includes (i) zero context, (ii) last one, two or three utterances, and (iii) all utterances. It was found that including the last utterance in the dialogue along with the response improved the performance of the classifier for the Twitter data set. On the other hand, the best performance for the Reddit data set was obtained when using only the response without any contextual information. The BERT classifier obtained F-score of 0.743 and 0.658 for the Twitter and Reddit data set respectively.",
  "keywords": [
    "svm",
    "language",
    "bert",
    "classifier",
    "conversational context",
    "text",
    "the classifier",
    "it",
    "bilstm",
    "classifiers",
    "information",
    "conversational",
    "we",
    "dialogue",
    "the bert classifier"
  ],
  "url": "https://aclanthology.org/2020.figlang-1.12/",
  "provenance": {
    "collected_at": "2025-06-05 07:55:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}