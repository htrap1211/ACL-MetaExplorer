{
  "id": "2024.acl-long.466",
  "title": "O}pen{T}o{M}: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models",
  "authors": [
    "Xu, Hainiu  and\nZhao, Runcong  and\nZhu, Lixing  and\nDu, Jinhua  and\nHe, Yulan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Neural Theory-of-Mind (N-ToM), machine’s ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence of personality traits and preferences, a lack of questions addressing characters’ psychological mental states, and limited diversity in the questions posed. In response to these issues, we construct OpenToM, a new benchmark for assessing N-ToM with (1) longer and clearer narrative stories, (2) characters with explicit personality traits, (3) actions that are triggered by character intentions, and (4) questions designed to challenge LLMs’ capabilities of modeling characters’ mental states of both the physical and psychological world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling certain aspects of mental states in the physical world but fall short when tracking characters’ mental states in the psychological world.",
  "keywords": [
    "we",
    "pen",
    "clearer narrative stories",
    "llms",
    "stories",
    "language",
    "machine",
    "large language models",
    "capabilities",
    "states",
    "theory",
    "mind",
    "characters",
    "state",
    "diversity"
  ],
  "url": "https://aclanthology.org/2024.acl-long.466/",
  "provenance": {
    "collected_at": "2025-06-05 10:40:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}