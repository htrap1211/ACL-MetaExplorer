{
  "id": "2022.findings-acl.136",
  "title": "How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis",
  "authors": [
    "Li, Shaobo  and\nLi, Xiaoguang  and\nShang, Lifeng  and\nDong, Zhenhua  and\nSun, Chengjie  and\nLiu, Bingquan  and\nJi, Zhenzhou  and\nJiang, Xin  and\nLiu, Qun"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Recently, there has been a trend to investigate the factual knowledge captured by Pre-trained Language Models (PLMs). Many works show the PLMs’ ability to fill in the missing factual words in cloze-style prompts such as ”Dante was born in [MASK].” However, it is still a mystery how PLMs generate the results correctly: relying on effective clues or shortcut patterns? We try to answer this question by a causal-inspired analysis that quantitatively measures and evaluates the word-level patterns that PLMs depend on to generate the missing words. We check the words that have three typical associations with the missing words: knowledge-dependent, positionally close, and highly co-occurred. Our analysis shows: (1) PLMs generate the missing factual words more by the positionally close and highly co-occurred words than the knowledge-dependent words; (2) the dependence on the knowledge-dependent words is more effective than the positionally close and highly co-occurred words. Accordingly, we conclude that the PLMs capture the factual knowledge ineffectively because of depending on the inadequate associations.",
  "keywords": [
    "prompts",
    "cloze-style prompts",
    "knowledge",
    "language",
    "pre-trained language models",
    "it",
    "question",
    "word",
    "we",
    "pre",
    "analysis",
    "that",
    "a mystery",
    "the dependence",
    "clues"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.136/",
  "provenance": {
    "collected_at": "2025-06-05 08:36:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}