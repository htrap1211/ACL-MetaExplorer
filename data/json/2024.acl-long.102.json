{
  "id": "2024.acl-long.102",
  "title": "I}n{C}haracter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews",
  "authors": [
    "Wang, Xintao  and\nXiao, Yunze  and\nHuang, Jen-tse  and\nYuan, Siyu  and\nXu, Rui  and\nGuo, Haoran  and\nTu, Quan  and\nFei, Yaying  and\nLeng, Ziang  and\nWang, Wei  and\nChen, Jiangjie  and\nLi, Cheng  and\nXiao, Yanghua"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether RPAs accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the knowledge and linguistic patterns of characters. This paper, instead, introduces a novel perspective to evaluate the personality fidelity of RPAs with psychological scales. Overcoming drawbacks of previous self-report assessments on RPAs, we propose InCharacter, namely **In**terviewing **Character** agents for personality tests. Experiments include various types of RPAs and LLMs, covering 32 distinct characters on 14 widely used psychological scales. The results validate the effectiveness of InCharacter in measuring RPA personalities. Then, with InCharacter, we show that state-of-the-art RPAs exhibit personalities highly aligned with the human-perceived personalities of the characters, achieving an accuracy up to 80.7%.",
  "keywords": [
    "knowledge",
    "i",
    "rpa personalities",
    "language",
    "psychological interviews",
    "human",
    "rpa",
    "large language models",
    "self",
    "field",
    "the human-perceived personalities",
    "an accuracy",
    "we",
    "interviews",
    "a flourishing field"
  ],
  "url": "https://aclanthology.org/2024.acl-long.102/",
  "provenance": {
    "collected_at": "2025-06-05 10:35:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}