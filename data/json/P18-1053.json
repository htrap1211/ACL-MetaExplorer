{
  "id": "P18-1053",
  "title": "Deep Reinforcement Learning for {C}hinese Zero Pronoun Resolution",
  "authors": [
    "Yin, Qingyu  and\nZhang, Yu  and\nZhang, Wei-Nan  and\nLiu, Ting  and\nWang, William Yang"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Recent neural network models for Chinese zero pronoun resolution gain great performance by capturing semantic information for zero pronouns and candidate antecedents, but tend to be short-sighted, operating solely by making local decisions. They typically predict coreference links between the zero pronoun and one single candidate antecedent at a time while ignoring their influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is crucial for classifying later zero pronoun-candidate antecedent pairs, a need which leads traditional models of zero pronoun resolution to draw on reinforcement learning. In this paper, we show how to integrate these goals, applying deep reinforcement learning to deal with the task. With the help of the reinforcement learning agent, our system learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 show that our approach substantially outperforms the state-of-the-art methods under three experimental settings.",
  "keywords": [
    "deep",
    "semantic",
    "we",
    "the reinforcement learning agent",
    "a sequential manner",
    "coreference links",
    "later coreference decisions",
    "neural",
    "deep reinforcement learning",
    "information",
    "learning",
    "manner",
    "recent neural network models",
    "coreference",
    "earlier predicted antecedents"
  ],
  "url": "https://aclanthology.org/P18-1053/",
  "provenance": {
    "collected_at": "2025-06-05 00:10:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}