{
  "id": "2023.acl-long.449",
  "title": "Multi-Row, Multi-Span Distant Supervision For {T}able+{T}ext Question Answering",
  "authors": [
    "Kumar, Vishwajeet  and\nGupta, Yash  and\nChemmengath, Saneem  and\nSen, Jaydeep  and\nChakrabarti, Soumen  and\nBharadwaj, Samarth  and\nPan, Feifei"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Question answering (QA) over tables and linked text, also called TextTableQA, has witnessed significant research in recent years, as tables are often found embedded in documents along with related text. HybridQA and OTT-QA are the two best-known TextTableQA datasets, with questions that are best answered by combining information from both table cells and linked text passages. A common challenge in both datasets, and TextTableQA in general, is that the training instances include just the question and answer, where the gold answer may match not only multiple table cells across table rows but also multiple text spans within the scope of a table row and its associated text. This leads to a noisy multi-instance training regime. We present MITQA, a transformer-based TextTableQA system that is explicitly designed to cope with distant supervision along both these axes, through a multi-instance loss objective, together with careful curriculum design. Our experiments show that the proposed multi-instance distant supervision approach helps MITQA get sate-of-the-art results beating the existing baselines for both HybridQA and OTT-QA, putting MITQA at the top of HybridQA leaderboard with best EM and F1 scores on a held out test set.",
  "keywords": [
    "mitqa",
    "question",
    "we",
    "related text hybridqa",
    "training",
    "answer",
    "hybridqa",
    "loss",
    "information",
    "both hybridqa",
    "text",
    "objective",
    "texttableqa",
    "ott-qa",
    "hybridqa leaderboard"
  ],
  "url": "https://aclanthology.org/2023.acl-long.449/",
  "provenance": {
    "collected_at": "2025-06-05 09:41:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}