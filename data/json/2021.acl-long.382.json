{
  "id": "2021.acl-long.382",
  "title": "Lexicon Learning for Few Shot Sequence Modeling",
  "authors": [
    "Akyurek, Ekin  and\nAndreas, Jacob"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Sequence-to-sequence transduction is the core problem in language processing applications as diverse as semantic parsing, machine translation, and instruction following. The neural network models that provide the dominant solution to these problems are brittle, especially in low-resource settings: they fail to generalize correctly or systematically from small datasets. Past work has shown that many failures of systematic generalization arise from neural modelsâ€™ inability to disentangle lexical phenomena from syntactic ones. To address this, we augment neural decoders with a lexical translation mechanism that generalizes existing copy mechanisms to incorporate learned, decontextualized, token-level translation rules. We describe how to initialize this mechanism using a variety of lexicon learning algorithms, and show that it improves systematic generalization on a diverse set of sequence modeling tasks drawn from cognitive science, formal semantics, and machine translation.",
  "keywords": [
    "variety",
    "machine translation",
    "semantic",
    "semantic parsing machine translation",
    "we",
    "cognitive science formal semantics",
    "shot",
    "translation",
    "instruction",
    "neural",
    "semantics",
    "the neural network models",
    "it",
    "token",
    "science"
  ],
  "url": "https://aclanthology.org/2021.acl-long.382/",
  "provenance": {
    "collected_at": "2025-06-05 08:04:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}