{
  "id": "2023.clinicalnlp-1.51",
  "title": "S}umm{QA} at {MEDIQA}-Chat 2023: In-Context Learning with {GPT}-4 for Medical Summarization",
  "authors": [
    "Mathur, Yash  and\nRangreji, Sanketh  and\nKapoor, Raghav  and\nPalavalli, Medha  and\nBertsch, Amanda  and\nGormley, Matthew"
  ],
  "year": "2023",
  "venue": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
  "abstract": "Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminologyin gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.",
  "keywords": [
    "code",
    "conversations",
    "k",
    "summarization",
    "we",
    "dialogue",
    "dialogue2note",
    "the top-k similar dialogues",
    "shot",
    "classification",
    "medical terminologyin gold summaries",
    "information",
    "learning",
    "a",
    "prompting-based approaches"
  ],
  "url": "https://aclanthology.org/2023.clinicalnlp-1.51/",
  "provenance": {
    "collected_at": "2025-06-05 10:23:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}