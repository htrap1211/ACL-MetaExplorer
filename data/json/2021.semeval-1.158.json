{
  "id": "2021.semeval-1.158",
  "title": "D}eep{B}lue{AI} at {S}em{E}val-2021 Task 7: Detecting and Rating Humor and Offense with Stacking Diverse Language Model-Based Methods",
  "authors": [
    "Song, Bingyan  and\nPan, Chunguang  and\nWang, Shengguang  and\nLuo, Zhipeng"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes the winning system for SemEval-2021 Task 7: Detecting and Rating Humor and Offense. Our strategy is stacking diverse pre-trained language models (PLMs) such as RoBERTa and ALBERT. We first perform fine-tuning on these two PLMs with various hyperparameters and different training strategies. Then a valid stacking mechanism is applied on top of the fine-tuned PLMs to get the final prediction. Experimental results on the dataset released by the organizer of the task show the validity of our method and we win first place and third place for subtask 2 and 1a.",
  "keywords": [
    "diverse language model-based methods",
    "top",
    "roberta",
    "hyperparameters",
    "em",
    "language",
    "model",
    "eep",
    "albert",
    "various hyperparameters",
    "strategies",
    "we",
    "valid",
    "pre",
    "different training strategies"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.158/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}