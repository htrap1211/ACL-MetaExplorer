{
  "id": "2024.acl-long.643",
  "title": "Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning",
  "authors": [
    "Wang, Tianduo  and\nLi, Shichen  and\nLu, Wei"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Teaching small-scale language models to perform math reasoning is a valuable yet challenging task. Besides obtaining labeled data from human experts, one of the most common ways to collect high-quality data is by sampling from a larger and more powerful language model. Although previous works have demonstrated the effectiveness of this method, such a knowledge distillation paradigm can be costly and unstable, especially considering that many large language models, such as GPT-4, are closed-sourced, proprietary, and their behaviors are unpredictable. In this work, to avoid relying on outputs from large models, we demonstrate that the reasoning abilities of small-scale language models can be enhanced through self-training, which involves training models with their own outputs. We also show that the vanilla self-training can be further augmented by an alignment algorithm, direct preference optimization (DPO). We empirically found that models trained with the DPO objective are capable of making better generations that largely benefit multi-turn self-training. The experiments show our models outperform the state-of-the-art models with comparable sizes on a series of downstream math reasoning tasks with minimal resource requirements.",
  "keywords": [
    "chain",
    "series",
    "we",
    "many large language models",
    "training",
    "better generations",
    "self",
    "small-scale language models",
    "the dpo objective",
    "abilities",
    "objective",
    "gpt-4",
    "generations",
    "direct preference optimization",
    "work"
  ],
  "url": "https://aclanthology.org/2024.acl-long.643/",
  "provenance": {
    "collected_at": "2025-06-05 10:43:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}