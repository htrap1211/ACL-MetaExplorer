{
  "id": "2020.acl-main.167",
  "title": "GPT}-too: A Language-Model-First Approach for {AMR}-to-Text Generation",
  "authors": [
    "Mager, Manuel  and\nFernandez Astudillo, Ram{\\'o}n  and\nNaseem, Tahira  and\nSultan, Md Arafat  and\nLee, Young-Suk  and\nFlorian, Radu  and\nRoukos, Salim"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Abstract Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10 dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.",
  "keywords": [
    "transformer",
    "the standard evaluation metrics",
    "language",
    "generation",
    "model",
    "text",
    "human",
    "metrics",
    "broad-coverage sentence-level semantic graphs",
    "-",
    "transformer architectures",
    "gpt",
    "semantic",
    "sequence",
    "we"
  ],
  "url": "https://aclanthology.org/2020.acl-main.167/",
  "provenance": {
    "collected_at": "2025-06-05 07:44:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}