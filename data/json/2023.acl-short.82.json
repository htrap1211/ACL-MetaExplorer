{
  "id": "2023.acl-short.82",
  "title": "Controllable Mixed-Initiative Dialogue Generation through Prompting",
  "authors": [
    "Chen, Maximillian  and\nYu, Xiao  and\nShi, Weiyan  and\nAwasthi, Urvi  and\nYu, Zhou"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",
  "keywords": [
    "human evaluation",
    "fine-tuning pre-trained language models",
    "tuning",
    "prompt",
    "generation",
    "controllable mixed-initiative dialogue generation",
    "these supervised generation models",
    "planner",
    "language",
    "support",
    "particular dialogue intents",
    "human",
    "large language models",
    "mixed-initiative dialogue tasks",
    "strategies"
  ],
  "url": "https://aclanthology.org/2023.acl-short.82/",
  "provenance": {
    "collected_at": "2025-06-05 09:49:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}