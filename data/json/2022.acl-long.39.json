{
  "id": "2022.acl-long.39",
  "title": "Learn to Adapt for Generalized Zero-Shot Text Classification",
  "authors": [
    "Zhang, Yiwen  and\nYuan, Caixia  and\nWang, Xiaojie  and\nBai, Ziwei  and\nLiu, Yongbin"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Generalized zero-shot text classification aims to classify textual instances from both previously seen classes and incrementally emerging unseen classes. Most existing methods generalize poorly since the learned parameters are only optimal for seen classes rather than for both classes, and the parameters keep stationary in predicting procedures. To address these challenges, we propose a novel Learn to Adapt (LTA) network using a variant meta-learning framework. Specifically, LTA trains an adaptive classifier by using both seen and virtual unseen classes to simulate a generalized zero-shot learning (GZSL) scenario in accordance with the test time, and simultaneously learns to calibrate the class prototypes and sample representations to make the learned parameters adaptive to incoming unseen classes. We claim that the proposed model is capable of representing all prototypes and samples from both classes to a more consistent distribution in a global space. Extensive experiments on five text classification datasets show that our model outperforms several competitive previous approaches by large margins. The code and the whole datasets are available athttps://github.com/Quareia/LTA.",
  "keywords": [
    "code",
    "classifier",
    "generalized",
    "we",
    "shot",
    "classification",
    "zero-shot text classification",
    "an adaptive classifier",
    "generalized zero-shot text classification",
    "five text classification datasets",
    "text",
    "model",
    "class",
    "network",
    "time"
  ],
  "url": "https://aclanthology.org/2022.acl-long.39/",
  "provenance": {
    "collected_at": "2025-06-05 08:24:49",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}