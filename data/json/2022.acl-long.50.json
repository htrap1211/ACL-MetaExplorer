{
  "id": "2022.acl-long.50",
  "title": "Learning When to Translate for Streaming Speech",
  "authors": [
    "Dong, Qian  and\nZhu, Yaoming  and\nWang, Mingxuan  and\nLi, Lei"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "How to find proper moments to generate partial sentence translation given a streaming speech input? Existing approaches waiting-and-translating for a fixed duration often break the acoustic units in speech, since the boundaries between acoustic units in speech are not even. In this paper, we propose MoSST, a simple yet effective method for translating streaming speech content. Given a usually long speech sequence, we develop an efficient monotonic segmentation module inside an encoder-decoder model to accumulate acoustic information incrementally and detect proper speech unit boundaries for the input in speech translation task. Experiments on multiple translation directions of the MuST-C dataset show that outperforms existing methods and achieves the best trade-off between translation quality (BLEU) and latency. Our code is available athttps://github.com/dqqcasia/mosst.",
  "keywords": [
    "code",
    "an encoder-decoder model",
    "speech translation task experiments",
    "model",
    "efficient",
    "boundaries",
    "bleu",
    "encoder",
    "the boundaries",
    "partial sentence translation",
    "decoder",
    "information",
    "we",
    "sequence",
    "proper speech unit boundaries"
  ],
  "url": "https://aclanthology.org/2022.acl-long.50/",
  "provenance": {
    "collected_at": "2025-06-05 08:24:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}