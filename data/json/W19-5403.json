{
  "id": "W19-5403",
  "title": "Findings of the {WMT} 2019 Biomedical Translation Shared Task: Evaluation for {MEDLINE} Abstracts and Biomedical Terminologies",
  "authors": [
    "Bawden, Rachel  and\nBretonnel Cohen, Kevin  and\nGrozea, Cristian  and\nJimeno Yepes, Antonio  and\nKittner, Madeleine  and\nKrallinger, Martin  and\nMah, Nancy  and\nNeveol, Aurelie  and\nNeves, Mariana  and\nSoares, Felipe  and\nSiu, Amy  and\nVerspoor, Karin  and\nVicente Navarro, Maika"
  ],
  "year": "2019",
  "venue": "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
  "abstract": "In the fourth edition of the WMT Biomedical Translation task, we considered a total of six languages, namely Chinese (zh), English (en), French (fr), German (de), Portuguese (pt), and Spanish (es). We performed an evaluation of automatic translations for a total of 10 language directions, namely, zh/en, en/zh, fr/en, en/fr, de/en, en/de, pt/en, en/pt, es/en, and en/es. We provided training data based on MEDLINE abstracts for eight of the 10 language pairs and test sets for all of them. In addition to that, we offered a new sub-task for the translation of terms in biomedical terminologies for the en/es language direction. Higher BLEU scores (close to 0.5) were obtained for the es/en, en/es and en/pt test sets, as well as for the terminology sub-task. After manual validation of the primary runs, some submissions were judged to be better than the reference translations, for instance, for de/en, en/es and es/en.",
  "keywords": [
    "higher bleu scores",
    "reference",
    "automatic translations",
    "the translation",
    "language",
    "validation",
    "bleu",
    "-",
    "all",
    "we",
    "terminologies",
    "an evaluation",
    "evaluation",
    "translations",
    "biomedical terminologies"
  ],
  "url": "https://aclanthology.org/W19-5403/",
  "provenance": {
    "collected_at": "2025-06-05 02:08:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}