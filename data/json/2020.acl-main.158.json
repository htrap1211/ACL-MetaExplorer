{
  "id": "2020.acl-main.158",
  "title": "A Systematic Assessment of Syntactic Generalization in Neural Language Models",
  "authors": [
    "Hu, Jennifer  and\nGauthier, Jon  and\nQian, Peng  and\nWilcox, Ethan  and\nLevy, Roger"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.",
  "keywords": [
    "syntactic generalization",
    "we",
    "neural language models",
    "a systematic evaluation",
    "generalizations",
    "neural",
    "it",
    "properties",
    "lower perplexity scores",
    "proper syntactic generalizations",
    "syntactic generalization performance",
    "perplexity",
    "generalization",
    "work",
    "the model properties"
  ],
  "url": "https://aclanthology.org/2020.acl-main.158/",
  "provenance": {
    "collected_at": "2025-06-05 07:44:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}