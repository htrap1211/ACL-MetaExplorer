{
  "id": "2024.acl-short.72",
  "title": "Cleaner Pretraining Corpus Curation with Neural Web Scraping",
  "authors": [
    "Xu, Zhipeng  and\nLiu, Zhenghao  and\nYan, Yukun  and\nLiu, Zhiyuan  and\nYu, Ge  and\nXiong, Chenyan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "The web contains large-scale, diverse, and abundant information to satisfy the information-seeking needs of humans. Through meticulous data collection, preprocessing, and curation, webpages can be used as a fundamental data resource for language model pretraining. However, when confronted with the progressively revolutionized and intricate nature of webpages, rule-based/feature-based web scrapers are becoming increasingly inadequate. This paper presents a simple, fast, and effective Neural web Scraper (NeuScraper) to help extract primary and clean text contents from webpages. Experimental results show that NeuScraper surpasses the baseline scrapers by achieving more than a 20% improvement, demonstrating its potential in extracting higher-quality data to facilitate the language model pretraining. All of the code is available at https://github.com/OpenMatch/NeuScraper.",
  "keywords": [
    "the language model",
    "code",
    "language",
    "neural",
    "model",
    "language model",
    "text",
    "information",
    "all",
    "cleaner",
    "fast",
    "the web",
    "github",
    "needs",
    "fundamental"
  ],
  "url": "https://aclanthology.org/2024.acl-short.72/",
  "provenance": {
    "collected_at": "2025-06-05 10:47:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}