{
  "id": "2021.findings-acl.287",
  "title": "Defending Pre-trained Language Models from Adversarial Word Substitution Without Performance Sacrifice",
  "authors": [
    "Bao, Rongzhou  and\nWang, Jiayi  and\nZhao, Hai"
  ],
  "year": "2021",
  "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
  "abstract": "Correct abstract if needed. Retain XML formatting tags such as <tex-math>.",
  "keywords": [
    "pre",
    "tex",
    "word",
    "language",
    "pre-trained language models",
    "xml",
    "sacrifice",
    "adversarial",
    "models",
    "tex-math",
    "correct",
    "adversarial word substitution",
    "performance sacrifice",
    "substitution",
    "tags"
  ],
  "url": "https://aclanthology.org/2021.findings-acl.287/",
  "provenance": {
    "collected_at": "2025-06-05 08:13:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}