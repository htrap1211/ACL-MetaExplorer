{
  "id": "2021.semeval-1.124",
  "title": "MIPT}-{NSU}-{UTMN} at {S}em{E}val-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection",
  "authors": [
    "Kotyushev, Mikhail  and\nGlazkova, Anna  and\nMorozov, Dmitry"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes our system for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our system obtained a F1-score of 67.55% on test data.",
  "keywords": [
    "ensemble",
    "various ensemble techniques",
    "processing",
    "language",
    "neural",
    "pre-trained language models",
    "bert",
    "a f1-score",
    "ensemble models",
    "bert-based neural architectures",
    "several pre-trained language models",
    "we",
    "pre",
    "post",
    "identification"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.124/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:25",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}