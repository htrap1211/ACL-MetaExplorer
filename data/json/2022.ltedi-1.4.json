{
  "id": "2022.ltedi-1.4",
  "title": "Measuring Harmful Sentence Completion in Language Models for {LGBTQIA}+ Individuals",
  "authors": [
    "Nozza, Debora  and\nBianchi, Federico  and\nLauscher, Anne  and\nHovy, Dirk"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",
  "abstract": "Current language technology is ubiquitous and directly influences individualsâ€™ lives worldwide. Given the recent trend in AI on training and constantly releasing new and powerful large language models (LLMs), there is a need to assess their biases and potential concrete consequences. While some studies have highlighted the shortcomings of these models, there is only little on the negative impact of LLMs on LGBTQIA+ individuals. In this paper, we investigated a state-of-the-art template-based approach for measuring the harmfulness of English LLMs sentence completion when the subjects belong to the LGBTQIA+ community. Our findings show that, on average, the most likely LLM-generated completion is an identity attack 13% of the time. Our results raise serious concerns about the applicability of these models in production environments.",
  "keywords": [
    "english llms",
    "we",
    "current",
    "training",
    "some studies",
    "their biases",
    "llms",
    "language models",
    "biases",
    "language",
    "ai",
    "studies",
    "time",
    "approach",
    "state"
  ],
  "url": "https://aclanthology.org/2022.ltedi-1.4/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}