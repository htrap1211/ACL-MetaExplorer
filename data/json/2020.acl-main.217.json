{
  "id": "2020.acl-main.217",
  "title": "Phone Features Improve Speech Translation",
  "authors": [
    "Salesky, Elizabeth  and\nBlack, Alan W"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "End-to-end models for speech translation (ST) more tightly couple speech recognition (ASR) and machine translation (MT) than a traditional cascade of separate ASR and MT models, with simpler model architectures and the potential for reduced error propagation. Their performance is often assumed to be superior, though in many conditions this is not yet the case. We compare cascaded and end-to-end models across high, medium, and low-resource conditions, and show that cascades remain stronger baselines. Further, we introduce two methods to incorporate phone features into ST models. We show that these features improve both architectures, closing the gap between end-to-end models and cascades, and outperforming previous academic work â€“ by up to 9 BLEU on our low-resource setting.",
  "keywords": [
    "work",
    "end",
    "translation",
    "model",
    "machine",
    "bleu",
    "machine translation",
    "propagation",
    "we",
    "speech translation",
    "up to 9 bleu",
    "speech",
    "recognition",
    "medium",
    "st models"
  ],
  "url": "https://aclanthology.org/2020.acl-main.217/",
  "provenance": {
    "collected_at": "2025-06-05 07:45:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}