{
  "id": "2022.acl-long.533",
  "title": "D}o{C}o{G}en: {D}omain Counterfactual Generation for Low Resource Domain Adaptation",
  "authors": [
    "Calderon, Nitay  and\nBen-David, Eyal  and\nFeder, Amir  and\nReichart, Roi"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Natural language processing (NLP) algorithms have become very successful, but they still struggle when applied to out-of-distribution examples. In this paper we propose a controllable generation approach in order to deal with this domain adaptation (DA) challenge. Given an input text example, our DoCoGen algorithm generates a domain-counterfactual textual example (D-con) - that is similar to the original in all aspects, including the task label, but its domain is changed to a desired one. Importantly, DoCoGen is trained using only unlabeled examples from multiple domains - no NLP task labels or parallel pairs of textual examples and their domain-counterfactuals are required. We show that DoCoGen can generate coherent counterfactuals consisting of multiple sentences. We use the D-cons generated by DoCoGen to augment a sentiment classifier and a multi-label intent classifier in 20 and 78 DA setups, respectively, where source-domain labeled data is scarce. Our model outperforms strong baselines and improves the accuracy of a state-of-the-art unsupervised DA algorithm.",
  "keywords": [
    "the accuracy",
    "classifier",
    "we",
    "a sentiment classifier",
    "a multi-label intent classifier",
    "natural",
    "processing",
    "con",
    "text",
    "a controllable generation approach",
    "no nlp task labels",
    "accuracy",
    "sentiment",
    "generation",
    "language"
  ],
  "url": "https://aclanthology.org/2022.acl-long.533/",
  "provenance": {
    "collected_at": "2025-06-05 08:31:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}