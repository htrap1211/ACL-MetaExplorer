{
  "id": "2024.findings-acl.696",
  "title": "M}us{TQ}: A Temporal Knowledge Graph Question Answering Dataset for Multi-Step Temporal Reasoning",
  "authors": [
    "Zhang, Tingyi  and\nWang, Jiaan  and\nLi, Zhixu  and\nQu, Jianfeng  and\nLiu, An  and\nChen, Zhigang  and\nZhi, Hongping"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Question answering over temporal knowledge graphs (TKGQA) is an emerging topic, which has attracted increasing interest since it considers the dynamic knowledge in the world. Several datasets along with model developments are proposed in the TKGQA research field. However, existing studies generally focus on fact-centered reasoning, with limited attention to temporal reasoning. To tackle the intricate and comprehensive nature of temporal reasoning, we propose a new TKGQA dataset, MusTQ, which contains 666K multi-step temporal reasoning questions as well as a TKG. The multi-step temporal reasoning is established based on six basic temporal reasoning types derived from a well-established measure theory. Using MusTQ, we evaluate previous TKGQA methods and find that they typically fall short in multi-step temporal reasoning. Furthermore, we propose a TKGQA model, MusTKGQA, which enhances multi-step reasoning ability with entity-time attention mechanism and optimized temporal knowledge graph representation. Extensive experiments on MusTQ show that our model achieves state-of-the-art multi-step temporal reasoning performance.",
  "keywords": [
    "a tkg",
    "field",
    "question",
    "we",
    "tkg",
    "graph",
    "limited attention",
    "it",
    "mustkgqa",
    "tkgqa",
    "existing studies",
    "a tkgqa model mustkgqa",
    "topic",
    "the tkgqa research field",
    "previous tkgqa methods"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.696/",
  "provenance": {
    "collected_at": "2025-06-05 10:58:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}