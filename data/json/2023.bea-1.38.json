{
  "id": "2023.bea-1.38",
  "title": "Training for Grammatical Error Correction Without Human-Annotated {L}2 Learners' Corpora",
  "authors": [
    "Oda, Mikio"
  ],
  "year": "2023",
  "venue": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
  "abstract": "Grammatical error correction (GEC) is a challenging task for non-native second language (L2) learners and learning machines. Data-driven GEC learning requires as much human-annotated genuine training data as possible. However, it is difficult to produce larger-scale human-annotated data, and synthetically generated large-scale parallel training data is valuable for GEC systems. In this paper, we propose a method for rebuilding a corpus of synthetic parallel data using target sentences predicted by a GEC model to improve performance. Experimental results show that our proposed pre-training outperforms that on the original synthetic datasets. Moreover, it is also shown that our proposed training without human-annotated L2 learners’ corpora is as practical as conventional full pipeline training with both synthetic datasets and L2 learners’ corpora in terms of accuracy.",
  "keywords": [
    "l2 learners",
    "language",
    "learners",
    "our proposed pre-training outperforms",
    "model",
    "it",
    "human",
    "human-annotated l2 learners",
    "we",
    "human-annotated l 2 learners",
    "learning",
    "pre",
    "accuracy",
    "training",
    "practical"
  ],
  "url": "https://aclanthology.org/2023.bea-1.38/",
  "provenance": {
    "collected_at": "2025-06-05 10:21:45",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}