{
  "id": "2024.cmcl-1.4",
  "title": "Do large language models resemble humans in language use?",
  "authors": [
    "Cai, Zhenguang  and\nDuan, Xufeng  and\nHaslett, David  and\nWang, Shuqi  and\nPickering, Martin"
  ],
  "year": "2024",
  "venue": "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
  "abstract": "It is unclear whether large language models (LLMs) develop humanlike characteristics in language use. We subjected ChatGPT and Vicuna to 12 pre-registered psycholinguistic experiments ranging from sounds to dialogue. ChatGPT and Vicuna replicated the human pattern of language use in 10 and 7 out of the 12 experiments, respectively. The models associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, attributed causality as a function of verb semantics, and accessed different meanings and retrieved different words depending on an interlocutorâ€™s identity. In addition, ChatGPT, but not Vicuna, nonliterally interpreted implausible sentences that were likely to have been corrupted by noise, drew reasonable inferences, and overlooked semantic fallacies in a sentence. Finally, unlike humans, neither model preferred using shorter words to convey less informative content, nor did they use context to resolve syntactic ambiguities. We discuss how these convergences and divergences may result from the transformer architecture. Overall, these experiments demonstrate that LLMs such as ChatGPT (and Vicuna to a lesser extent) are humanlike in many aspects of human language processing.",
  "keywords": [
    "verb semantics",
    "semantic",
    "we",
    "dialogue",
    "ambiguities",
    "semantics",
    "it",
    "fallacies",
    "chatgpt",
    "addition chatgpt",
    "dialogue chatgpt",
    "llms",
    "processing",
    "syntactic ambiguities",
    "large language models llms"
  ],
  "url": "https://aclanthology.org/2024.cmcl-1.4/",
  "provenance": {
    "collected_at": "2025-06-05 11:05:29",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}