{
  "id": "2023.acl-long.441",
  "title": "Text Style Transfer Back-Translation",
  "authors": [
    "Wei, Daimeng  and\nWu, Zhanglin  and\nShang, Hengchao  and\nLi, Zongyao  and\nWang, Minghan  and\nGuo, Jiaxin  and\nChen, Xiaoyu  and\nYu, Zhengzhe  and\nYang, Hao"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Back Translation (BT) is widely used in the field of machine translation, as it has been proved effective for enhancing translation quality. However, BT mainly improves the translation of inputs that share a similar style (to be more specific, translation-liked inputs), since the source side of BT data is machine-translated. For natural inputs, BT brings only slight improvements and sometimes even adverse effects. To address this issue, we propose Text Style Transfer Back Translation (TST BT), which uses a style transfer to modify the source side of BT data. By making the style of source-side text more natural, we aim to improve the translation of natural inputs. Our experiments on various language pairs, including both high-resource and low-resource ones, demonstrate that TST BT significantly improves translation performance against popular BT benchmarks. In addition, TST BT is proved to be effective in domain adaptation so this strategy can be regarded as a generalized data augmentation method. Our training code and text style transfer model are open-sourced.",
  "keywords": [
    "back translation bt",
    "code",
    "the translation",
    "language",
    "natural",
    "the field",
    "machine",
    "model",
    "text",
    "it",
    "generalized",
    "field",
    "machine translation",
    "a generalized data augmentation",
    "translation quality"
  ],
  "url": "https://aclanthology.org/2023.acl-long.441/",
  "provenance": {
    "collected_at": "2025-06-05 09:41:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}