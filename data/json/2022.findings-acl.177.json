{
  "id": "2022.findings-acl.177",
  "title": "C}hart{QA}: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
  "authors": [
    "Masry, Ahmed  and\nLong, Do Xuan  and\nTan, Jia Qing  and\nJoty, Shafiq  and\nHoque, Enamul"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic operations. They also commonly refer to visual features of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their questions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and logical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a unified way to answer questions. While our models achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.",
  "keywords": [
    "work",
    "variety",
    "transformer",
    "summaries",
    "a unified way",
    "human",
    "unified",
    "two transformer-based models",
    "question",
    "human-written chart summaries",
    "we",
    "a variety",
    "visual",
    "evaluation",
    "the evaluation"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.177/",
  "provenance": {
    "collected_at": "2025-06-05 08:37:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}