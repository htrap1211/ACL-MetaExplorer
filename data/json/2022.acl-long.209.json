{
  "id": "2022.acl-long.209",
  "title": "FIBER}: Fill-in-the-Blanks as a Challenging Video Understanding Evaluation Framework",
  "authors": [
    "Castro, Santiago  and\nWang, Ruoyao  and\nHuang, Pingxuan  and\nStewart, Ian  and\nIgnat, Oana  and\nLiu, Nan  and\nStroud, Jonathan  and\nMihalcea, Rada"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We propose fill-in-the-blanks as a video understanding evaluation framework and introduce FIBER – a novel dataset consisting of 28,000 videos and descriptions in support of this evaluation framework. The fill-in-the-blanks setting tests a model’s understanding of a video by requiring it to predict a masked noun phrase in the caption of the video, given the video and the surrounding text. The FIBER benchmark does not share the weaknesses of the current state-of-the-art language-informed video understanding tasks, namely: (1) video question answering using multiple-choice questions, where models perform relatively well because they exploit linguistic biases in the task formulation, thus making our framework challenging for the current state-of-the-art systems to solve; and (2) video captioning, which relies on an open-ended evaluation framework that is often inaccurate because system answers may be perceived as incorrect if they differ in form from the ground truth. The FIBER dataset and our code are available athttps://lit.eecs.umich.edu/fiber/.",
  "keywords": [
    "an open-ended evaluation framework",
    "code",
    "support",
    "question",
    "form",
    "we",
    "this evaluation framework",
    "current",
    "linguistic biases",
    "it",
    "text",
    "edu",
    "biases",
    "language",
    "model"
  ],
  "url": "https://aclanthology.org/2022.acl-long.209/",
  "provenance": {
    "collected_at": "2025-06-05 08:27:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}