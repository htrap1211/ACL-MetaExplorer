{
  "id": "P17-2041",
  "title": "Discourse Annotation of Non-native Spontaneous Spoken Responses Using the {R}hetorical {S}tructure {T}heory Framework",
  "authors": [
    "Wang, Xinhao  and\nBruno, James  and\nMolloy, Hillary  and\nEvanini, Keelan  and\nZechner, Klaus"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "The availability of the Rhetorical Structure Theory (RST) Discourse Treebank has spurred substantial research into discourse analysis of written texts; however, limited research has been conducted to date on RST annotation and parsing of spoken language, in particular, non-native spontaneous speech. Considering that the measurement of discourse coherence is typically a key metric in human scoring rubrics for assessments of spoken language, we initiated a research effort to obtain RST annotations of a large number of non-native spoken responses from a standardized assessment of academic English proficiency. The resulting inter-annotator kappa agreements on the three different levels of Span, Nuclearity, and Relation are 0.848, 0.766, and 0.653, respectively. Furthermore, a set of features was explored to evaluate the discourse structure of non-native spontaneous speech based on these annotations; the highest performing feature resulted in a correlation of 0.612 with scores of discourse coherence provided by expert human raters.",
  "keywords": [
    "parsing",
    "we",
    "analysis",
    "academic english proficiency",
    "metric",
    "proficiency",
    "language",
    "human",
    "a large number",
    "theory",
    "a key metric",
    "assessment",
    "native",
    "annotator",
    "responses"
  ],
  "url": "https://aclanthology.org/P17-2041/",
  "provenance": {
    "collected_at": "2025-06-05 00:03:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}