{
  "id": "2022.acl-demo.3",
  "title": "V}i{LM}edic: a framework for research at the intersection of vision and language in medical {AI",
  "authors": [
    "Delbrouck, Jean-benoit  and\nSaab, Khaled  and\nVarma, Maya  and\nEyuboglu, Sabri  and\nChambon, Pierre  and\nDunnmon, Jared  and\nZambrano, Juan  and\nChaudhari, Akshay  and\nLanglotz, Curtis"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "There is a growing need to model interactions between data modalities (e.g., vision, language) â€” both to improve AI predictions on existing tasks and to enable new applications. In the recent field of multimodal medical AI, integrating multiple modalities has gained widespread popularity as multimodal models have proven to improve performance, robustness, require less training samples and add complementary information. To improve technical reproducibility and transparency for multimodal medical tasks as well as speed up progress across medical AI, we present ViLMedic, a Vision-and-Language medical library. As of 2022, the library contains a dozen reference implementations replicating the state-of-the-art results for problems that range from medical visual question answering and radiology report generation to multimodal representation learning on widely adopted medical datasets. In addition, ViLMedic hosts a model-zoo with more than twenty pretrained models for the above tasks designed to be extensible by researchers but also simple for practitioners. Ultimately, we hope our reproducible pipelines can enable clinical translation and create real impact. The library is available athttps://github.com/jbdel/vilmedic.",
  "keywords": [
    "clinical translation",
    "field",
    "question",
    "we",
    "training",
    "translation",
    "information",
    "learning",
    "visual",
    "the recent field",
    "i",
    "answering",
    "multiple modalities",
    "practitioners",
    "reference"
  ],
  "url": "https://aclanthology.org/2022.acl-demo.3/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}