{
  "id": "2022.findings-acl.61",
  "title": "Read before Generate! Faithful Long Form Question Answering with Machine Reading",
  "authors": [
    "Su, Dan  and\nLi, Xiaoguang  and\nZhang, Jindi  and\nShang, Lifeng  and\nJiang, Xin  and\nLiu, Qun  and\nFung, Pascale"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Long-form question answering (LFQA) aims to generate a paragraph-length answer for a given question. While current work on LFQA using large pre-trained model for generation are effective at producing fluent and somewhat relevant content, one primary challenge lies in how to generate a faithful answer that has less hallucinated content. We propose a new end-to-end framework that jointly models answer generation and machine reading. The key idea is to augment the generation model with fine-grained, answer-related salient information which can be viewed as an emphasis on faithful facts. State-of-the-art results on two LFQA datasets, ELI5 and MS MARCO, demonstrate the effectiveness of our method, in comparison with strong baselines on automatic and human evaluation metrics. A detailed analysis further proves the competency of our methods in generating fluent, relevant, and more faithful answers.",
  "keywords": [
    "work",
    "fine-grained answer-related salient information",
    "end",
    "answer",
    "generation",
    "the generation model",
    "model",
    "machine",
    "human",
    "metrics",
    "salient",
    "lfqa",
    "question",
    "information",
    "form"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.61/",
  "provenance": {
    "collected_at": "2025-06-05 08:35:40",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}