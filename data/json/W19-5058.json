{
  "id": "W19-5058",
  "title": "NCUEE} at {MEDIQA} 2019: Medical Text Inference Using Ensemble {BERT}-{B}i{LSTM}-Attention Model",
  "authors": [
    "Lee, Lung-Hao  and\nLu, Yi  and\nChen, Po-Han  and\nLee, Po-Lei  and\nShyu, Kuo-Kai"
  ],
  "year": "2019",
  "venue": "Proceedings of the 18th BioNLP Workshop and Shared Task",
  "abstract": "This study describes the model design of the NCUEE system for the MEDIQA challenge at the ACL-BioNLP 2019 workshop. We use the BERT (Bidirectional Encoder Representations from Transformers) as the word embedding method to integrate the BiLSTM (Bidirectional Long Short-Term Memory) network with an attention mechanism for medical text inferences. A total of 42 teams participated in natural language inference task at MEDIQA 2019. Our best accuracy score of 0.84 ranked the top-third among all submissions in the leaderboard.",
  "keywords": [
    "ensemble",
    "ensemble bert - b",
    "the bilstm bidirectional",
    "accuracy",
    "transformers",
    "i",
    "lstm -attention model",
    "language",
    "the mediqa challenge",
    "natural",
    "bert",
    "model",
    "text",
    "bilstm",
    "-attention"
  ],
  "url": "https://aclanthology.org/W19-5058/",
  "provenance": {
    "collected_at": "2025-06-05 00:57:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}