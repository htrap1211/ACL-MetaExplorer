{
  "id": "2023.acl-long.903",
  "title": "What Do {NLP} Researchers Believe? Results of the {NLP} Community Metasurvey",
  "authors": [
    "Michael, Julian  and\nHoltzman, Ari  and\nParrish, Alicia  and\nMueller, Aaron  and\nWang, Alex  and\nChen, Angelica  and\nMadaan, Divyam  and\nNangia, Nikita  and\nPang, Richard Yuanzhe  and\nPhang, Jason  and\nBowman, Samuel R."
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We present the results of the NLP Community Metasurvey. Run from May to June 2022, it elicited opinions on controversial issues, including industry influence in the field, concerns about AGI, and ethics. Our results put concrete numbers to several controversies: For example, respondents are split in half on the importance of artificial general intelligence, whether language models understand language, and the necessity of linguistic structure and inductive bias for solving NLP problems. In addition, the survey posed meta-questions, asking respondents to predict the distribution of survey responses. This allows us to uncover false sociological beliefs where the community’s predictions don’t match reality. Among other results, we find that the community greatly overestimates its own belief in the usefulness of benchmarks and the potential for scaling to solve real-world problems, while underestimating its belief in the importance of linguistic structure, inductive bias, and interdisciplinary science.",
  "keywords": [
    "bias",
    "linguistic structure inductive bias",
    "field",
    "several controversies",
    "we",
    "inductive bias",
    "it",
    "science",
    "its belief",
    "controversies",
    "its own belief",
    "language models",
    "beliefs",
    "the nlp community metasurvey",
    "nlp problems"
  ],
  "url": "https://aclanthology.org/2023.acl-long.903/",
  "provenance": {
    "collected_at": "2025-06-05 09:48:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}