{
  "id": "2023.acl-long.50",
  "title": "How About Kind of Generating Hedges using End-to-End Neural Models?",
  "authors": [
    "Abulimiti, Alafate  and\nClavel, Chlo{\\'e}  and\nCassell, Justine"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, “face threat”) to one’s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",
  "keywords": [
    "end",
    "classifier",
    "a hedge classifier",
    "we",
    "instruction",
    "listener",
    "neural",
    "natural",
    "it",
    "hedge generation",
    "disfluencies repetitions",
    "analysis",
    "fine",
    "one s listener",
    "disfluencies"
  ],
  "url": "https://aclanthology.org/2023.acl-long.50/",
  "provenance": {
    "collected_at": "2025-06-05 09:36:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}