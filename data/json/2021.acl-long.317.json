{
  "id": "2021.acl-long.317",
  "title": "Check It Again:Progressive Visual Question Answering via Visual Entailment",
  "authors": [
    "Si, Qingyi  and\nLin, Zheng  and\nZheng, Ming yu  and\nFu, Peng  and\nWang, Weiping"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "While sophisticated neural-based models have achieved remarkable success in Visual Question Answering (VQA), these models tend to answer questions only according to superficial correlations between question and answer. Several recent approaches have been developed to address this language priors problem. However, most of them predict the correct answer according to one best output without checking the authenticity of answers. Besides, they only explore the interaction between image and question, ignoring the semantics of candidate answers. In this paper, we propose a select-and-rerank (SAR) progressive framework based on Visual Entailment. Specifically, we first select the candidate answers relevant to the question or the image, then we rerank the candidate answers by a visual entailment task, which verifies whether the image semantically entails the synthetic statement of the question and each candidate answer. Experimental results show the effectiveness of our proposed framework, which establishes a new state-of-the-art accuracy on VQA-CP v2 with a 7.55% improvement.",
  "keywords": [
    "the semantics",
    "question",
    "we",
    "answer",
    "neural",
    "semantics",
    "it",
    "visual",
    "accuracy",
    "language",
    "vqa",
    "correlations",
    "state",
    "interaction",
    "visual question"
  ],
  "url": "https://aclanthology.org/2021.acl-long.317/",
  "provenance": {
    "collected_at": "2025-06-05 08:03:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}