{
  "id": "2024.acl-long.636",
  "title": "Quantifying Generalizations: Exploring the Divide Between Human and {LLM}s' Sensitivity to Quantification",
  "authors": [
    "Collacciani, Claudia  and\nRambelli, Giulia  and\nBolognesi, Marianna"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., “Birds fly”), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the basis of how we express it (Hampton, 2012; Leslie, 2014).This study investigates how Large Language Models (LLMs) interpret generics, drawing upon psycholinguistic experimental methodologies. Understanding how LLMs interpret generic statements serves not only as a measure of their ability to abstract but also arguably plays a role in their encoding of stereotypes. Given that generics interpretation necessitates a comparison with explicitly quantified sentences, we explored i.) whether LLMs can correctly associate a quantifier with the generic structure, and ii.) whether the presence of a generic sentence as context influences the outcomes of quantifiers. We evaluated LLMs using both Surprisal distributions and prompting techniques.The findings indicate that models do not exhibit a strong sensitivity to quantification. Nevertheless, they seem to encode a meaning linked with the generic structure, which leads them to adjust their answers accordingly when a generalization is provided as context.",
  "keywords": [
    "generics",
    "the generic structure",
    "quantifying generalizations",
    "quantification generics",
    "we",
    "llm",
    "generalizations",
    "it",
    "generics interpretation",
    "leslie",
    "quantifier",
    "llms",
    "a generalization",
    "i",
    "categories"
  ],
  "url": "https://aclanthology.org/2024.acl-long.636/",
  "provenance": {
    "collected_at": "2025-06-05 10:43:04",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}