{
  "id": "2021.semeval-1.153",
  "title": "ES}-{JUST} at {S}em{E}val-2021 Task 7: Detecting and Rating Humor and Offensive Text Using Deep Learning",
  "authors": [
    "Al Bashabsheh, Emran  and\nAbu Alasal, Sanaa"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This research presents the work of the teamâ€™s ES-JUST at semEval-2021 task 7 for detecting and rating humor and offensive text using deep learning. The team evaluates several approaches (i.e.Bert, Roberta, XLM-Roberta, and Bert embedding + Bi-LSTM) that employ in four sub-tasks. The first sub-task deal with whether the text is humorous or not. The second sub-task is the degree of humor in the text if the first sub-task is humorous. The third sub-task represents the text is controversial or not if it is humorous. While in the last task is the degree of an offensive in the text. However, Roberta pre-trained model outperforms other approaches and score the highest in all sub-tasks. We rank on the leader board at the evaluation phase are 14, 15, 20, and 5 through 0.9564 F-score, 0.5709 RMSE, 0.4888 F-score, and 0.4467 RMSE results, respectively, for each of the first, second, third, and fourth sub-task, respectively.",
  "keywords": [
    "deep",
    "work",
    "roberta",
    "bert",
    "model",
    "text",
    "it",
    "deep learning",
    "the evaluation phase",
    "-",
    "we",
    "xlm-roberta",
    "learning",
    "lstm",
    "pre"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.153/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}