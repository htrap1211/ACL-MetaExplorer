{
  "id": "P19-1470",
  "title": "COMET}: Commonsense Transformers for Automatic Knowledge Graph Construction",
  "authors": [
    "Bosselut, Antoine  and\nRashkin, Hannah  and\nSap, Maarten  and\nMalaviya, Chaitanya  and\nCelikyilmaz, Asli  and\nChoi, Yejin"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
  "keywords": [
    "deep",
    "generative models",
    "transformers",
    "precision",
    "automatic knowledge graph construction",
    "we",
    "graph",
    "commonsense knowledge graphs",
    "natural",
    "deep pre-trained language models",
    "rich",
    "generative commonsense models",
    "natural language",
    "91 7 conceptnet precision",
    "generative"
  ],
  "url": "https://aclanthology.org/P19-1470/",
  "provenance": {
    "collected_at": "2025-06-05 00:42:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}