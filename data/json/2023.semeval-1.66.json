{
  "id": "2023.semeval-1.66",
  "title": "Diane Simmons at {S}em{E}val-2023 Task 5: Is it possible to make good clickbait spoilers using a Zero-Shot approach? Check it out!",
  "authors": [
    "Krog, Niels  and\nAgirrezabal, Manex"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "In this paper, we present a possible solution to the SemEval23 shared task of generating spoilers for clickbait headlines. Using a Zero-Shot approach with two different Transformer architectures, BLOOM and RoBERTa, we generate three different types of spoilers: phrase, passage and multi. We found, RoBERTa pretrained for Question-Answering to perform better than BLOOM for causal language modelling, however both architectures proved promising for future attempts at such tasks.",
  "keywords": [
    "transformer",
    "roberta",
    "language",
    "it",
    "causal language modelling",
    "two different transformer",
    "question",
    "we",
    "a zero-shot approach",
    "shot",
    "clickbait",
    "multi",
    "good",
    "approach",
    "spoilers"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.66/",
  "provenance": {
    "collected_at": "2025-06-05 10:27:32",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}