{
  "id": "2020.acl-main.655",
  "title": "Fine-grained Fact Verification with Kernel Graph Attention Network",
  "authors": [
    "Liu, Zhenghao  and\nXiong, Chenyan  and\nSun, Maosong  and\nLiu, Zhiyuan"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Fact Verification requires fine-grained natural language inference capability that finds subtle clues to identify the syntactical and semantically correct but not well-supported claims. This paper presents Kernel Graph Attention Network (KGAT), which conducts more fine-grained fact verification with kernel-based attentions. Given a claim and a set of potential evidence sentences that form an evidence graph, KGAT introduces node kernels, which better measure the importance of the evidence node, and edge kernels, which conduct fine-grained evidence propagation in the graph, into Graph Attention Networks for more accurate fact verification. KGAT achieves a 70.38% FEVER score and significantly outperforms existing fact verification models on FEVER, a large-scale benchmark for fact verification. Our analyses illustrate that, compared to dot-product attentions, the kernel-based attention concentrates more on relevant evidence sentences and meaningful clues in the evidence graph, which is the main source of KGATâ€™s effectiveness. All source codes of this work are available athttps://github.com/thunlp/KernelGAT.",
  "keywords": [
    "kgat s effectiveness",
    "attention network kgat",
    "kernel",
    "attentions",
    "dot-product attentions",
    "graph",
    "kernels",
    "node kernels",
    "kernel-based attentions",
    "natural",
    "the kernel-based attention",
    "edge kernels",
    "work",
    "language",
    "graph attention networks"
  ],
  "url": "https://aclanthology.org/2020.acl-main.655/",
  "provenance": {
    "collected_at": "2025-06-05 07:50:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}