{
  "id": "2020.iwslt-1.9",
  "title": "SRPOL}{'}s System for the {IWSLT} 2020 End-to-End Speech Translation Task",
  "authors": [
    "Potapczyk, Tomasz  and\nPrzybysz, Pawel"
  ],
  "year": "2020",
  "venue": "Proceedings of the 17th International Conference on Spoken Language Translation",
  "abstract": "We took part in the offline End-to-End English to German TED lectures translation task. We based our solution on our last year’s submission. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. To improve the model’s quality of translation we introduced two regularization techniques and trained on machine translated Librispeech corpus in addition to iwslt-corpus, TEDLIUM2 andMust_C corpora. Our best model scored almost 3 BLEU higher than last year’s model. To segment 2020 test set we used exactly the same procedure as last year.",
  "keywords": [
    "transformer",
    "end",
    "model",
    "machine",
    "bleu",
    "encoder",
    "regularization",
    "translation task",
    "layer",
    "we",
    "transformer encoder",
    "resnet-like convolutional layer",
    "two regularization techniques",
    "convolutional",
    "translation"
  ],
  "url": "https://aclanthology.org/2020.iwslt-1.9/",
  "provenance": {
    "collected_at": "2025-06-05 07:56:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}