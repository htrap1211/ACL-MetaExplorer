{
  "id": "2023.findings-acl.537",
  "title": "Multi-Dimensional Evaluation of Text Summarization with In-Context Learning",
  "authors": [
    "Jain, Sameer  and\nKeshava, Vaishakh  and\nMysore Sathyendra, Swarnashree  and\nFernandes, Patrick  and\nLiu, Pengfei  and\nNeubig, Graham  and\nZhou, Chunting"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning-based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.",
  "keywords": [
    "summaries",
    "language",
    "generation",
    "natural",
    "learned evaluation frameworks",
    "text",
    "large language models",
    "text summarization",
    "gpt-3",
    "dimensional",
    "summarization",
    "we",
    "learning",
    "natural language generation nlg",
    "evaluation"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.537/",
  "provenance": {
    "collected_at": "2025-06-05 10:15:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}