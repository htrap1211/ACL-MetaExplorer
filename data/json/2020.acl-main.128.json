{
  "id": "2020.acl-main.128",
  "title": "Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network",
  "authors": [
    "Hou, Yutai  and\nChe, Wanxiang  and\nLai, Yongkui  and\nZhou, Zhihan  and\nLiu, Yijia  and\nLiu, Han  and\nLiu, Ting"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "In this paper, we explore the slot tagging with only a few labeled support sentences (a.k.a. few-shot). Few-shot slot tagging faces a unique challenge compared to the other fewshot classification problems as it calls for modeling the dependencies between labels. But it is hard to apply previously learned label dependencies to an unseen domain, due to the discrepancy of label sets. To tackle this, we introduce a collapsed dependency transfer mechanism into the conditional random field (CRF) to transfer abstract label dependency patterns as transition scores. In the few-shot setting, the emission score of CRF can be calculated as a word’s similarity to the representation of each label. To calculate such similarity, we propose a Label-enhanced Task-Adaptive Projection Network (L-TapNet) based on the state-of-the-art few-shot classification model – TapNet, by leveraging label name semantics in representing labels. Experimental results show that our model significantly outperforms the strongest few-shot learning baseline by 14.64 F1 scores in the one-shot setting.",
  "keywords": [
    "support",
    "field",
    "the few-shot",
    "the dependencies",
    "we",
    "shot",
    "classification",
    "few-shot slot tagging",
    "14 64 f1 scores",
    "collapsed dependency transfer",
    "semantics",
    "it",
    "dependencies",
    "word",
    "learning"
  ],
  "url": "https://aclanthology.org/2020.acl-main.128/",
  "provenance": {
    "collected_at": "2025-06-05 07:43:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}