{
  "id": "2024.findings-acl.124",
  "title": "INTERVENOR}: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair",
  "authors": [
    "Wang, Hanbin  and\nLiu, Zhenghao  and\nWang, Shuo  and\nCui, Ganqu  and\nDing, Ning  and\nLiu, Zhiyuan  and\nYu, Ge"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "This paper introduces INTERVENOR (INTERactiVE chaiN Of Repair), a system designed to emulate the interactive code repair processes observed in humans, encompassing both code diagnosis and code repair. INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair process, functioning as both a Code Learner and a Code Teacher. Specifically, the Code Learner is tasked with adhering to instructions to generate or repair code, while the Code Teacher is responsible for crafting a Chain-of-Repair (CoR) to serve as guidance for the Code Learner. During generating the CoR, the Code Teacher needs to check the generated codes from Code Learner and reassess how to address code bugs based on error feedback received from compilers. Experimental results demonstrate that INTERVENOR surpasses baseline models, exhibiting improvements of approximately 18% and 4.3% over GPT-3.5 in code generation and code translation tasks, respectively. Our further analyses show that CoR is effective to illuminate the reasons behind bugs and outline solution plans in natural language. With the feedback of code compilers, INTERVENOR can accurately identify syntax errors and assertion errors and provide precise instructions to repair codes. All data and codes are available at [https://github.com/NEUIR/INTERVENOR](https://github.com/NEUIR/INTERVENOR).",
  "keywords": [
    "code",
    "feedback",
    "specifically the code learner",
    "chain",
    "code learner",
    "syntax",
    "translation",
    "syntax errors",
    "natural",
    "gpt-3",
    "natural language",
    "cor",
    "the generated codes",
    "the code learner",
    "learner"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.124/",
  "provenance": {
    "collected_at": "2025-06-05 10:50:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}