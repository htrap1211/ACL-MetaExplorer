{
  "id": "P18-1155",
  "title": "From Credit Assignment to Entropy Regularization: Two New Algorithms for Neural Sequence Prediction",
  "authors": [
    "Dai, Zihang  and\nXie, Qizhe  and\nHovy, Eduard"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "In this work, we study the credit assignment problem in reward augmented maximum likelihood (RAML) learning, and establish a theoretical equivalence between the token-level counterpart of RAML and the entropy regularized reinforcement learning. Inspired by the connection, we propose two sequence prediction algorithms, one extending RAML with fine-grained credit assignment and the other improving Actor-Critic with a systematic entropy regularization. On two benchmark datasets, we show the proposed algorithms outperform RAML and Actor-Critic respectively, providing new alternatives to sequence prediction.",
  "keywords": [
    "work",
    "reinforcement",
    "neural",
    "token",
    "regularization",
    "regularization two new algorithms",
    "we",
    "sequence",
    "a systematic entropy regularization",
    "learning",
    "reinforcement learning",
    "entropy",
    "the proposed algorithms",
    "likelihood",
    "connection"
  ],
  "url": "https://aclanthology.org/P18-1155/",
  "provenance": {
    "collected_at": "2025-06-05 00:13:13",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}