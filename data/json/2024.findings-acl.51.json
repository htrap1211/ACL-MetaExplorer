{
  "id": "2024.findings-acl.51",
  "title": "Are {U} a Joke Master? Pun Generation via Multi-Stage Curriculum Learning towards a Humor {LLM",
  "authors": [
    "Chen, Yang  and\nYang, Chong  and\nHu, Tu  and\nChen, Xinhao  and\nLan, Man  and\nCai, Li  and\nZhuang, Xinlin  and\nLin, Xuan  and\nLu, Xin  and\nZhou, Aimin"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Although large language models (LLMs) acquire extensive world knowledge and some reasoning abilities, their proficiency in generating humorous sentences remains a challenge. Previous research has demonstrated that the humor generation capabilities of ChatGPT are confined to producing merely 25 unique jokes. In this work, we concentrate on endowing LLMs with the ability of generating puns, a particular category of humor by preference learning method. We propose a multi-stage curriculum preference learning framework to optimize both pun structure preferences and humor preferences. Specifically, we improve the Direct Preference Optimization (DPO) algorithm to address the challenge of multi-objective alignment problem. Besides, to facilitate further advancement in this field, we collect a Chinese Pun (ChinesePun) dataset, containing 2.1k puns and corresponding annotations. Experimental results on both Chinese and English benchmark datasets demonstrate that our method significantly outperforms all the baseline models.",
  "keywords": [
    "field",
    "we",
    "llm",
    "their proficiency",
    "u",
    "chatgpt",
    "the humor generation capabilities",
    "some reasoning abilities",
    "learning",
    "llms",
    "abilities",
    "objective",
    "large language models llms",
    "multi-objective alignment problem",
    "work"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.51/",
  "provenance": {
    "collected_at": "2025-06-05 10:49:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}