{
  "id": "2022.acl-long.109",
  "title": "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization",
  "authors": [
    "Karn, Sanjeev Kumar  and\nLiu, Ning  and\nSchuetze, Hinrich  and\nFarri, Oladimeji"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist’s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models – which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4%.",
  "keywords": [
    "salient 1 sentences",
    "end",
    "extraction",
    "multi-step radiology report summarization",
    "summarization",
    "we",
    "salient content",
    "salient content acquisition",
    "it",
    "information",
    "rich",
    "abstractive summarization second",
    "radiology report summarization",
    "process",
    "generation"
  ],
  "url": "https://aclanthology.org/2022.acl-long.109/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:46",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}