{
  "id": "2020.acl-main.132",
  "title": "Bridging Anaphora Resolution as Question Answering",
  "authors": [
    "Hou, Yufang"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Most previous studies on bridging anaphora resolution (Poesio et al., 2004; Hou et al., 2013b; Hou, 2018a) use the pairwise model to tackle the problem and assume that the gold mention information is given. In this paper, we cast bridging anaphora resolution as question answering based on context. This allows us to find the antecedent for a given anaphor without knowing any gold mention information (except the anaphor itself). We present a question answering framework (BARQA) for this task, which leverages the power of transfer learning. Furthermore, we propose a novel method to generate a large amount of “quasi-bridging” training data. We show that our model pre-trained on this dataset and fine-tuned on a small amount of in-domain dataset achieves new state-of-the-art results for bridging anaphora resolution on two bridging corpora (ISNotes (Markert et al., 2012) and BASHI (Ro ̈siger, 2018)).",
  "keywords": [
    "most previous studies",
    "model",
    "studies",
    "hou",
    "question",
    "information",
    "us",
    "we",
    "transfer",
    "barqa",
    "et al",
    "training",
    "a large amount",
    "a novel method",
    "isnotes"
  ],
  "url": "https://aclanthology.org/2020.acl-main.132/",
  "provenance": {
    "collected_at": "2025-06-05 07:43:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}