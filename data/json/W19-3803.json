{
  "id": "W19-3803",
  "title": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis",
  "authors": [
    "Friedman, Scott  and\nSchmer-Galunder, Sonja  and\nChen, Anthony  and\nRye, Jeffrey"
  ],
  "year": "2019",
  "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing",
  "abstract": "Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.",
  "keywords": [
    "bias",
    "we",
    "inherent bias",
    "regularities",
    "training",
    "quantifying gender bias",
    "cross",
    "word",
    "99 countries",
    "these metrics",
    "analysis",
    "racial and gender biases",
    "gender biases",
    "text",
    "metrics"
  ],
  "url": "https://aclanthology.org/W19-3803/",
  "provenance": {
    "collected_at": "2025-06-05 00:59:29",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}