{
  "id": "2024.findings-acl.697",
  "title": "Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models",
  "authors": [
    "Sicilia, Anthony  and\nKim, Hyunwoo  and\nChandu, Khyathi  and\nAlikhani, Malihe  and\nHessel, Jack"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Effective interlocutors account for the uncertain goals, beliefs, and emotions of others. But even the best human conversationalist cannot perfectly anticipate the trajectory of a dialogue. How well can language models represent inherent uncertainty in conversations? We propose FortUne Dial, an expansion of the long-standing “conversation forecasting” task: instead of just accuracy, evaluation is conducted with uncertainty-aware metrics, effectively enabling abstention on individual instances. We study two ways in which language models potentially represent outcome uncertainty (internally, using scores and directly, using tokens) and propose fine-tuning strategies to improve calibration of both representations. Experiments on eight difficult negotiation corpora demonstrate that our proposed fine-tuning strategies (a traditional supervision strategy and an off-policy reinforcement learning strategy) can calibrate smaller open-source models to compete with pre-trained models 10x their size.",
  "keywords": [
    "conversations",
    "our proposed fine-tuning strategies",
    "we",
    "dialogue",
    "dial",
    "learning",
    "uncertainty-aware metrics",
    "tuning",
    "fine-tuning strategies",
    "metrics",
    "strategies",
    "language models",
    "beliefs",
    "fine",
    "accuracy"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.697/",
  "provenance": {
    "collected_at": "2025-06-05 10:58:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}