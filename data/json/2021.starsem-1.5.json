{
  "id": "2021.starsem-1.5",
  "title": "Recovering Lexically and Semantically Reused Texts",
  "authors": [
    "MacLaughlin, Ansel  and\nXu, Shaobin  and\nSmith, David A."
  ],
  "year": "2021",
  "venue": "Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics",
  "abstract": "Writers often repurpose material from existing texts when composing new documents. Because most documents have more than one source, we cannot trace these connections using only models of document-level similarity. Instead, this paper considers methods for local text reuse detection (LTRD), detecting localized regions of lexically or semantically similar text embedded in otherwise unrelated material. In extensive experiments, we study the relative performance of four classes of neural and bag-of-words models on three LTRD tasks – detecting plagiarism, modeling journalists’ use of press releases, and identifying scientists’ citation of earlier papers. We conduct evaluations on three existing datasets and a new, publicly-available citation localization dataset. Our findings shed light on a number of previously-unexplored questions in the study of LTRD, including the importance of incorporating document-level context for predictions, the applicability of of-the-shelf neural models pretrained on “general” semantic textual similarity tasks such as paraphrase detection, and the trade-offs between more efficient bag-of-words and feature-based neural models and slower pairwise neural models.",
  "keywords": [
    "more efficient bag",
    "efficient",
    "semantic",
    "we",
    "bag",
    "neural",
    "earlier papers",
    "text",
    "scientists",
    "earlier",
    "general",
    "evaluations",
    "scientists citation",
    "documents",
    "writers"
  ],
  "url": "https://aclanthology.org/2021.starsem-1.5/",
  "provenance": {
    "collected_at": "2025-06-05 08:23:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}