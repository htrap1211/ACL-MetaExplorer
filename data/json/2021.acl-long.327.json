{
  "id": "2021.acl-long.327",
  "title": "Verb Metaphor Detection via Contextual Relation Learning",
  "authors": [
    "Song, Wei  and\nZhou, Shuhui  and\nFu, Ruiji  and\nLiu, Ting  and\nLiu, Lizhen"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Correct natural language understanding requires computers to distinguish the literal and metaphorical senses of a word. Recent neu- ral models achieve progress on verb metaphor detection by viewing it as sequence labeling. In this paper, we argue that it is appropriate to view this task as relation classification between a verb and its various contexts. We propose the Metaphor-relation BERT (Mr-BERT) model, which explicitly models the relation between a verb and its grammatical, sentential and semantic contexts. We evaluate our method on the VUA, MOH-X and TroFi datasets. Our method gets competitive results compared with state-of-the-art approaches.",
  "keywords": [
    "relation classification",
    "language",
    "natural",
    "bert",
    "model",
    "it",
    "ral",
    "semantic",
    "word",
    "we",
    "learning",
    "sequence",
    "classification",
    "recent neu- ral models",
    "contexts"
  ],
  "url": "https://aclanthology.org/2021.acl-long.327/",
  "provenance": {
    "collected_at": "2025-06-05 08:03:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}