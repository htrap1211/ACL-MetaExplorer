{
  "id": "2022.acl-long.321",
  "title": "Semi-Supervised Formality Style Transfer with Consistency Training",
  "authors": [
    "Liu, Ao  and\nWang, An  and\nOkazaki, Naoaki"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Formality style transfer (FST) is a task that involves paraphrasing an informal sentence into a formal one without altering its meaning. To address the data-scarcity problem of existing parallel datasets, previous studies tend to adopt a cycle-reconstruction scheme to utilize additional unlabeled data, where the FST model mainly benefits from target-side unlabeled sentences. In this work, we propose a simple yet effective semi-supervised framework to better utilize source-side unlabeled sentences based on consistency training. Specifically, our approach augments pseudo-parallel data obtained from a source-side informal sentence by enforcing the model to generate similar outputs for its perturbed version. Moreover, we empirically examined the effects of various data perturbation methods and propose effective data filtering strategies to improve our framework. Experimental results on the GYAFC benchmark demonstrate that our approach can achieve state-of-the-art results, even with less than 40% of the parallel data.",
  "keywords": [
    "effective data filtering strategies",
    "we",
    "training",
    "transfer",
    "previous studies",
    "strategies",
    "work",
    "model",
    "studies",
    "its perturbed version",
    "approach",
    "state",
    "a formal one",
    "additional unlabeled data",
    "our framework experimental results"
  ],
  "url": "https://aclanthology.org/2022.acl-long.321/",
  "provenance": {
    "collected_at": "2025-06-05 08:28:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}