{
  "id": "2021.acl-short.34",
  "title": "A Semantics-aware Transformer Model of Relation Linking for Knowledge Base Question Answering",
  "authors": [
    "Naseem, Tahira  and\nRavishankar, Srinivas  and\nMihindukulasooriya, Nandana  and\nAbdelaziz, Ibrahim  and\nLee, Young-Suk  and\nKapanipathi, Pavan  and\nRoukos, Salim  and\nGliozzo, Alfio  and\nGray, Alexander"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Relation linking is a crucial component of Knowledge Base Question Answering systems. Existing systems use a wide variety of heuristics, or ensembles of multiple systems, heavily relying on the surface question text. However, the explicit semantic parse of the question is a rich source of relation information that is not taken advantage of. We propose a simple transformer-based neural model for relation linking that leverages the AMR semantic parse of a sentence. Our system significantly outperforms the state-of-the-art on 4 popular benchmark datasets. These are based on either DBpedia or Wikidata, demonstrating that our approach is effective across KGs.",
  "keywords": [
    "ensembles",
    "transformer",
    "variety",
    "knowledge",
    "neural",
    "a semantics-aware transformer model",
    "model",
    "semantics",
    "text",
    "question",
    "information",
    "rich",
    "semantic",
    "we",
    "kgs"
  ],
  "url": "https://aclanthology.org/2021.acl-short.34/",
  "provenance": {
    "collected_at": "2025-06-05 08:07:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}