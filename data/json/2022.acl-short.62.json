{
  "id": "2022.acl-short.62",
  "title": "On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations",
  "authors": [
    "Cao, Yang Trista  and\nPruksachatkun, Yada  and\nChang, Kai-Wei  and\nGupta, Rahul  and\nKumar, Varun  and\nDhamala, Jwala  and\nGalstyan, Aram"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Multiple metrics have been introduced to measure fairness in various natural language processing tasks. These metrics can be roughly categorized into two categories: 1) extrinsic metrics for evaluating fairness in downstream applications and 2) intrinsic metrics for estimating fairness in upstream contextualized language representation models. In this paper, we conduct an extensive correlation study between intrinsic and extrinsic metrics across bias notions using 19 contextualized language models. We find that intrinsic and extrinsic metrics do not necessarily correlate in their original setting, even when correcting for metric misalignments, noise in evaluation datasets, and confounding factors such as experiment configuration for extrinsic metrics.",
  "keywords": [
    "processing",
    "bias",
    "language",
    "natural",
    "categories",
    "metric",
    "bias notions",
    "misalignments",
    "metrics",
    "19 contextualized language models",
    "metric misalignments",
    "multiple metrics",
    "extrinsic metrics",
    "we",
    "1 extrinsic metrics"
  ],
  "url": "https://aclanthology.org/2022.acl-short.62/",
  "provenance": {
    "collected_at": "2025-06-05 08:33:15",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}