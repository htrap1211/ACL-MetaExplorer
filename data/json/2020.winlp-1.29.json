{
  "id": "2020.winlp-1.29",
  "title": "The human unlikeness of neural language models in next-word prediction",
  "authors": [
    "Jacobs, Cassandra L.  and\nMcCarthy, Arya D."
  ],
  "year": "2020",
  "venue": "Proceedings of the Fourth Widening Natural Language Processing Workshop",
  "abstract": "The training objective of unidirectional language models (LMs) is similar to a psycholinguistic benchmark known as the cloze task, which measures next-word predictability. However, LMs lack the rich set of experiences that people do, and humans can be highly creative. To assess human parity in these modelsâ€™ training objective, we compare the predictions of three neural language models to those of human participants in a freely available behavioral dataset (Luke & Christianson, 2016). Our results show that while neural models show a close correspondence to human productions, they nevertheless assign insufficient probability to how often speakers guess upcoming words, especially for open-class content words.",
  "keywords": [
    "language",
    "neural",
    "experiences",
    "objective",
    "human",
    "class",
    "rich",
    "the training objective",
    "word",
    "we",
    "neural language models",
    "unidirectional language models lms",
    "three neural language models",
    "insufficient",
    "insufficient probability"
  ],
  "url": "https://aclanthology.org/2020.winlp-1.29/",
  "provenance": {
    "collected_at": "2025-06-05 07:59:13",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}