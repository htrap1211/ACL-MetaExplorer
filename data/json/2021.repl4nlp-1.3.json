{
  "id": "2021.repl4nlp-1.3",
  "title": "Comprehension Based Question Answering using Bloom{'}s Taxonomy",
  "authors": [
    "Sahu, Pritish  and\nCogswell, Michael  and\nDivakaran, Ajay  and\nRutherford-Quach, Sara"
  ],
  "year": "2021",
  "venue": "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)",
  "abstract": "Current pre-trained language models have lots of knowledge, but a more limited ability to use that knowledge. Bloomâ€™s Taxonomy helps educators teach children how to use knowledge by categorizing comprehension skills, so we use it to analyze and improve the comprehension skills of large pre-trained language models. Our experiments focus on zero-shot question answering, using the taxonomy to provide proximal context that helps the model answer questions by being relevant to those questions. We show targeting context in this manner improves performance across 4 popular common sense question answer datasets.",
  "keywords": [
    "knowledge",
    "language",
    "large pre-trained language models",
    "answer",
    "model",
    "it",
    "question",
    "current pre-trained language models",
    "this manner",
    "we",
    "zero-shot question",
    "pre",
    "current",
    "shot",
    "manner"
  ],
  "url": "https://aclanthology.org/2021.repl4nlp-1.3/",
  "provenance": {
    "collected_at": "2025-06-05 08:19:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}