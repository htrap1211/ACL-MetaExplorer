{
  "id": "2024.acl-long.764",
  "title": "EWEK}-{QA} : Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems",
  "authors": [
    "Dehghan, Mohammad  and\nAlomrani, Mohammad  and\nBagga, Sunyam  and\nAlfonso-Hermelo, David  and\nBibi, Khalil  and\nGhaddar, Abbas  and\nZhang, Yingxue  and\nLi, Xiaoguang  and\nHao, Jianye  and\nLiu, Qun  and\nLin, Jimmy  and\nChen, Boxing  and\nParthasarathi, Prasanna  and\nBiparva, Mahdi  and\nRezagholizadeh, Mehdi"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The emerging citation-based QA systems are gaining more attention especially in generative AI search applications. The importance of extracted knowledge provided to these systems is vital from both accuracy (completeness of information) and efficiency (extracting the information in a timely manner). In this regard, citation-based QA systems are suffering from two shortcomings. First, they usually rely only on web as a source of extracted knowledge and adding other external knowledge sources can hamper the efficiency of the system. Second, web-retrieved contents are usually obtained by some simple heuristics such as fixed length or breakpoints which might lead to splitting information into pieces. To mitigate these issues, we propose our enhanced web and efficient knowledge graph (KG) retrieval solution (EWEK-QA) to enrich the content of the extracted knowledge fed to the system. This has been done through designing an adaptive web retriever and incorporating KGs triples in an efficient manner. We demonstrate the effectiveness of over the open-source state-of-the-art (SoTA) web-based and KG baseline models using a comprehensive set of quantitative and human evaluation experiments. Our model is able to: first, improve the web-retriever baseline in terms of extracting more relevant passages (>20%), the coverage of answer span (>25%) and self containment (>35%); second, obtain and integrate KG triples into its pipeline very efficiently (by avoiding any LLM calls) to outperform the web-only and KG-only SoTA baselines significantly in 7 quantitative QA tasks and our human evaluation.",
  "keywords": [
    "efficient knowledge graph retrieval",
    "efficient",
    "question",
    "efficiency",
    "a timely manner",
    "we",
    "graph",
    "llm",
    "answer",
    "self",
    "the efficiency",
    "retrieval",
    "information",
    "pieces",
    "kg triples"
  ],
  "url": "https://aclanthology.org/2024.acl-long.764/",
  "provenance": {
    "collected_at": "2025-06-05 10:44:49",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}