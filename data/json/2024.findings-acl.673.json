{
  "id": "2024.findings-acl.673",
  "title": "Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction",
  "authors": [
    "Li, Xiaoyuan  and\nWang, Wenjie  and\nLi, Moxin  and\nGuo, Junrong  and\nZhang, Yang  and\nFeng, Fuli"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual perspective of examiner regarding error identification and correction.From the examiner perspective, we define four evaluation tasks for error identification and correction along with a new dataset with annotated error types and steps. We also design diverse prompts to thoroughly evaluate eleven representative LLMs. Our principal findings indicate that GPT-4 outperforms all models, while open-source model LLaMA-2-7B demonstrates comparable abilities to closed-source models GPT-3.5 and Gemini Pro.Notably, calculation error proves the most challenging error type. Moreover, prompting LLMs with the error types can improve the average correction accuracy by 47.9%. These results reveal potential directions for developing the mathematical reasoning abilities of LLMs.Our code and dataset is available on https://github.com/LittleCirc1e/EIC.",
  "keywords": [
    "code",
    "we",
    "examiner",
    "comparable abilities",
    "diverse prompts",
    "comprehensive evaluations",
    "llms",
    "abilities",
    "the average correction accuracy",
    "gpt-4",
    "the examiner perspective",
    "four evaluation tasks",
    "accuracy",
    "prompts",
    "language"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.673/",
  "provenance": {
    "collected_at": "2025-06-05 10:57:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}