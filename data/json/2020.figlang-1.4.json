{
  "id": "2020.figlang-1.4",
  "title": "D}eep{M}et: A Reading Comprehension Paradigm for Token-level Metaphor Detection",
  "authors": [
    "Su, Chuandong  and\nFukumoto, Fumiyo  and\nHuang, Xiaoxi  and\nLi, Jiyi  and\nWang, Rongbo  and\nChen, Zhiqun"
  ],
  "year": "2020",
  "venue": "Proceedings of the Second Workshop on Figurative Language Processing",
  "abstract": "Machine metaphor understanding is one of the major topics in NLP. Most of the recent attempts consider it as classification or sequence tagging task. However, few types of research introduce the rich linguistic information into the field of computational metaphor by leveraging powerful pre-training language models. We focus a novel reading comprehension paradigm for solving the token-level metaphor detection task which provides an innovative type of solution for this task. We propose an end-to-end deep metaphor detection model named DeepMet based on this paradigm. The proposed approach encodes the global text context (whole sentence), local text context (sentence fragments), and question (query word) information as well as incorporating two types of part-of-speech (POS) features by making use of the advanced pre-training language model. The experimental results by using several metaphor datasets show that our model achieves competitive results in the second shared task on metaphor detection.",
  "keywords": [
    "deep",
    "end",
    "powerful pre-training language models",
    "field",
    "question",
    "we",
    "training",
    "classification",
    "the field",
    "it",
    "token",
    "information",
    "rich",
    "word",
    "sequence"
  ],
  "url": "https://aclanthology.org/2020.figlang-1.4/",
  "provenance": {
    "collected_at": "2025-06-05 07:55:36",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}