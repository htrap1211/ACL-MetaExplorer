{
  "id": "2024.acl-long.658",
  "title": "V}is{D}ia{H}al{B}ench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models",
  "authors": [
    "Cao, Qingxing  and\nCheng, Junhao  and\nLiang, Xiaodan  and\nLin, Liang"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Despite the significant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hallucination problem, where the LVLMsâ€™ response contains descriptions of non-existent objects. Although various benchmarks have been proposed to investigate this problem, they mostly focus on single-turn evaluation and overlook the hallucination raised by textual inputs. To investigate the hallucination problem of LVLMs when given long-term misleading textual history, we propose a novel visual dialogue hallucination evaluation benchmark VisDiaHalBench. The benchmark consists of samples with five-turn questions about an edited image and its original version. VisDiaHalBench differs from previous hallucination benchmarks in the following three points: 1) The questions and answers are unambiguously grounded by annotated scene graphs. 2) The images are uncommonly edited to inspect the visual model and common-object hallucination in LLMs. 3) The carefully designed dialogue refers a same object in different turns to assess the image consistency and influence of history for LVLMs. The detailed analysis of several state-of-the-art LVLMs across image consistency, visual understanding, history influence, and other dimensions reveals their substantial performance gap with single-turn VQA tasks. The benchmark is released in: https://github.com/qingxingcao/VisDiaHalBench",
  "keywords": [
    "single-turn evaluation",
    "we",
    "dialogue",
    "v",
    "some studies",
    "large vision-language models",
    "visual",
    "analysis",
    "llms",
    "object",
    "a visual dialogue benchmark",
    "ia",
    "the carefully designed dialogue",
    "d",
    "language"
  ],
  "url": "https://aclanthology.org/2024.acl-long.658/",
  "provenance": {
    "collected_at": "2025-06-05 10:43:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}