{
  "id": "2024.findings-acl.916",
  "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models",
  "authors": [
    "Xu, Ran  and\nCui, Hejie  and\nYu, Yue  and\nKan, Xuan  and\nShi, Wenqi  and\nZhuang, Yuchen  and\nWang, May Dongmei  and\nJin, Wei  and\nHo, Joyce  and\nYang, Carl"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation with LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 8 clinical NLP tasks and 18 datasets reveals that ClinGen consistently enhances performance across various tasks by 7.7%-8.7% on average, effectively aligning the distribution of real datasets and enriching the diversity of generated training instances.",
  "keywords": [
    "extraction",
    "efficient",
    "clinical text data generation",
    "external domain-specific knowledge graphs",
    "we",
    "generated training instances",
    "8 clinical nlp tasks",
    "llm",
    "training",
    "data generation",
    "clinical natural language processing",
    "natural",
    "synthetic clinical text generation",
    "clinical nlp tasks",
    "llms"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.916/",
  "provenance": {
    "collected_at": "2025-06-05 11:01:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}