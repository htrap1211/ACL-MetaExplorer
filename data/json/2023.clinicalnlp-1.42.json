{
  "id": "2023.clinicalnlp-1.42",
  "title": "Teddysum at {MEDIQA}-Chat 2023: an analysis of fine-tuning strategy for long dialog summarization",
  "authors": [
    "Jeong, Yongbin  and\nHan, Ju-Hyuck  and\nChae, Kyung Min  and\nCho, Yousang  and\nSeo, Hyunbin  and\nLim, KyungTae  and\nChoi, Key-Sun  and\nHahm, Younggyun"
  ],
  "year": "2023",
  "venue": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
  "abstract": "In this paper, we introduce the design and various attempts for TaskB of MEDIQA-Chat 2023. The goal of TaskB in MEDIQA-Chat 2023 is to generate full clinical note from doctor-patient consultation dialogues. This task has several challenging issues, such as lack of training data, handling long dialogue inputs, and generating semi-structured clinical note which have section heads. To address these issues, we conducted various experiments and analyzed their results. We utilized the DialogLED model pre-trained on long dialogue data to handle long inputs, and we pre-trained on other dialogue datasets to address the lack of training data. We also attempted methods such as using prompts and contrastive learning for handling sections. This paper provides insights into clinical note generation through analyzing experimental methods and results, and it suggests future research directions.",
  "keywords": [
    "long dialogue data",
    "summarization",
    "we",
    "dialogue",
    "training",
    "long dialogue inputs",
    "it",
    "mediqa-chat",
    "learning",
    "fine-tuning strategy",
    "analysis",
    "tuning",
    "other dialogue datasets",
    "fine",
    "clinical note generation"
  ],
  "url": "https://aclanthology.org/2023.clinicalnlp-1.42/",
  "provenance": {
    "collected_at": "2025-06-05 10:23:51",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}