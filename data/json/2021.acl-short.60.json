{
  "id": "2021.acl-short.60",
  "title": "In Factuality: Efficient Integration of Relevant Facts for Visual Question Answering",
  "authors": [
    "Vickers, Peter  and\nAletras, Nikolaos  and\nMonti, Emilio  and\nBarrault, Lo{\\\"i}c"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Visual Question Answering (VQA) methods aim at leveraging visual input to answer questions that may require complex reasoning over entities. Current models are trained on labelled data that may be insufficient to learn complex knowledge representations. In this paper, we propose a new method to enhance the reasoning capabilities of a multi-modal pretrained model (Vision+Language BERT) by integrating facts extracted from an external knowledge base. Evaluation on the KVQA dataset benchmark demonstrates that our method outperforms competitive baselines by 19%, achieving new state-of-the-art results. We also perform an extensive analysis highlighting the limitations of our best performing model through an ablation study.",
  "keywords": [
    "entities current models",
    "knowledge",
    "the kvqa dataset benchmark",
    "factuality efficient integration",
    "language",
    "kvqa",
    "bert",
    "model",
    "entities",
    "vqa methods",
    "efficient",
    "question",
    "capabilities",
    "we",
    "visual"
  ],
  "url": "https://aclanthology.org/2021.acl-short.60/",
  "provenance": {
    "collected_at": "2025-06-05 08:07:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}