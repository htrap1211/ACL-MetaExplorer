{
  "id": "2020.acl-main.1",
  "title": "Learning to Understand Child-directed and Adult-directed Speech",
  "authors": [
    "Gelderloos, Lieke  and\nChrupa{\\l}a, Grzegorz  and\nAlishahi, Afra"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Speech directed to children differs from adult-directed speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.",
  "keywords": [
    "language",
    "learners",
    "acoustic properties",
    "human",
    "properties",
    "information",
    "semantic",
    "word",
    "we",
    "semantic information",
    "language learners",
    "speech",
    "acoustically comparable synthetic speech",
    "indications",
    "repetition"
  ],
  "url": "https://aclanthology.org/2020.acl-main.1/",
  "provenance": {
    "collected_at": "2025-06-05 07:42:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}