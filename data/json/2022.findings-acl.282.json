{
  "id": "2022.findings-acl.282",
  "title": "Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach",
  "authors": [
    "Lv, Xin  and\nLin, Yankai  and\nCao, Yixin  and\nHou, Lei  and\nLi, Juanzi  and\nLiu, Zhiyuan  and\nLi, Peng  and\nZhou, Jie"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "In recent years, pre-trained language models (PLMs) have been shown to capture factual knowledge from massive texts, which encourages the proposal of PLM-based knowledge graph completion (KGC) models. However, these models are still quite behind the SOTA KGC models in terms of performance. In this work, we find two main reasons for the weak performance: (1) Inaccurate evaluation setting. The evaluation setting under the closed-world assumption (CWA) may underestimate the PLM-based KGC models since they introduce more external knowledge; (2) Inappropriate utilization of PLMs. Most PLM-based KGC models simply splice the labels of entities and relations as inputs, leading to incoherent sentences that do not take full advantage of the implicit knowledge in PLMs. To alleviate these problems, we highlight a more accurate evaluation setting under the open-world assumption (OWA), which manual checks the correctness of knowledge that is not in KGs. Moreover, motivated by prompt tuning, we propose a novel PLM-based KGC model named PKGC. The basic idea is to convert each triple and its support information into natural prompt sentences, which is further fed into PLMs for classification. Experiment results on two KGC datasets demonstrate OWA is more reliable for evaluating KGC, especially on the link prediction, and the effectiveness of our PKCG model on both CWA and OWA settings.",
  "keywords": [
    "a reliable evaluation",
    "support",
    "classification experiment results",
    "pkgc",
    "kgc",
    "we",
    "graph",
    "the sota kgc models",
    "classification",
    "natural",
    "knowledge graph completion",
    "1 inaccurate evaluation",
    "information",
    "pre-trained language models plms",
    "the plm-based kgc models"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.282/",
  "provenance": {
    "collected_at": "2025-06-05 08:38:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}