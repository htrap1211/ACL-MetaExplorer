{
  "id": "2022.dravidianlangtech-1.36",
  "title": "O}ptimize{\\_}{P}rime@{D}ravidian{L}ang{T}ech-{ACL}2022: Abusive Comment Detection in {T}amil",
  "authors": [
    "Patankar, Shantanu  and\nGokhale, Omkar  and\nLitake, Onkar  and\nMandke, Aditya  and\nKadam, Dipali"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages",
  "abstract": "This paper tries to address the problem of abusive comment detection in low-resource indic languages. Abusive comments are statements that are offensive to a person or a group of people. These comments are targeted toward individuals belonging to specific ethnicities, genders, caste, race, sexuality, etc. Abusive Comment Detection is a significant problem, especially with the recent rise in social media users. This paper presents the approach used by our team — Optimize_Prime, in the ACL 2022 shared task “Abusive Comment Detection in Tamil.” This task detects and classifies YouTube comments in Tamil and Tamil-English Codemixed format into multiple categories. We have used three methods to optimize our results: Ensemble models, Recurrent Neural Networks, and Transformers. In the Tamil data, MuRIL and XLM-RoBERTA were our best performing models with a macro-averaged f1 score of 0.43. Furthermore, for the Code-mixed data, MuRIL and M-BERT provided sublime results, with a macro-averaged f1 score of 0.45.",
  "keywords": [
    "code",
    "transformers",
    "roberta",
    "we",
    "ethnicities",
    "specific ethnicities genders",
    "classifies",
    "ensemble",
    "neural",
    "ensemble models",
    "format",
    "ang",
    "m",
    "categories",
    "neural networks"
  ],
  "url": "https://aclanthology.org/2022.dravidianlangtech-1.36/",
  "provenance": {
    "collected_at": "2025-06-05 08:41:57",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}