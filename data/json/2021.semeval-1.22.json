{
  "id": "2021.semeval-1.22",
  "title": "IIE}-{NLP}-Eyas at {S}em{E}val-2021 Task 4: Enhancing {PLM} for {R}e{CAM} with Special Tokens, Re-Ranking, {S}iamese Encoders and Back Translation",
  "authors": [
    "Xie, Yuqiang  and\nXing, Luxi  and\nPeng, Wei  and\nHu, Yue"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper introduces our systems for all three subtasks of SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning. To help our model better represent and understand abstract concepts in natural language, we well-design many simple and effective approaches adapted to the backbone model (RoBERTa). Specifically, we formalize the subtasks into the multiple-choice question answering format and add special tokens to abstract concepts, then, the final prediction of QA is considered as the result of subtasks. Additionally, we employ many finetuning tricks to improve the performance. Experimental results show that our approach gains significant performance compared with the baseline systems. Our system achieves eighth rank (87.51%) and tenth rank (89.64%) on the official blind test set of subtask 1 and subtask 2 respectively.",
  "keywords": [
    "roberta",
    "question",
    "ranking s iamese encoders",
    "we",
    "the backbone model roberta",
    "translation",
    "iie",
    "natural",
    "format",
    "iie - nlp -eyas",
    "natural language",
    "encoders",
    "language",
    "back translation",
    "nlp"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.22/",
  "provenance": {
    "collected_at": "2025-06-05 08:20:03",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}