{
  "id": "2022.acl-long.178",
  "title": "Hierarchical Sketch Induction for Paraphrase Generation",
  "authors": [
    "Hosking, Tom  and\nTang, Hao  and\nLapata, Mirella"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We propose a generative model of paraphrase generation, that encourages syntactic diversity by conditioning on an explicit syntactic sketch. We introduce Hierarchical Refinement Quantized Variational Autoencoders (HRQ-VAE), a method for learning decompositions of dense encodings as a sequence of discrete latent variables that make iterative refinements of increasing granularity. This hierarchy of codes is learned through end-to-end training, and represents fine-to-coarse grained information about the input. We use HRQ-VAE to encode the syntactic form of an input sentence as a path through the hierarchy, allowing us to more easily predict syntactic sketches at test time. Extensive experiments, including a human evaluation, confirm that HRQ-VAE learns a hierarchical representation of the input space, and generates paraphrases of higher quality than previous systems.",
  "keywords": [
    "end",
    "paraphrase generation",
    "a human evaluation",
    "the hierarchy",
    "form",
    "we",
    "training",
    "autoencoders",
    "a hierarchical representation",
    "information",
    "latent",
    "sequence",
    "this hierarchy",
    "variational autoencoders",
    "generative"
  ],
  "url": "https://aclanthology.org/2022.acl-long.178/",
  "provenance": {
    "collected_at": "2025-06-05 08:26:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}