{
  "id": "2022.acl-short.56",
  "title": "Fire Burns, Sword Cuts: Commonsense Inductive Bias for Exploration in Text-based Games",
  "authors": [
    "Ryu, Dongwon  and\nShareghi, Ehsan  and\nFang, Meng  and\nXu, Yunqiu  and\nPan, Shirui  and\nHaf, Reza"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Text-based games (TGs) are exciting testbeds for developing deep reinforcement learning techniques due to their partially observed environments and large action spaces. In these games, the agent learns to explore the environment via natural language interactions with the game simulator. A fundamental challenge in TGs is the efficient exploration of the large action space when the agent has not yet acquired enough knowledge about the environment. We propose CommExpl, an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training when the agent is the most uncertain about its next action. Our method exhibits improvement on the collected game scores during the training in four out of nine games from Jericho. Additionally, the produced trajectory of actions exhibit lower perplexity, when tested with a pretrained LM, indicating better closeness to human language.",
  "keywords": [
    "deep",
    "bias",
    "efficient",
    "we",
    "training",
    "natural",
    "learning",
    "lower perplexity",
    "a pretrained language model",
    "text",
    "perplexity",
    "the efficient exploration",
    "action",
    "reinforcement",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2022.acl-short.56/",
  "provenance": {
    "collected_at": "2025-06-05 08:33:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}