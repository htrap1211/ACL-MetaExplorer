{
  "id": "2024.acl-long.816",
  "title": "Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models",
  "authors": [
    "R{\\\"o}ttger, Paul  and\nHofmann, Valentin  and\nPyatkin, Valentina  and\nHinck, Musashi  and\nKirk, Hannah  and\nSchuetze, Hinrich  and\nHovy, Dirk"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing *constrained* evaluation paradigm for values and opinions in LLMs and explore more realistic *unconstrained* evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT *forces models to comply with the PCTâ€™s multiple-choice format. We show that models give substantively different answers when not forced; that answers change depending on how models are forced; and that answers lack paraphrase robustness. Then, we demonstrate that models give different answers yet again in a more realistic open-ended answer setting. We distill these findings into recommendations and open challenges in evaluating values and opinions in LLMs.",
  "keywords": [
    "a systematic review",
    "we",
    "more realistic unconstrained evaluations",
    "current",
    "llm",
    "answer",
    "format",
    "llms",
    "example politically-biased llms",
    "large language models llms",
    "current evaluations",
    "society",
    "work",
    "language",
    "evaluations"
  ],
  "url": "https://aclanthology.org/2024.acl-long.816/",
  "provenance": {
    "collected_at": "2025-06-05 10:45:32",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}