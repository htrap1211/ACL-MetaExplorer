{
  "id": "2023.acl-long.742",
  "title": "Dense-{ATOMIC}: Towards Densely-connected {ATOMIC} with High Knowledge Coverage and Massive Multi-hop Paths",
  "authors": [
    "Shen, Xiangqing  and\nWu, Siwei  and\nXia, Rui"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing everyday if-then knowledge triplets, i.e., head event, relation, tail event. The one-hop annotation manner made ATOMIC a set of independent bipartite graphs, which ignored the numerous links between events in different bipartite graphs and consequently caused shortages in knowledge coverage and multi-hop paths. In this work, we aim to construct Dense-ATOMIC with high knowledge coverage and massive multi-hop paths. The events in ATOMIC are normalized to a consistent pattern at first. We then propose a CSKG completion method called Rel-CSKGC to predict the relation given the head event and the tail event of a triplet, and train a CSKG completion model based on existing triplets in ATOMIC. We finally utilize the model to complete the missing links in ATOMIC and accordingly construct Dense-ATOMIC. Both automatic and human evaluation on an annotated subgraph of ATOMIC demonstrate the advantage of Rel-CSKGC over strong baselines. We further conduct extensive evaluations on Dense-ATOMIC in terms of statistics, human evaluation, and simple downstream tasks, all proving Dense-ATOMICâ€™s advantages in Knowledge Coverage and Multi-hop Paths. Both the source code of Rel-CSKGC and Dense-ATOMIC are publicly available onhttps://github.com/NUSTM/Dense-ATOMIC.",
  "keywords": [
    "code",
    "rel-cskgc",
    "a cskg completion model",
    "all",
    "we",
    "cskgc",
    "graph",
    "rel",
    "cskg",
    "manner",
    "the one-hop annotation manner",
    "extensive evaluations",
    "statistics human evaluation",
    "work",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2023.acl-long.742/",
  "provenance": {
    "collected_at": "2025-06-05 09:45:43",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}