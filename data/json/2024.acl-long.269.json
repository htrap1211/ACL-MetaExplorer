{
  "id": "2024.acl-long.269",
  "title": "M}ap{C}oder: Multi-Agent Code Generation for Competitive Problem Solving",
  "authors": [
    "Islam, Md. Ashraful  and\nAli, Mohammed Eunus  and\nParvez, Md Rizwan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Code synthesis, which requires a deep understanding of complex natural language (NL) problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. Thus, while large language models (LLMs) demonstrate impressive proficiency in natural language processing (NLP), their performance in code generation tasks remains limited. In this paper, we introduce a new approach to code generation tasks leveraging the multi-agent prompting that uniquely replicates the full cycle of program synthesis as observed in human developers. Our framework, MapCoder, consists of four LLM agents specifically designed to emulate the stages of this cycle: recalling relevant examples, planning, code generation, and debugging. After conducting thorough experiments, with multiple LLMs ablations and analyses across eight challenging competitive problem-solving and program synthesis benchmarks—MapCoder showcases remarkable code generation capabilities, achieving their new state-of-the-art (pass@1) results—(HumanEval 93.9%, MBPP 83.1%, APPS 22.0%, CodeContests 28.5%, and xCodeEval 45.3%). Moreover, our method consistently delivers superior performance across various programming languages and varying problem difficulties. We open-source our framework at https://github.com/Md-Ashraful-Pramanik/MapCoder.",
  "keywords": [
    "deep",
    "code",
    "code generation tasks",
    "we",
    "llm",
    "natural",
    "natural language processing",
    "four llm agents",
    "difficulties",
    "llms",
    "processing",
    "large language models llms",
    "ap",
    "impressive proficiency",
    "proficiency"
  ],
  "url": "https://aclanthology.org/2024.acl-long.269/",
  "provenance": {
    "collected_at": "2025-06-05 10:37:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}