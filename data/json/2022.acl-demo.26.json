{
  "id": "2022.acl-demo.26",
  "title": "Adaptor: Objective-Centric Adaptation Framework for Language Models",
  "authors": [
    "{\\v{S}}tef{\\'a}nik, Michal  and\nNovotn{\\'y}, V{\\'i}t  and\nGroverov{\\'a}, Nikola  and\nSojka, Petr"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "This paper introduces Adaptor library, which transposes traditional model-centric approach composed of pre-training + fine-tuning steps to objective-centric approach, composing the training process by applications of selected objectives. We survey research directions that can benefit from enhanced objective-centric experimentation in multitask training, custom objectives development, dynamic training curricula, or domain adaptation. Adaptor aims to ease reproducibility of these research directions in practice. Finally, we demonstrate the practical applicability of Adaptor in selected unsupervised domain adaptation scenarios.",
  "keywords": [
    "process",
    "objectives",
    "language",
    "model",
    "objective",
    "selected objectives",
    "language models",
    "fine",
    "we",
    "enhanced objective-centric experimentation",
    "pre",
    "adaptor objective-centric adaptation framework",
    "pre-training fine-tuning steps",
    "training",
    "objective-centric approach"
  ],
  "url": "https://aclanthology.org/2022.acl-demo.26/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}