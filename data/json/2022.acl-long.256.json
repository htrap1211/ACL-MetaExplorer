{
  "id": "2022.acl-long.256",
  "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented Data",
  "authors": [
    "Joshi, Nitish  and\nHe, He"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data. Recent work has explored using counterfactually-augmented data (CAD)—data generated by minimally perturbing examples to flip the ground-truth label—to identify robust features that are invariant under distribution shift. However, empirical results using CAD during training for OOD generalization have been mixed. To explain this discrepancy, through a toy theoretical example and empirical analysis on two crowdsourced CAD datasets, we show that: (a) while features perturbed in CAD are indeed robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data. Our results thus show that the lack of perturbation diversity limits CAD’s effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples.",
  "keywords": [
    "we",
    "training",
    "natural",
    "it",
    "analysis",
    "generalization",
    "ood generalization",
    "while pretrained language models",
    "work",
    "language",
    "model",
    "excellent performance",
    "correlations",
    "effectiveness",
    "diversity"
  ],
  "url": "https://aclanthology.org/2022.acl-long.256/",
  "provenance": {
    "collected_at": "2025-06-05 08:27:45",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}