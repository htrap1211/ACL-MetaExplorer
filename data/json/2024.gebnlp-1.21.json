{
  "id": "2024.gebnlp-1.21",
  "title": "Evaluating Gender Bias in Multilingual Multimodal {AI} Models: Insights from an {I}ndian Context",
  "authors": [
    "Ghate, Kshitish  and\nChoudhry, Arjun  and\nBannihatti Kumar, Vanya"
  ],
  "year": "2024",
  "venue": "Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
  "abstract": "We evaluate gender biases in multilingual multimodal image and text models in two settings: text-to-image retrieval and text-to-image generation, to show that even seemingly gender-neutral traits generate biased results. We evaluate our framework in the context of people from India, working with two languages: English and Hindi. We work with frameworks built around mCLIP-based models to ensure a thorough evaluation of recent state-of-the-art models in the multilingual setting due to their potential for widespread applications. We analyze the results across 50 traits for retrieval and 8 traits for generation, showing that current multilingual multimodal models are biased towards men for most traits, and this problem is further exacerbated for lower-resource languages like Hindi. We further discuss potential reasons behind this observation, particularly stemming from the bias introduced by the pretraining datasets.",
  "keywords": [
    "the bias",
    "bias",
    "generation",
    "biased results",
    "text",
    "gender bias",
    "a thorough evaluation",
    "retrieval",
    "we",
    "evaluation",
    "biased",
    "current",
    "biases",
    "men",
    "gender biases"
  ],
  "url": "https://aclanthology.org/2024.gebnlp-1.21/",
  "provenance": {
    "collected_at": "2025-06-05 11:06:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}