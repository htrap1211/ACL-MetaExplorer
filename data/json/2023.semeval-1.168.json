{
  "id": "2023.semeval-1.168",
  "title": "Team {JUSTR}00 at {S}em{E}val-2023 Task 3: Transformers for News Articles Classification",
  "authors": [
    "Al-Qarqaz, Ahmed  and\nAbdullah, Malak"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "The SemEval-2023 Task 3 competition offers participants a multi-lingual dataset with three schemes one for each subtask. The competition challenges participants to construct machine learning systems that can categorize news articles based on their nature and style of writing. We esperiment with many state-of-the-art transformer-based language models proposed in the natural language processing literature and report the results of the best ones. Our top performing model is based on a transformer called “Longformer” and has achieved an F1-Micro score of 0.256 on the English version of subtask-1 and F1-Macro of 0.442 on subtask-2 on the test data. We also experiment with a number of state-of-the-art multi-lingual transformer-based models and report the results of the best performing ones.",
  "keywords": [
    "transformer",
    "transformers",
    "processing",
    "language",
    "natural",
    "an f1-micro score",
    "machine",
    "model",
    "we",
    "machine learning systems",
    "3 transformers",
    "a transformer",
    "subtask-1 and f1-macro",
    "that",
    "news"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.168/",
  "provenance": {
    "collected_at": "2025-06-05 10:28:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}