{
  "id": "2023.findings-acl.369",
  "title": "Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection",
  "authors": [
    "Iskander, Shadi  and\nRadinsky, Kira  and\nBelinkov, Yonatan"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the modelâ€™s representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.",
  "keywords": [
    "bias",
    "encode social biases",
    "encode",
    "classifiers",
    "we",
    "current",
    "neural classifiers",
    "neural",
    "natural",
    "information",
    "processing",
    "downstream task accuracy",
    "intrinsic and extrinsic evaluations",
    "such biases",
    "biases"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.369/",
  "provenance": {
    "collected_at": "2025-06-05 10:13:37",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}