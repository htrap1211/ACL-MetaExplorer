{
  "id": "P17-1033",
  "title": "Topically Driven Neural Language Model",
  "authors": [
    "Lau, Jey Han  and\nBaldwin, Timothy  and\nCohn, Trevor"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Language models are typically applied at the sentence level, without access to the broader document context. We present a neural language model that incorporates document context in the form of a topic model-like architecture, thus providing a succinct representation of the broader document context outside of the current sentence. Experiments over a range of datasets demonstrate that our model outperforms a pure sentence-based model in terms of language model perplexity, and leads to topics that are potentially more coherent than those produced by a standard LDA topic model. Our model also has the ability to generate related sentences for a topic, providing another way to interpret topics.",
  "keywords": [
    "language",
    "neural",
    "model",
    "lda",
    "topic",
    "perplexity",
    "form",
    "we",
    "current",
    "language model perplexity",
    "a neural language model",
    "that",
    "coherent",
    "pure",
    "another way"
  ],
  "url": "https://aclanthology.org/P17-1033/",
  "provenance": {
    "collected_at": "2025-06-04 23:57:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}