{
  "id": "2021.semeval-1.97",
  "title": "U}o{B}{\\_}{UK} at {S}em{E}val 2021 Task 2: Zero-Shot and Few-Shot Learning for Multi-lingual and Cross-lingual Word Sense Disambiguation.",
  "authors": [
    "Li, Wei  and\nTayyar Madabushi, Harish  and\nLee, Mark"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes our submission to SemEval 2021 Task 2. We compare XLM-RoBERTa Base and Large in the few-shot and zero-shot settings and additionally test the effectiveness of using a k-nearest neighbors classifier in the few-shot setting instead of the more traditional multi-layered perceptron. Our experiments on both the multi-lingual and cross-lingual data show that XLM-RoBERTa Large, unlike the Base version, seems to be able to more effectively transfer learning in a few-shot setting and that the k-nearest neighbors classifier is indeed a more powerful classifier than a multi-layered perceptron when used in few-shot learning.",
  "keywords": [
    "cross",
    "a more powerful classifier",
    "the few-shot setting",
    "val",
    "roberta",
    "em",
    "classifier",
    "few-shot learning",
    "xlm-roberta base",
    "a few-shot setting",
    "word",
    "we",
    "learning",
    "xlm-roberta",
    "the k-nearest neighbors classifier"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.97/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:03",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}