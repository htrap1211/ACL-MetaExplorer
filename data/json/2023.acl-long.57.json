{
  "id": "2023.acl-long.57",
  "title": "FC}-{KBQA}: A Fine-to-Coarse Composition Framework for Knowledge Base Question Answering",
  "authors": [
    "Zhang, Lingxi  and\nZhang, Jing  and\nWang, Yanling  and\nCao, Shulin  and\nHuang, Xinmei  and\nLi, Cuiping  and\nChen, Hong  and\nLi, Juanzi"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The generalization problem on KBQA has drawn considerable attention. Existing research suffers from the generalization issue brought by the entanglement in the coarse-grained modeling of the logical expression, or inexecutability issues due to the fine-grained modeling of disconnected classes and relations in real KBs. We propose a Fine-to-Coarse Composition framework for KBQA (FC-KBQA) to both ensure the generalization ability and executability of the logical expression. The main idea of FC-KBQA is to extract relevant fine-grained knowledge components from KB and reformulate them into middle-grained knowledge pairs for generating the final logical expressions. FC-KBQA derives new state-of-the-art performance on GrailQA and WebQSP, and runs 4 times faster than the baseline. Our code is now available at GitHubhttps://github.com/RUCKBReasoning/FC-KBQA.",
  "keywords": [
    "code",
    "knowledge",
    "the generalization ability",
    "the generalization problem",
    "grailqa",
    "modeling",
    "-",
    "fc-kbqa",
    "question",
    "generalization",
    "fine",
    "attention",
    "we",
    "kbqa",
    "the generalization issue"
  ],
  "url": "https://aclanthology.org/2023.acl-long.57/",
  "provenance": {
    "collected_at": "2025-06-05 09:36:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}