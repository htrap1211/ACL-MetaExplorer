{
  "id": "2024.findings-acl.238",
  "title": "M}-{QALM}: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
  "authors": [
    "Subramanian, Anand  and\nSchlegel, Viktor  and\nRamesh Kashyap, Abhinav  and\nNguyen, Thanh-Tung  and\nDwivedi, Vijay Prakash  and\nWinkler, Stefan"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain: a fundamental pre-requisite for success on down-stream tasks.Addressing this gap, we use Multiple Choice and Abstractive Question Answering to conduct a large-scale empirical study on 22 datasets in three generalist and three specialist biomedical sub-domains. Our multifaceted analysis of the performance of 15 LLMs, further broken down by sub-domain, source of knowledge and model architecture, uncovers success factors such as instruction tuning that lead to improved recall and comprehension. We further show that while recently proposed domain-adapted models may lack adequate knowledge, directly fine-tuning on our collected medical knowledge datasets shows encouraging results, even generalising to unseen specialist sub-domains. We complement the quantitative results with a skill-oriented manual error analysis, which reveals a significant gap between the modelsâ€™ capabilities to simply recall necessary knowledge and to integrate it with the presented context.To foster research and collaboration in this field we share M-QALM, our resources, standardised methodology, and evaluation results, with the research community to facilitate further advancements in clinical knowledge representation learning within language models.",
  "keywords": [
    "variety",
    "field",
    "question",
    "we",
    "15 llms",
    "instruction",
    "it",
    "information",
    "learning",
    "a variety",
    "m",
    "analysis",
    "improved recall",
    "llms",
    "instruction tuning"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.238/",
  "provenance": {
    "collected_at": "2025-06-05 10:51:51",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}