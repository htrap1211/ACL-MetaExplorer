{
  "id": "2024.arabicnlp-1.87",
  "title": "CUFE} at {NADI} 2024 shared task: Fine-Tuning Llama-3 To Translate From {A}rabic Dialects To {M}odern {S}tandard {A}rabic",
  "authors": [
    "Ibrahim, Michael"
  ],
  "year": "2024",
  "venue": "Proceedings of the Second Arabic Natural Language Processing Conference",
  "abstract": "LLMs such as GPT-4 and LLaMA excel in multiple natural language processing tasks, however, LLMs face challenges in delivering satisfactory performance on low-resource languages due to limited availability of training data. In this paper, LLaMA-3 with 8 Billion parameters is finetuned to translate among Egyptian, Emirati, Jordanian, Palestinian Arabic dialects, and Modern Standard Arabic (MSA). In the NADI 2024 Task on DA-MSA Machine Translation, the proposed method achieved a BLEU score of 21.44 when it was fine-tuned on thedevelopment dataset of the NADI 2024 Task on DA-MSA and a BLEU score of 16.09 when trained when it was fine-tuned using the OSACT dataset.",
  "keywords": [
    "da-msa machine translation",
    "tuning",
    "processing",
    "language",
    "a bleu score",
    "natural",
    "machine",
    "it",
    "bleu",
    "gpt-4",
    "fine",
    "a rabic llms",
    "training",
    "translation",
    "llms"
  ],
  "url": "https://aclanthology.org/2024.arabicnlp-1.87/",
  "provenance": {
    "collected_at": "2025-06-05 11:03:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}