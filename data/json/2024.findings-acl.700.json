{
  "id": "2024.findings-acl.700",
  "title": "Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models",
  "authors": [
    "Kao, Chang-Sheng  and\nChen, Yun-Nung"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "For dialogue systems, the utilization of multimodal dialogue responses, as opposed to relying solely on text-only responses, offers the capability to describe different concepts through various modalities. This enhances the effectiveness of communication and elevates the overall conversational experience. However, current methods for dialogue-to-image retrieval are constrained by the capabilities of the pre-trained vision language models (VLMs). They struggle to accurately extract key information from conversations and are unable to handle long-turn conversations. In this paper, we leverage the reasoning capabilities of large language models (LLMs) to predict the potential features that may be present in the images to be shared, based on the dialogue context. This approach allows us to obtain succinct and precise descriptors, thereby improving the performance of text-image retrieval. Experimental results shows that our method outperforms previous approaches significantly in terms of Recall@k.",
  "keywords": [
    "the dialogue context",
    "multimodal dialogue responses",
    "conversations",
    "k",
    "we",
    "dialogue",
    "current",
    "dialogue systems",
    "retrieval",
    "information",
    "dialogue understanding",
    "text-image retrieval experimental results",
    "various modalities",
    "the capabilities",
    "the reasoning capabilities"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.700/",
  "provenance": {
    "collected_at": "2025-06-05 10:58:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}