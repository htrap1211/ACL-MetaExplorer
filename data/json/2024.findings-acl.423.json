{
  "id": "2024.findings-acl.423",
  "title": "Spotting {AI}{'}s Touch: Identifying {LLM}-Paraphrased Spans in Text",
  "authors": [
    "Li, Yafu  and\nWang, Zhilin  and\nCui, Leyang  and\nBi, Wei  and\nShi, Shuming  and\nZhang, Yue"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "AI-generated text detection has attracted increasing attention as powerful language models approach human-level generation. Limited work is devoted to detecting (partially) AI-paraphrased texts. However, AI paraphrasing is commonly employed in various application scenarios for text refinement and diversity. To this end, we propose a novel detection framework, paraphrased text span detection (PTD), aiming to identify paraphrased text spans within a text. Different from text-level detection, PTD takes in the full text and assigns each of the sentences with a score indicating the paraphrasing degree. We construct a dedicated dataset, PASTED, for paraphrased text span detection. Both in-distribution and out-of-distribution results demonstrate the effectiveness of PTD models in identifying AI-paraphrased text spans. Statistical and model analysis explains the crucial role of the surrounding context of the paraphrased text spans. Extensive experiments show that PTD models can generalize to versatile paraphrasing prompts as well as multiple paraphrased text spans.",
  "keywords": [
    "text ai-generated text detection",
    "work",
    "prompts",
    "end",
    "language",
    "generation",
    "increasing attention",
    "versatile paraphrasing prompts",
    "text",
    "human",
    "human-level generation limited work",
    "attention",
    "we",
    "powerful language models",
    "llm -paraphrased spans"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.423/",
  "provenance": {
    "collected_at": "2025-06-05 10:54:23",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}