{
  "id": "2024.acl-short.65",
  "title": "Towards Artwork Explanation in Large-scale Vision Language Models",
  "authors": [
    "Hayashi, Kazuki  and\nSakai, Yusuke  and\nKamigaito, Hidetaka  and\nHayashi, Katsuhiko  and\nWatanabe, Taro"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships between various pieces of knowledge, and how they integrate these understandings into their explanations. To address this issue, we propose a new task: the artwork explanation generation task, along with its evaluation dataset and metric for quantitatively assessing the understanding and utilization of knowledge about artworks. This task is apt for image description based on the premise that LVLMs are expected to have pre-existing knowledge of artworks, which are often subjects of wide recognition and documented information.It consists of two parts: generating explanations from both images and titles of artworks, and generating explanations using only images, thus evaluating the LVLMsâ€™ language-based and vision-based knowledge.Alongside, we release a training dataset for LVLMs to learn explanations that incorporate knowledge about artworks.Our findings indicate that LVLMs not only struggle with integrating language and visual information but also exhibit a more pronounced limitation in acquiring knowledge from images alone. The datasets ExpArt=Explain Artworks are available at https://huggingface.co/datasets/naist-nlp/ExpArt",
  "keywords": [
    "we",
    "two parts generating explanations",
    "text generation",
    "training",
    "it",
    "various pieces",
    "its evaluation dataset",
    "information",
    "pieces",
    "generating explanations",
    "visual",
    "large-scale vision-language models",
    "advanced capabilities",
    "metric",
    "text"
  ],
  "url": "https://aclanthology.org/2024.acl-short.65/",
  "provenance": {
    "collected_at": "2025-06-05 10:47:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}