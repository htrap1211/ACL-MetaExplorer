{
  "id": "P19-1130",
  "title": "Exploiting Entity {BIO} Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data",
  "authors": [
    "Ye, Wei  and\nLi, Bo  and\nXie, Rui  and\nSheng, Zhonghao  and\nChen, Long  and\nZhang, Shikun"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "In practical scenario, relation extraction needs to first identify entity pairs that have relation and then assign a correct relation class. However, the number of non-relation entity pairs in context (negative instances) usually far exceeds the others (positive instances), which negatively affects a modelâ€™s performance. To mitigate this problem, we propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification with ranking loss. Meanwhile, we observe that a sentence may have multiple entities and relation mentions, and the patterns in which the entities appear in a sentence may contain useful semantic information that can be utilized to distinguish between positive and negative instances. Thus we further incorporate the embeddings of character-wise/word-wise BIO tag from the named entity recognition task into character/word embeddings to enrich the input representation. Experiment results show that our proposed approach can significantly improve the performance of a baseline model with more than 10% absolute increase in F1-score, and outperform the state-of-the-art models on ACE 2005 Chinese and English corpus. Moreover, BIO tag embeddings are particularly effective and can be used to improve other models as well.",
  "keywords": [
    "extraction",
    "semantic",
    "we",
    "classification",
    "the entities",
    "cross",
    "f1-score",
    "loss",
    "tag",
    "information",
    "word",
    "learning",
    "the embeddings",
    "multiple entities",
    "embeddings"
  ],
  "url": "https://aclanthology.org/P19-1130/",
  "provenance": {
    "collected_at": "2025-06-05 00:32:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}