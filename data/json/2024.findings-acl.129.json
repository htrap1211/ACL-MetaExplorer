{
  "id": "2024.findings-acl.129",
  "title": "Plum: Prompt Learning using Metaheuristics",
  "authors": [
    "Pan, Rui  and\nXing, Shuo  and\nDiao, Shizhe  and\nSun, Wenhe  and\nLiu, Xiang  and\nShum, KaShun  and\nZhang, Jipeng  and\nPi, Renjie  and\nZhang, Tong"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly “general”, i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in white-box and black-box prompt learning. Furthermore, we show that these methods can be used to discover more human-understandable prompts that were previously unknown in both reasoning and image generation tasks, opening the door to a cornucopia of possibilities in prompt optimization.",
  "keywords": [
    "general prompt optimization methods",
    "discrete non-convex optimization methods",
    "chain",
    "plum prompt learning",
    "we",
    "effective prompts",
    "more human-understandable prompts",
    "unknown reasoning capabilities",
    "prompt learning",
    "learning",
    "prompt",
    "i",
    "prompts",
    "general",
    "possibilities"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.129/",
  "provenance": {
    "collected_at": "2025-06-05 10:50:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}