{
  "id": "2023.acl-long.703",
  "title": "Large-scale Lifelong Learning of In-context Instructions and How to Tackle It",
  "authors": [
    "Mok, Jisoo  and\nDo, Jaeyoung  and\nLee, Sungjin  and\nTaghavi, Tara  and\nYu, Seunghak  and\nYoon, Sungroh"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Jointly fine-tuning a Pre-trained Language Model (PLM) on a pre-defined set of tasks with in-context instructions has been proven to improve its generalization performance, allowing us to build a universal language model that can be deployed across task boundaries. In this work, we explore for the first time whether this attractive property of in-context instruction learning can be extended to a scenario in which tasks are fed to the target PLM in a sequential manner. The primary objective of so-called lifelong in-context instruction learning is to improve the target PLMâ€™s instance- and task-level generalization performance as it observes more tasks. DynaInst, the proposed method to lifelong in-context instruction learning, achieves noticeable improvements in both types of generalization, nearly reaching the upper bound performance obtained through joint training.",
  "keywords": [
    "work",
    "instruction",
    "language",
    "model",
    "its generalization performance",
    "it",
    "objective",
    "the primary objective",
    "boundaries",
    "a universal language model",
    "us",
    "generalization",
    "we",
    "learning",
    "pre"
  ],
  "url": "https://aclanthology.org/2023.acl-long.703/",
  "provenance": {
    "collected_at": "2025-06-05 09:45:09",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}