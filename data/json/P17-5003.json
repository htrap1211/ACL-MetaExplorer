{
  "id": "P17-5003",
  "title": "Deep Learning for Semantic Composition",
  "authors": [
    "Zhu, Xiaodan  and\nGrefenstette, Edward"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts",
  "abstract": "Learning representation to model the meaning of text has been a core problem in NLP. The last several years have seen extensive interests on distributional approaches, in which text spans of different granularities are encoded as vectors of numerical values. If properly learned, such representation has showed to achieve the state-of-the-art performance on a wide range of NLP problems.In this tutorial, we will cover the fundamentals and the state-of-the-art research on neural network-based modeling for semantic composition, which aims to learn distributed representation for different granularities of text, e.g., phrases, sentences, or even documents, from their sub-component meaning representation, e.g., word embedding.",
  "keywords": [
    "deep",
    "neural network-based modeling",
    "neural",
    "nlp",
    "text",
    "deep learning",
    "vectors",
    "modeling",
    "different granularities",
    "granularities",
    "semantic",
    "network",
    "we",
    "learning",
    "word"
  ],
  "url": "https://aclanthology.org/P17-5003/",
  "provenance": {
    "collected_at": "2025-06-05 00:06:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}