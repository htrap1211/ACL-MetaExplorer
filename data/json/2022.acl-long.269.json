{
  "id": "2022.acl-long.269",
  "title": "Is Attention Explanation? An Introduction to the Debate",
  "authors": [
    "Bibal, Adrien  and\nCardon, R{\\'e}mi  and\nAlfter, David  and\nWilkens, Rodrigo  and\nWang, Xiaoou  and\nFran{\\c{c}}ois, Thomas  and\nWatrin, Patrick"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount. Attention has been seen as a solution to increase performance, while providing some explanations. However, a debate has started to cast doubt on the explanatory power of attention in neural networks. Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible. In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas. This holistic vision can be of great interest for future works in all the communities concerned by this debate. We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.",
  "keywords": [
    "deep",
    "paramount attention",
    "communities",
    "overview",
    "we",
    "fields",
    "neural",
    "other fields",
    "machine learning",
    "attention explanation",
    "learning",
    "neural networks",
    "a clear overview",
    "all the communities",
    "deep learning models"
  ],
  "url": "https://aclanthology.org/2022.acl-long.269/",
  "provenance": {
    "collected_at": "2025-06-05 08:27:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}