{
  "id": "P19-1111",
  "title": "Poetry to Prose Conversion in {S}anskrit as a Linearisation Task: A Case for Low-Resource Languages",
  "authors": [
    "Krishna, Amrith  and\nSharma, Vishnu  and\nSantra, Bishal  and\nChakraborty, Aishik  and\nSatuluri, Pavankumar  and\nGoyal, Pawan"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "The word ordering in a Sanskrit verse is often not aligned with its corresponding prose order. Conversion of the verse to its corresponding prose helps in better comprehension of the construction. Owing to the resource constraints, we formulate this task as a word ordering (linearisation) task. In doing so, we completely ignore the word arrangement at the verse side. kāvya guru, the approach we propose, essentially consists of a pipeline of two pretraining steps followed by a seq2seq model. The first pretraining step learns task-specific token embeddings from pretrained embeddings. In the next step, we generate multiple possible hypotheses for possible word arrangements of the input %using another pretraining step. We then use them as inputs to a neural seq2seq model for the final prediction. We empirically show that the hypotheses generated by our pretraining step result in predictions that consistently outperform predictions based on the original order in the verse. Overall, kāvya guru outperforms current state of the art models in linearisation for the poetry to prose conversion task in Sanskrit.",
  "keywords": [
    "we",
    "current",
    "neural",
    "pretrained embeddings",
    "a seq2seq model",
    "a neural seq2seq model",
    "token",
    "word",
    "seq2seq",
    "task-specific token embeddings",
    "embeddings",
    "model",
    "a linearisation task",
    "kāvya",
    "approach"
  ],
  "url": "https://aclanthology.org/P19-1111/",
  "provenance": {
    "collected_at": "2025-06-05 00:32:24",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}