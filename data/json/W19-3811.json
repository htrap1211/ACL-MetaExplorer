{
  "id": "W19-3811",
  "title": "BERT} Masked Language Modeling for Co-reference Resolution",
  "authors": [
    "Alfaro, Felipe  and\nCosta-juss{\\`a}, Marta R.  and\nFonollosa, Jos{\\'e} A. R."
  ],
  "year": "2019",
  "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing",
  "abstract": "This paper explains the TALP-UPC participation for the Gendered Pronoun Resolution shared-task of the 1st ACL Workshop on Gender Bias for Natural Language Processing. We have implemented two models for mask language modeling using pre-trained BERT adjusted to work for a classification problem. The proposed solutions are based on the word probabilities of the original BERT model, but using common English names to replace the original test names.",
  "keywords": [
    "reference",
    "mask language modeling",
    "bias",
    "processing",
    "language",
    "bert",
    "natural",
    "model",
    "gender bias",
    "modeling",
    "pre-trained bert",
    "probabilities",
    "word",
    "we",
    "natural language processing"
  ],
  "url": "https://aclanthology.org/W19-3811/",
  "provenance": {
    "collected_at": "2025-06-05 00:59:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}