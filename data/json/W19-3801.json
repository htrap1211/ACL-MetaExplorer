{
  "id": "W19-3801",
  "title": "Gendered Ambiguous Pronoun ({GAP}) Shared Task at the Gender Bias in {NLP} Workshop 2019",
  "authors": [
    "Webster, Kellie  and\nCosta-juss{\\`a}, Marta R.  and\nHardmeier, Christian  and\nRadford, Will"
  ],
  "year": "2019",
  "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing",
  "abstract": "The 1st ACL workshop on Gender Bias in Natural Language Processing included a shared task on gendered ambiguous pronoun (GAP) resolution. This task was based on the coreference challenge defined in Webster et al. (2018), designed to benchmark the ability of systems to resolve pronouns in real-world contexts in a gender-fair way. 263 teams competed via a Kaggle competition, with the winning system achieving logloss of 0.13667 and near gender parity. We review the approaches of eleven systems with accepted description papers, noting their effective use of BERT (Devlin et al., 2018), both via fine-tuning and for feature extraction, as well as ensembling.",
  "keywords": [
    "tuning",
    "bias",
    "processing",
    "the coreference challenge",
    "language",
    "nlp",
    "natural",
    "bert",
    "extraction",
    "gender bias",
    "nlp workshop",
    "the gender bias",
    "we",
    "bert devlin",
    "natural language processing"
  ],
  "url": "https://aclanthology.org/W19-3801/",
  "provenance": {
    "collected_at": "2025-06-05 00:59:25",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}