{
  "id": "2022.acl-long.361",
  "title": "Dynamic Global Memory for Document-level Argument Extraction",
  "authors": [
    "Du, Xinya  and\nLi, Sha  and\nJi, Heng"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Extracting informative arguments of events from news articles is a challenging problem in information extraction, which requires a global contextual understanding of each document. While recent work on document-level extraction has gone beyond single-sentence and increased the cross-sentence inference capability of end-to-end models, they are still restricted by certain input sequence length constraints and usually ignore the global context between events. To tackle this issue, we introduce a new global neural generation-based framework for document-level event argument extraction by constructing a document memory store to record the contextual event information and leveraging it to implicitly and explicitly help with decoding of arguments for later events. Empirical results show that our framework outperforms prior methods substantially and it is more robust to adversarially annotated examples with our constrained decoding design.",
  "keywords": [
    "work",
    "cross",
    "end",
    "generation",
    "neural",
    "extraction",
    "it",
    "information",
    "information extraction",
    "we",
    "sequence",
    "news",
    "this issue",
    "the cross-sentence inference capability",
    "certain"
  ],
  "url": "https://aclanthology.org/2022.acl-long.361/",
  "provenance": {
    "collected_at": "2025-06-05 08:29:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}