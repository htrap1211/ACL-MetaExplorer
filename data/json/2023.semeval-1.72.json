{
  "id": "2023.semeval-1.72",
  "title": "T}eam{S}hakespeare at {S}em{E}val-2023 Task 6: Understand Legal Documents with Contextualized Large Language Models",
  "authors": [
    "Jin, Xin  and\nWang, Yuchen"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "The growth of pending legal cases in populouscountries, such as India, has become a major is-sue. Developing effective techniques to processand understand legal documents is extremelyuseful in resolving this problem. In this pa-per, we present our systems for SemEval-2023Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the com-prehensive context information in both intra-and inter-sentence levels to predict rhetoricalroles (subtask A) and then train a Legal-LUKEmodel, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B).Our evaluations demonstrate that our designedmodels are more accurate than baselines, e.g.,with an up to 15.0% better F1 score in subtaskB. We achieved notable performance in the taskleaderboard, e.g., 0.834 micro F1 score, andranked No.5 out of 27 teams in subtask A.",
  "keywords": [
    "t",
    "legal entities",
    "b",
    "we",
    "the legal-bert-hsln model",
    "information",
    "a",
    "contextualized large language models",
    "bert",
    "language",
    "model",
    "entities",
    "evaluations",
    "our evaluations",
    "populouscountries"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.72/",
  "provenance": {
    "collected_at": "2025-06-05 10:27:37",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}