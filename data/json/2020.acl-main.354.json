{
  "id": "2020.acl-main.354",
  "title": "Learning Implicit Text Generation via Feature Matching",
  "authors": [
    "Padhi, Inkit  and\nDognin, Pierre  and\nBai, Ke  and\nNogueira dos Santos, C{\\'i}cero  and\nChenthamarakshan, Vijil  and\nMroueh, Youssef  and\nDas, Payel"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Generative feature matching network (GFMN) is an approach for training state-of-the-art implicit generative models for images by performing moment matching on features from pre-trained neural networks. In this paper, we present new GFMN formulations that are effective for sequential data. Our experimental results show the effectiveness of the proposed method, SeqGFMN, for three distinct generation tasks in English: unconditional text generation, class-conditional text generation, and unsupervised text style transfer. SeqGFMN is stable to train and outperforms various adversarial approaches for text generation and text style transfer.",
  "keywords": [
    "generative",
    "implicit text generation",
    "generation",
    "neural",
    "text",
    "class",
    "three distinct generation tasks",
    "network",
    "we",
    "transfer",
    "moment",
    "pre",
    "text generation",
    "pre-trained neural networks",
    "that"
  ],
  "url": "https://aclanthology.org/2020.acl-main.354/",
  "provenance": {
    "collected_at": "2025-06-05 07:46:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}