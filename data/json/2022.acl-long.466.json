{
  "id": "2022.acl-long.466",
  "title": "P}rompt for Extraction? {PAIE}: {P}rompting Argument Interaction for Event Argument Extraction",
  "authors": [
    "Ma, Yubo  and\nWang, Zehao  and\nCao, Yixin  and\nLi, Mukai  and\nChen, Meiqi  and\nWang, Kun  and\nShao, Jing"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "In this paper, we propose an effective yet efficient model PAIE for both sentence-level and document-level Event Argument Extraction (EAE), which also generalizes well when there is a lack of training data. On the one hand, PAIE utilizes prompt tuning for extractive objectives to take the best advantages of Pre-trained Language Models (PLMs). It introduces two span selectors based on the prompt to select start/end tokens among input texts for each role. On the other hand, it captures argument interactions via multi-role prompts and conducts joint optimization with optimal span assignments via a bipartite matching loss. Also, with a flexible prompt design, PAIE can extract multiple arguments with the same role instead of conventional heuristic threshold tuning. We have conducted extensive experiments on three benchmarks, including both sentence- and document-level EAE. The results present promising improvements from PAIE (3.5% and 2.3% F1 gains in average on three benchmarks, for PAIE-base and PAIE-large respectively). Further analysis demonstrates the efficiency, generalization to few-shot settings, and effectiveness of different extractive prompt tuning strategies. Our code is available athttps://github.com/mayubo2333/PAIE.",
  "keywords": [
    "code",
    "objectives",
    "end",
    "extraction",
    "efficient",
    "efficiency",
    "we",
    "shot",
    "training",
    "it",
    "loss",
    "pre-trained language models plms",
    "analysis",
    "tuning",
    "prompt"
  ],
  "url": "https://aclanthology.org/2022.acl-long.466/",
  "provenance": {
    "collected_at": "2025-06-05 08:30:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}