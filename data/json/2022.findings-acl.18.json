{
  "id": "2022.findings-acl.18",
  "title": "Analyzing Dynamic Adversarial Training Data in the Limit",
  "authors": [
    "Wallace, Eric  and\nWilliams, Adina  and\nJia, Robin  and\nKiela, Douwe"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "To create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Models trained on DADC examples make 26% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.",
  "keywords": [
    "we",
    "training",
    "it",
    "analysis",
    "generalization",
    "work",
    "better generalization",
    "time",
    "term",
    "approach",
    "error",
    "benefits",
    "test",
    "adversarial",
    "longer-term dadc"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.18/",
  "provenance": {
    "collected_at": "2025-06-05 08:35:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}