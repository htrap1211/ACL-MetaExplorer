{
  "id": "2020.repl4nlp-1.8",
  "title": "Adversarial Training for Commonsense Inference",
  "authors": [
    "Pereira, Lis  and\nLiu, Xiaodong  and\nCheng, Fei  and\nAsahara, Masayuki  and\nKobayashi, Ichiro"
  ],
  "year": "2020",
  "venue": "Proceedings of the 5th Workshop on Representation Learning for NLP",
  "abstract": "We apply small perturbations to word embeddings and minimize the resultant adversarial risk to regularize the model. We exploit a novel combination of two different approaches to estimate these perturbations: 1) using the true label and 2) using the model prediction. Without relying on any human-crafted features, knowledge bases, or additional datasets other than the target datasets, our model boosts the fine-tuning performance of RoBERTa, achieving competitive results on multiple reading comprehension datasets that require commonsense inference.",
  "keywords": [
    "embeddings",
    "tuning",
    "roberta",
    "knowledge",
    "model",
    "human",
    "the fine-tuning performance",
    "we",
    "training",
    "that",
    "reading",
    "the resultant adversarial risk",
    "the true label",
    "true",
    "competitive"
  ],
  "url": "https://aclanthology.org/2020.repl4nlp-1.8/",
  "provenance": {
    "collected_at": "2025-06-05 07:58:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}