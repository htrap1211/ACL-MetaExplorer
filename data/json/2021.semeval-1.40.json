{
  "id": "2021.semeval-1.40",
  "title": "B}reaking{BERT}@{IITK} at {S}em{E}val-2021 Task 9: Statement Verification and Evidence Finding with Tables",
  "authors": [
    "Jindal, Aditya  and\nGupta, Ankur  and\nSrivastava, Jaya  and\nMenghwani, Preeti  and\nMalik, Vijit  and\nKaushik, Vishesh  and\nModi, Ashutosh"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "Recently, there has been an interest in the research on factual verification and prediction over structured data like tables and graphs. To circumvent any false news incident, it is necessary to not only model and predict over structured data efficiently but also to explain those predictions. In this paper, as the part of the SemEval-2021 Task 9, we tackle the problem of fact verification and evidence finding over tabular data. There are two subtasks, in which given a table and a statement/fact, the subtask A is to determine whether the statement is inferred from the tabular data and the subtask B is to determine which cells in the table provide evidence for the former subtask. We make a comparison of the baselines and state of the art approaches over the given SemTabFact dataset. We also propose a novel approach CellBERT to solve the task of evidence finding, as a form of Natural Language Inference task. We obtain a 3-way F1 score of 0.69 on subtask A and an F1 score of 0.65 on subtask B.",
  "keywords": [
    "form",
    "we",
    "b reaking bert iitk",
    "natural",
    "it",
    "a",
    "bert",
    "cellbert",
    "a 3-way f1 score",
    "language",
    "an f1 score",
    "a novel approach cellbert",
    "model",
    "tabular data",
    "approach"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.40/",
  "provenance": {
    "collected_at": "2025-06-05 08:20:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}