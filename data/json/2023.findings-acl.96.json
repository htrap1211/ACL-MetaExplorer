{
  "id": "2023.findings-acl.96",
  "title": "Adversarial Multi-task Learning for End-to-end Metaphor Detection",
  "authors": [
    "Zhang, Shenglong  and\nLiu, Ying"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Metaphor detection (MD) suffers from limited training data. In this paper, we started with a linguistic rule called Metaphor Identification Procedure and then proposed a novel multi-task learning framework to transfer knowledge in basic sense discrimination (BSD) to MD. BSD is constructed from word sense disambiguation (WSD), which has copious amounts of data. We leverage adversarial training to align the data distributions of MD and BSD in the same feature space, so task-invariant representations can be learned. To capture fine-grained alignment patterns, we utilize the multi-mode structures of MD and BSD. Our method is totally end-to-end and can mitigate the data scarcity problem in MD. Competitive results are reported on four public datasets. Our code and datasets are available.",
  "keywords": [
    "alignment",
    "code",
    "knowledge",
    "end",
    "fine-grained alignment patterns",
    "word",
    "we",
    "learning",
    "training",
    "mode",
    "md",
    "identification",
    "task-invariant representations",
    "basic",
    "multi"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.96/",
  "provenance": {
    "collected_at": "2025-06-05 09:54:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}