{
  "id": "2023.semeval-1.113",
  "title": "CNLP}-{NITS} at {S}em{E}val-2023 Task 10: Online sexism prediction, {PREDHATE}!",
  "authors": [
    "Vetagiri, Advaitha  and\nAdhikary, Prottay  and\nPakray, Partha  and\nDas, Amitava"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "Online sexism is a rising issue that threatens womenâ€™s safety, fosters hostile situations, and upholds social inequities. We describe a task SemEval-2023 Task 10 for creating English-language models that can precisely identify and categorize sexist content on internet forums and social platforms like Gab and Reddit as well to provide an explainability in order to address this problem. The problem is divided into three hierarchically organized subtasks: binary sexism detection, sexism by category, and sexism by fine-grained vector. The dataset consists of 20,000 labelled entries. For Task A, pertained models like Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM), which is called CNN-BiLSTM and Generative Pretrained Transformer 2 (GPT-2) models were used, as well as the GPT-2 model for Task B and C, and have provided experimental configurations. According to our findings, the GPT-2 model performs better than the CNN-BiLSTM model for Task A, while GPT-2 is highly accurate for Tasks B and C on the training, validation and testing splits of the training data provided in the task. Our proposed models allow researchers to create more precise and understandable models for identifying and categorizing sexist content in online forums, thereby empowering users and moderators.",
  "keywords": [
    "validation",
    "fine-grained vector",
    "english-language models",
    "entries",
    "we",
    "upholds social inequities",
    "convolutional",
    "training",
    "neural",
    "cnn",
    "bilstm",
    "c",
    "cnlp - nits",
    "gpt-2",
    "generative"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.113/",
  "provenance": {
    "collected_at": "2025-06-05 10:28:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}