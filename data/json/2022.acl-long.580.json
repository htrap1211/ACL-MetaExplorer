{
  "id": "2022.acl-long.580",
  "title": "SUPERB}-{SG}: Enhanced Speech processing Universal {PER}formance Benchmark for Semantic and Generative Capabilities",
  "authors": [
    "Tsai, Hsiang-Sheng  and\nChang, Heng-Jui  and\nHuang, Wen-Chin  and\nHuang, Zili  and\nLakhotia, Kushal  and\nYang, Shu-wen  and\nDong, Shuyan  and\nLiu, Andy  and\nLai, Cheng-I  and\nShi, Jiatong  and\nChang, Xuankai  and\nHall, Phil  and\nChen, Hsuan-Jui  and\nLi, Shang-Wen  and\nWatanabe, Shinji  and\nMohamed, Abdelrahman  and\nLee, Hung-yi"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years. In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks. However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models. SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks. In this paper, we introduce SUPERB-SG, a new benchmark focusing on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB. We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks. It entails freezing pre-trained model parameters, only using simple task-specific trainable heads. The goal is to be inclusive of all researchers, and encourage efficient use of computational resources. We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation.",
  "keywords": [
    "natural language processing research",
    "efficient use",
    "efficient",
    "semantic",
    "we",
    "generalizability",
    "a consistent evaluation methodology",
    "natural",
    "it",
    "the generalizability",
    "self",
    "learning",
    "transfer",
    "generative",
    "processing"
  ],
  "url": "https://aclanthology.org/2022.acl-long.580/",
  "provenance": {
    "collected_at": "2025-06-05 08:32:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}