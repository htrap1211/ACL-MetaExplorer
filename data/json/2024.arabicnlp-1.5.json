{
  "id": "2024.arabicnlp-1.5",
  "title": "Strategies for {A}rabic Readability Modeling",
  "authors": [
    "Liberato, Juan  and\nAlhafni, Bashar  and\nKhalil, Muhamed  and\nHabash, Nizar"
  ],
  "year": "2024",
  "venue": "Proceedings of the Second Arabic Natural Language Processing Conference",
  "abstract": "Automatic readability assessment is relevant to building NLP applications for education, content analysis, and accessibility. However, Arabic readability assessment is a challenging task due to Arabicâ€™s morphological richness and limited readability resources. In this paper, we present a set of experimental results on Arabic readability assessment using a diverse range of approaches, from rule-based methods to Arabic pretrained language models. We report our results on a newly created corpus at different textual granularity levels (words and sentence fragments). Our results show that combining different techniques yields the best results, achieving an overall macro F1 score of 86.7 at the word level and 87.9 at the fragment level on a blind test set. We make our code, data, and pretrained models publicly available.",
  "keywords": [
    "code",
    "different techniques yields",
    "language",
    "nlp",
    "arabic pretrained language models",
    "strategies",
    "word",
    "we",
    "nlp applications",
    "yields",
    "analysis",
    "applications",
    "granularity",
    "a diverse range",
    "techniques"
  ],
  "url": "https://aclanthology.org/2024.arabicnlp-1.5/",
  "provenance": {
    "collected_at": "2025-06-05 11:02:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}