{
  "id": "2023.acl-industry.9",
  "title": "KG}-{FLIP}: Knowledge-guided Fashion-domain Language-Image Pre-training for {E}-commerce",
  "authors": [
    "Jia, Qinjin  and\nLiu, Yang  and\nWu, Daoping  and\nXu, Shaoyuan  and\nLiu, Huidong  and\nFu, Jinmiao  and\nVollgraf, Roland  and\nWang, Bryan"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
  "abstract": "Various Vision-Language Pre-training (VLP) models (e.g., CLIP, BLIP) have sprung up and dramatically advanced the benchmarks for public general-domain datasets (e.g., COCO, Flickr30k). Such models usually learn the cross-modal alignment from large-scale well-aligned image-text datasets without leveraging external knowledge. Adapting these models to downstream applications in specific domains like fashion requires fine-grained in-domain image-text corpus, which are usually less semantically aligned and in small scale that requires efficient pre-training strategies. In this paper, we propose a knowledge-guided fashion-domain language-image pre-training (FLIP) framework that focuses on learning fine-grained representations in e-commerce domain and utilizes external knowledge (i.e., product attribute schema), to improve the pre-training efficiency. Experiments demonstrate that FLIP outperforms previous state-of-the-art VLP models on Amazon data and on the Fashion-Gen dataset by large margins. FLIP has been successfully deployed in the Amazon catalog system to backfill missing attributes and improve the customer shopping experience.",
  "keywords": [
    "efficient",
    "the cross-modal alignment",
    "efficiency",
    "the customer shopping experience",
    "we",
    "training",
    "cross",
    "efficient pre-training strategies",
    "the pre-training efficiency experiments",
    "text",
    "public general-domain datasets",
    "strategies",
    "-",
    "gen",
    "experience"
  ],
  "url": "https://aclanthology.org/2023.acl-industry.9/",
  "provenance": {
    "collected_at": "2025-06-05 09:52:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}