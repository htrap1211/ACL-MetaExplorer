{
  "id": "2022.csrr-1.6",
  "title": "Knowledge-Augmented Language Models for Cause-Effect Relation Classification",
  "authors": [
    "Hosseini, Pedram  and\nBroniatowski, David A.  and\nDiab, Mona"
  ],
  "year": "2022",
  "venue": "Proceedings of the First Workshop on Commonsense Representation and Reasoning (CSRR 2022)",
  "abstract": "Previous studies have shown the efficacy of knowledge augmentation methods in pretrained language models. However, these methods behave differently across domains and downstream tasks. In this work, we investigate the augmentation of pretrained language models with knowledge graph data in the cause-effect relation classification and commonsense causal reasoning tasks. After automatically verbalizing triples in ATOMIC2020, a wide coverage commonsense reasoning knowledge graph, we continually pretrain BERT and evaluate the resulting model on cause-effect pair classification and answering commonsense causal reasoning questions. Our results show that a continually pretrained language model augmented with commonsense reasoning knowledge outperforms our baselines on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset, without additional improvement in model architecture or using quality-enhanced data for fine-tuning.",
  "keywords": [
    "work",
    "tuning",
    "knowledge",
    "language",
    "previous studies",
    "bert",
    "model",
    "studies",
    "knowledge-augmented language models",
    "pretrained language models",
    "fine",
    "we",
    "graph",
    "knowledge graph data",
    "cause-effect relation classification"
  ],
  "url": "https://aclanthology.org/2022.csrr-1.6/",
  "provenance": {
    "collected_at": "2025-06-05 08:40:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}