{
  "id": "2024.acl-long.432",
  "title": "Chain-of-Exemplar: Enhancing Distractor Generation for Multimodal Educational Question Generation",
  "authors": [
    "Luo, Haohao  and\nDeng, Yang  and\nShen, Ying  and\nNg, See-Kiong  and\nChua, Tat-Seng"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Multiple-choice questions (MCQs) are important in enhancing concept learning and student engagement for educational purposes. Despite the multimodal nature of educational content, current methods focus mainly on text-based inputs and often neglect the integration of visual information. In this work, we study the problem of multimodal educational question generation, which aims at generating subject-specific educational questions with plausible yet incorrect distractors based on multimodal educational content. To tackle this problem, we introduce a novel framework, named Chain-of-Exemplar (CoE), which utilizes multimodal large language models (MLLMs) with Chain-of-Thought reasoning to improve the generation of challenging distractors. Furthermore, CoE leverages three-stage contextualized exemplar retrieval to retrieve exemplary questions as guides for generating more subject-specific educational questions. Experimental results on the ScienceQA benchmark demonstrate the superiority of CoE in both question generation and distractor generation over existing methods across various subjects and educational levels.",
  "keywords": [
    "the scienceqa benchmark",
    "both question generation",
    "chain",
    "the generation",
    "question",
    "we",
    "current",
    "distractor generation",
    "scienceqa",
    "large language models mllms",
    "retrieval",
    "information",
    "learning",
    "visual",
    "text"
  ],
  "url": "https://aclanthology.org/2024.acl-long.432/",
  "provenance": {
    "collected_at": "2025-06-05 10:40:15",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}