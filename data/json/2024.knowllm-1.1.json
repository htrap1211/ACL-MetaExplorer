{
  "id": "2024.knowllm-1.1",
  "title": "P}honology{B}ench: Evaluating Phonological Skills of Large Language Models",
  "authors": [
    "Suvarna, Ashima  and\nKhandelwal, Harshita  and\nPeng, Nanyun"
  ],
  "year": "2024",
  "venue": "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)",
  "abstract": "Phonology, the study of speechâ€™s structure and pronunciation rules, is a critical yet often overlooked component in Large Language Model (LLM) research. LLMs are widely used in various downstream applications that leverage phonology such as educational tools and poetry generation. Moreover, LLMs can potentially learn imperfect associations between orthographic and phonological forms from the training data. Thus, it is imperative to benchmark the phonological skills of LLMs. To this end, we present PhonologyBench, a novel benchmark consisting of three diagnostic tasks designed to explicitly test the phonological skills of LLMs in English: grapheme-to-phoneme conversion, syllable counting, and rhyme word generation. Despite having no access to speech data, LLMs showcased notable performance on the PhonologyBench tasks. However, we observe a significant gap of 17% and 45% on Rhyme Word Generation and Syllable counting, respectively, when compared to humans. Our findings underscore the importance of studying LLM performance on phonological tasks that inadvertently impact real-world applications. Furthermore, we encourage researchers to choose LLMs that perform well on the phonological task that is closely related to the downstream application since we find that no single model consistently outperforms the others on all the tasks.",
  "keywords": [
    "end",
    "rhyme word generation",
    "large language model",
    "we",
    "llm",
    "training",
    "it",
    "word",
    "llms",
    "speech data llms",
    "llm research llms",
    "language",
    "generation",
    "model",
    "llm performance"
  ],
  "url": "https://aclanthology.org/2024.knowllm-1.1/",
  "provenance": {
    "collected_at": "2025-06-05 11:07:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}