{
  "id": "2023.semeval-1.45",
  "title": "RIGA} at {S}em{E}val-2023 Task 2: {NER} Enhanced with {GPT}-3",
  "authors": [
    "Mukans, Eduards  and\nBarzdins, Guntis"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "The following is a description of the RIGA teamâ€™s submissions for the English track of the SemEval-2023 Task 2: Multilingual Complex Named Entity Recognition (MultiCoNER) II. Our approach achieves 17% boost in results by utilizing pre-existing Large-scale Language Models (LLMs), such as GPT-3, to gather additional contexts. We then fine-tune a pre-trained neural network utilizing these contexts. The final step of our approach involves meticulous model and compute resource scaling, which results in improved performance. Our results placed us 12th out of 34 teams in terms of overall ranking and 7th in terms of the noisy subset ranking. The code for our method is available on GitHub (https://github.com/emukans/multiconer2-riga).",
  "keywords": [
    "code",
    "em",
    "multiconer",
    "we",
    "neural",
    "gpt-3",
    "boost",
    "llms",
    "ner",
    "fine",
    "multiconer2",
    "language",
    "model",
    "gpt",
    "us"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.45/",
  "provenance": {
    "collected_at": "2025-06-05 10:27:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}