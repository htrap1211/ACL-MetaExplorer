{
  "id": "2022.acl-long.100",
  "title": "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization",
  "authors": [
    "Ladhak, Faisal  and\nDurmus, Esin  and\nHe, He  and\nCardie, Claire  and\nMcKeown, Kathleen"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Despite recent progress in abstractive summarization, systems still suffer from faithfulness errors. While prior work has proposed models that improve faithfulness, it is unclear whether the improvement comes from an increased level of extractiveness of the model outputs as one naive way to improve faithfulness is to make summarization models more extractive. In this work, we present a framework for evaluating the effective faithfulness of summarization systems, by generating a faithfulness-abstractiveness trade-off curve that serves as a control at different operating points on the abstractiveness spectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as well as recently proposed methods for improving faithfulness, fail to consistently improve over the control at the same level of abstractiveness. Finally, we learn a selector to identify the most faithful and abstractive summary for a given document, and show that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets. Moreover, we show that our system is able to achieve a better faithfulness-abstractiveness trade-off than the control at the same level of abstractiveness.",
  "keywords": [
    "summarization",
    "we",
    "summarization systems",
    "it",
    "abstractive summarization",
    "abstractive summarization systems",
    "summarization models",
    "human evaluations",
    "work",
    "model",
    "human",
    "evaluations",
    "recent progress",
    "abstractive",
    "recent"
  ],
  "url": "https://aclanthology.org/2022.acl-long.100/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}