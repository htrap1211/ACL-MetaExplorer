{
  "id": "2021.acl-long.536",
  "title": "Improving Factual Consistency of Abstractive Summarization via Question Answering",
  "authors": [
    "Nan, Feng  and\nNogueira dos Santos, Cicero  and\nZhu, Henghui  and\nNg, Patrick  and\nMcKeown, Kathleen  and\nNallapati, Ramesh  and\nZhang, Dejiao  and\nWang, Zhiguo  and\nArnold, Andrew O.  and\nXiang, Bing"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "A commonly observed problem with the state-of-the art abstractive summarization models is that the generated summaries can be factually inconsistent with the input documents. The fact that automatic summarization may produce plausible-sounding yet inaccurate summaries is a major concern that limits its wide application. In this paper we present an approach to address factual consistency in summarization. We first propose an efficient automatic evaluation metric to measure factual consistency; next, we propose a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, we confirm that our method is effective in improving factual consistency and even overall quality of the summaries, as judged by both automatic metrics and human evaluation.",
  "keywords": [
    "both automatic metrics",
    "human evaluation",
    "automatic summarization",
    "summaries",
    "model",
    "metric",
    "human",
    "efficient",
    "metrics",
    "abstractive summarization",
    "the summaries",
    "question",
    "the generated summaries",
    "summarization",
    "we"
  ],
  "url": "https://aclanthology.org/2021.acl-long.536/",
  "provenance": {
    "collected_at": "2025-06-05 08:06:37",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}