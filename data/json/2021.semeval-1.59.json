{
  "id": "2021.semeval-1.59",
  "title": "ITNLP} at {S}em{E}val-2021 Task 11: Boosting {BERT} with Sampling and Adversarial Training for Knowledge Extraction",
  "authors": [
    "Zhang, Genyu  and\nSu, Yu  and\nHe, Changhong  and\nLin, Lei  and\nSun, Chengjie  and\nShan, Lili"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper describes the winning system in the End-to-end Pipeline phase for the NLPContributionGraph task. The system is composed of three BERT-based models and the three models are used to extract sentences, entities and triples respectively. Experiments show that sampling and adversarial training can greatly boost the system. In End-to-end Pipeline phase, our system got an average F1 of 0.4703, significantly higher than the second-placed system which got an average F1 of 0.3828.",
  "keywords": [
    "knowledge",
    "end",
    "extraction",
    "bert",
    "entities",
    "three bert-based models",
    "an average f1",
    "itnlp",
    "sentences entities",
    "nlpcontributiongraph",
    "the nlpcontributiongraph task",
    "training",
    "sampling",
    "task",
    "knowledge extraction"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.59/",
  "provenance": {
    "collected_at": "2025-06-05 08:20:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}