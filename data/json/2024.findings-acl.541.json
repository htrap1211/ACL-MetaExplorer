{
  "id": "2024.findings-acl.541",
  "title": "P4: Plug-and-Play Discrete Prompting for Large Language Models Personalization",
  "authors": [
    "Zhang, Yuansen  and\nWang, Xiao  and\nChen, Tianze  and\nFu, Jiayi  and\nGui, Tao  and\nZhang, Qi"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Empowering Large Language Models (LLMs) with distinct human-like personality traits has become an innovative task for developing advanced dialog systems.Although LLMs demonstrate impressive capabilities in following instructions, directly prompting them to exhibit certain personalities through manually crafted instructions may result in sub-optimal performance.In this paper, we propose a plug-and-play prompting method to manipulate the LLMs’ personality traits.Specifically, we append discrete personalized suffixes, automatically generated through an aggregated gradient-based search method, to the user query or dialog histories and induce LLMs to respond with target personalities.In addition, due to the high redundancy of the search space, we adopt a reward-based strategy to prune the vocabulary and focus exclusively on influential tokens.Experiment results on four models ranging from 1.1B to 13B show that our method achieves 79.9% accuracy in customizing LLMs’ personalities, significantly outperforming other prompting methods (65.5%) and model editing methods.Our method also excels in generation fluency and quality with the lowest generation perplexity and the highest GPT-4 evaluation scores.",
  "keywords": [
    "large language models personalization",
    "the llms",
    "we",
    "target personalities",
    "personalities",
    "79 9 accuracy",
    "a plug-and-play prompting method",
    "the lowest generation perplexity",
    "generation fluency",
    "other prompting methods",
    "impressive capabilities",
    "histories",
    "dialog histories",
    "llms",
    "perplexity"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.541/",
  "provenance": {
    "collected_at": "2025-06-05 10:56:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}