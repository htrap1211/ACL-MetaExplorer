{
  "id": "2023.acl-long.835",
  "title": "A Needle in a Haystack: An Analysis of High-Agreement Workers on {MT}urk for Summarization",
  "authors": [
    "Zhang, Lining  and\nMille, Simon  and\nHou, Yufang  and\nDeutsch, Daniel  and\nClark, Elizabeth  and\nLiu, Yixin  and\nMahamood, Saad  and\nGehrmann, Sebastian  and\nClinciu, Miruna  and\nChandu, Khyathi Raghavi  and\nSedoc, Jo{\\~a}o"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "To prevent the costly and inefficient use of resources on low-quality annotations, we want a method for creating a pool of dependable annotators who can effectively complete difficult tasks, such as evaluating automatic summarization. Thus, we investigate the recruitment of high-quality Amazon Mechanical Turk workers via a two-step pipeline. We show that we can successfully filter out subpar workers before they carry out the evaluations and obtain high-agreement annotations with similar constraints on resources. Although our workers demonstrate a strong consensus among themselves and CloudResearch workers, their alignment with expert judgments on a subset of the data is not as expected and needs further training in correctness. This paper still serves as a best practice for the recruitment of qualified annotators in other challenging annotation tasks.",
  "keywords": [
    "inefficient",
    "summarization",
    "we",
    "their alignment",
    "training",
    "qualified",
    "qualified annotators",
    "the evaluations",
    "analysis",
    "automatic summarization",
    "alignment",
    "evaluations",
    "correctness",
    "consensus",
    "dependable annotators"
  ],
  "url": "https://aclanthology.org/2023.acl-long.835/",
  "provenance": {
    "collected_at": "2025-06-05 09:47:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}