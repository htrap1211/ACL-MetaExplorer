{
  "id": "2022.insights-1.16",
  "title": "Do Data-based Curricula Work?",
  "authors": [
    "Surkov, Maxim  and\nMosin, Vladislav  and\nYamshchikov, Ivan P."
  ],
  "year": "2022",
  "venue": "Proceedings of the Third Workshop on Insights from Negative Results in NLP",
  "abstract": "Current state-of-the-art NLP systems use large neural networks that require extensive computational resources for training. Inspired by human knowledge acquisition, researchers have proposed curriculum learning - sequencing tasks (task-based curricula) or ordering and sampling the datasets (data-based curricula) that facilitate training. This work investigates the benefits of data-based curriculum learning for large language models such as BERT and T5. We experiment with various curricula based on complexity measures and different sampling strategies. Extensive experiments on several NLP tasks show that curricula based on various complexity measures rarely have any benefits, while random sampling performs either as well or better than curricula.",
  "keywords": [
    "work",
    "large neural networks",
    "knowledge",
    "language",
    "different sampling strategies",
    "random",
    "nlp",
    "bert",
    "neural",
    "human",
    "large language models",
    "strategies",
    "we",
    "several nlp tasks",
    "current"
  ],
  "url": "https://aclanthology.org/2022.insights-1.16/",
  "provenance": {
    "collected_at": "2025-06-05 08:43:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}