{
  "id": "2022.acl-long.84",
  "title": "Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension",
  "authors": [
    "Zhang, Huibin  and\nZhang, Zhengkun  and\nZhang, Yao  and\nWang, Jun  and\nLi, Yufan  and\nJiang, Ning  and\nWei, Xin  and\nYang, Zhenglu"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Procedural Multimodal Documents (PMDs) organize textual instructions and corresponding images step by step. Comprehending PMDs and inducing their representations for the downstream reasoning tasks is designated as Procedural MultiModal Machine Comprehension (M3C). In this study, we approach Procedural M3C at a fine-grained level (compared with existing explorations at a document or sentence level), that is, entity. With delicate consideration, we model entity both in its temporal and cross-modal relation and propose a novel Temporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated to capture textual and visual entities and trace their temporal-modal evolution. In addition, a graph aggregation module is introduced to conduct graph encoding and reasoning. Comprehensive experiments across three Procedural M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset CraftQA, which can better evaluate the generalization of TMEG.",
  "keywords": [
    "cross",
    "machine",
    "entities",
    "craftqa",
    "textual and visual entities",
    "the generalization",
    "generalization",
    "a traditional dataset recipeqa",
    "recipeqa",
    "we",
    "visual",
    "graph",
    "entity",
    "our new dataset craftqa",
    "that"
  ],
  "url": "https://aclanthology.org/2022.acl-long.84/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}