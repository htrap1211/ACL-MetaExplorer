{
  "id": "2024.langmol-1.12",
  "title": "M}ol2{L}ang-{VLM}: Vision- and Text-Guided Generative Pre-trained Language Models for Advancing Molecule Captioning through Multimodal Fusion",
  "authors": [
    "Tran, Duong  and\nPham, Nhat Truong  and\nNguyen, Nguyen  and\nManavalan, Balachandran"
  ],
  "year": "2024",
  "venue": "Proceedings of the 1st Workshop on Language + Molecules (L+M 2024)",
  "abstract": "This paper introduces Mol2Lang-VLM, an enhanced method for refining generative pre-trained language models for molecule captioning using multimodal features to achieve more accurate caption generation. Our approach leverages the encoder and decoder blocks of the Transformer-based architecture by introducing third sub-layers into both. Specifically, we insert sub-layers in the encoder to fuse features from SELFIES strings and molecular images, while the decoder fuses features from SMILES strings and their corresponding descriptions. Moreover, cross multi-head attention is employed instead of common multi-head attention to enable the decoder to attend to the encoder’s output, thereby integrating the encoded contextual information for better and more accurate caption generation. Performance evaluation on the CheBI-20 and L+M-24 benchmark datasets demonstrates Mol2Lang-VLM’s superiority, achieving higher accuracy and quality in caption generation compared to existing methods. Our code and pre-processed data are available at https://github.com/nhattruongpham/mol-lang-bridge/tree/mol2lang/.",
  "keywords": [
    "code",
    "the transformer-based architecture",
    "the encoder s output",
    "the decoder",
    "we",
    "fusion",
    "selfies",
    "generative pre-trained language models",
    "lang",
    "the encoder",
    "common multi-head attention",
    "decoder",
    "information",
    "higher accuracy",
    "more accurate caption generation"
  ],
  "url": "https://aclanthology.org/2024.langmol-1.12/",
  "provenance": {
    "collected_at": "2025-06-05 11:07:45",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}