{
  "id": "2023.acl-long.208",
  "title": "Free Lunch for Efficient Textual Commonsense Integration in Language Models",
  "authors": [
    "Cui, Wanyun  and\nChen, Xingran"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Recent years have witnessed the emergence of textual commonsense knowledge bases, aimed at providing more nuanced and context-rich knowledge. The integration of external commonsense into language models has been shown to be a key enabler in advancing the state-of-the-art for a wide range of NLP tasks. However, incorporating textual commonsense descriptions is computationally expensive, as compared to encoding conventional symbolic knowledge. In this paper, we propose a method to improve its efficiency without modifying the model. Our idea is to group training samples with similar commonsense descriptions into a single batch, thus reusing the encoded description across multiple samples. We theoretically investigate this problem and demonstrate that its upper bound can be reduced to the classicgraph k-cut problem. Consequently, we propose a spectral clustering-based algorithm to solve this problem. Extensive experiments illustrate that the proposed batch partitioning approach effectively reduces the computational cost while preserving performance. The efficiency improvement is more pronounced on larger datasets and on devices with more memory capacity, attesting to its practical utility for large-scale applications.",
  "keywords": [
    "its efficiency",
    "efficient",
    "a spectral clustering-based algorithm",
    "efficiency",
    "we",
    "training",
    "rich",
    "nlp tasks",
    "the efficiency improvement",
    "language models",
    "knowledge",
    "language",
    "nlp",
    "model",
    "efficient textual commonsense integration"
  ],
  "url": "https://aclanthology.org/2023.acl-long.208/",
  "provenance": {
    "collected_at": "2025-06-05 09:38:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}