{
  "id": "2024.cmcl-1.14",
  "title": "How can large language models become more human?",
  "authors": [
    "Wang, Daphne  and\nSadrzadeh, Mehrnoosh  and\nStanojevi{\\'c}, Milo{\\v{s}}  and\nChow, Wing-Yee  and\nBreheny, Richard"
  ],
  "year": "2024",
  "venue": "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
  "abstract": "Psycholinguistic experiments reveal that efficiency of human language use is founded on predictions at both syntactic and lexical levels. Previous models of human prediction exploiting LLMs have used an information theoretic measure calledsurprisal, with success on naturalistic text in a wide variety of languages, but under-performance on challenging text such as garden path sentences. This paper introduces a novel framework that combines the lexical predictions of an LLM with the syntactic structures provided by a dependency parser. The framework gives rise to anIncompatibility Fraction. When tested on two garden path datasets, it correlated well with human reading times, distinguished between easy and hard garden path, and outperformed surprisal.",
  "keywords": [
    "variety",
    "human prediction exploiting llms",
    "language",
    "text",
    "it",
    "human",
    "an llm",
    "information",
    "efficiency",
    "dependency",
    "a wide variety",
    "a dependency parser",
    "llm",
    "llms",
    "naturalistic text"
  ],
  "url": "https://aclanthology.org/2024.cmcl-1.14/",
  "provenance": {
    "collected_at": "2025-06-05 11:05:37",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}