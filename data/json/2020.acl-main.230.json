{
  "id": "2020.acl-main.230",
  "title": "Cross-media Structured Common Space for Multimedia Event Extraction",
  "authors": [
    "Li, Manling  and\nZareian, Alireza  and\nZeng, Qi  and\nWhitehead, Spencer  and\nLu, Di  and\nJi, Heng  and\nChang, Shih-Fu"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "We introduce a new task, MultiMedia Event Extraction, which aims to extract events and their arguments from multimedia documents. We develop the first benchmark and collect a dataset of 245 multimedia news articles with extensively annotated events and arguments. We propose a novel method, Weakly Aligned Structured Embedding (WASE), that encodes structured representations of semantic information from textual and visual data into a common embedding space. The structures are aligned across modalities by employing a weakly supervised training strategy, which enables exploiting available resources without explicit cross-media annotation. Compared to uni-modal state-of-the-art methods, our approach achieves 4.0% and 9.8% absolute F-score gains on text event argument role labeling and visual event extraction. Compared to state-of-the-art multimedia unstructured representations, we achieve 8.3% and 5.0% absolute F-score gains on multimedia event extraction and argument role labeling, respectively. By utilizing images, we extract 21.4% more event mentions than traditional text-only methods.",
  "keywords": [
    "cross",
    "extraction",
    "uni",
    "text",
    "modalities",
    "information",
    "semantic",
    "we",
    "semantic information",
    "visual",
    "a common embedding space",
    "training",
    "that",
    "a novel method",
    "documents"
  ],
  "url": "https://aclanthology.org/2020.acl-main.230/",
  "provenance": {
    "collected_at": "2025-06-05 07:45:18",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}