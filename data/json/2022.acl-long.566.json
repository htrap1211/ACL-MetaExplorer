{
  "id": "2022.acl-long.566",
  "title": "Uncertainty Estimation of Transformer Predictions for Misclassification Detection",
  "authors": [
    "Vazhentsev, Artem  and\nKuzmin, Gleb  and\nShelmanov, Artem  and\nTsvigun, Akim  and\nTsymbalov, Evgenii  and\nFedyanin, Kirill  and\nPanov, Maxim  and\nPanchenko, Alexander  and\nGusev, Gleb  and\nBurtsev, Mikhail  and\nAvetisian, Manvel  and\nZhukov, Leonid"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Uncertainty estimation (UE) of model predictions is a crucial step for a variety of tasks such as active learning, misclassification detection, adversarial attack detection, out-of-distribution detection, etc. Most of the works on modeling the uncertainty of deep neural networks evaluate these methods on image classification tasks. Little attention has been paid to UE in natural language processing. To fill this gap, we perform a vast empirical investigation of state-of-the-art UE methods for Transformer models on misclassification detection in named entity recognition and text classification tasks and propose two computationally efficient modifications, one of which approaches or even outperforms computationally intensive methods.",
  "keywords": [
    "deep",
    "transformer",
    "variety",
    "processing",
    "transformer models",
    "language",
    "classification tasks",
    "neural",
    "natural",
    "model",
    "efficient",
    "misclassification",
    "two computationally efficient modifications",
    "little attention",
    "deep neural networks"
  ],
  "url": "https://aclanthology.org/2022.acl-long.566/",
  "provenance": {
    "collected_at": "2025-06-05 08:31:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}