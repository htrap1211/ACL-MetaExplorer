{
  "id": "2024.findings-acl.819",
  "title": "Complex Logical Query Answering by Calibrating Knowledge Graph Completion Models",
  "authors": [
    "Xiao, Changyi  and\nCao, Yixin"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Complex logical query answering (CLQA) is a challenging task that involves finding answer entities for complex logical queries over incomplete knowledge graphs (KGs). Previous research has explored the use of pre-trained knowledge graph completion (KGC) models, which can predict the missing facts in KGs, to answer complex logical queries. However, KGC models are typically evaluated using ranking evaluation metrics, which may result in values of predictions of KGC models that are not well-calibrated. In this paper, we propose a method for calibrating KGC models, namely CKGC, which enables KGC models to adapt to answering complex logical queries. Notably, CKGC is lightweight and effective. The adaptation function is simple, allowing the model to quickly converge during the adaptation process. The core concept of CKGC is to map the values of predictions of KGC models to the range [0, 1], ensuring that values associated with true facts are close to 1, while values linked to false facts are close to 0. Through experiments on three benchmark datasets, we demonstrate that our proposed calibration method can significantly boost model performance in the CLQA task. Moreover, our approach can enhance the performance of CLQA while preserving the ranking evaluation metrics of KGC models. The code is available at https://github.com/changyi7231/CKGC.",
  "keywords": [
    "the ranking evaluation metrics",
    "code",
    "answering clqa",
    "complex logical queries",
    "namely ckgc",
    "kgc",
    "we",
    "graph",
    "clqa",
    "incomplete knowledge graphs",
    "answer",
    "queries",
    "kgs",
    "core",
    "metrics"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.819/",
  "provenance": {
    "collected_at": "2025-06-05 10:59:46",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}