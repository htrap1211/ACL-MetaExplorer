{
  "id": "2021.acl-long.229",
  "title": "Rational {LAMOL}: A Rationale-based Lifelong Learning Framework",
  "authors": [
    "Kanwatchara, Kasidis  and\nHorsuwan, Thanapapas  and\nLertvittayakumjorn, Piyawat  and\nKijsirikul, Boonserm  and\nVateekul, Peerapon"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Lifelong learning (LL) aims to train a neural network on a stream of tasks while retaining knowledge from previous tasks. However, many prior attempts in NLP still suffer from the catastrophic forgetting issue, where the model completely forgets what it just learned in the previous tasks. In this paper, we introduce Rational LAMOL, a novel end-to-end LL framework for language models. In order to alleviate catastrophic forgetting, Rational LAMOL enhances LAMOL, a recent LL model, by applying critical freezing guided by human rationales. When the human rationales are not available, we propose exploiting unsupervised generated rationales as substitutions. In the experiment, we tested Rational LAMOL on permutations of three datasets from the ERASER benchmark. The results show that our proposed framework outperformed vanilla LAMOL on most permutations. Furthermore, unsupervised rationale generation was able to consistently improve the overall LL performance from the baseline without relying on human-annotated rationales.",
  "keywords": [
    "knowledge",
    "end",
    "a neural network",
    "language",
    "generation",
    "neural",
    "nlp",
    "model",
    "it",
    "human",
    "furthermore unsupervised rationale generation",
    "language models",
    "unsupervised generated rationales",
    "network",
    "we"
  ],
  "url": "https://aclanthology.org/2021.acl-long.229/",
  "provenance": {
    "collected_at": "2025-06-05 08:02:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}