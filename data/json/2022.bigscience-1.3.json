{
  "id": "2022.bigscience-1.3",
  "title": "You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings",
  "authors": [
    "Talat, Zeerak  and\nN{\\'e}v{\\'e}ol, Aur{\\'e}lie  and\nBiderman, Stella  and\nClinciu, Miruna  and\nDey, Manan  and\nLongpre, Shayne  and\nLuccioni, Sasha  and\nMasoud, Maraim  and\nMitchell, Margaret  and\nRadev, Dragomir  and\nSharma, Shanya  and\nSubramonian, Arjun  and\nTae, Jaesung  and\nTan, Samson  and\nTunuguntla, Deepak  and\nVan Der Wal, Oskar"
  ],
  "year": "2022",
  "venue": "Proceedings of BigScience Episode {\\#}5 -- Workshop on Challenges {\\&} Perspectives in Creating Large Language Models",
  "abstract": "Evaluating bias, fairness, and social impact in monolingual language models is a difficult task. This challenge is further compounded when language modeling occurs in a multilingual context. Considering the implication of evaluation biases for large multilingual language models, we situate the discussion of bias evaluation within a wider context of social scientific research with computational work. We highlight three dimensions of developing multilingual bias evaluation frameworks: (1) increasing transparency through documentation, (2) expanding targets of bias beyond gender, and (3) addressing cultural differences that exist between languages. We further discuss the power dynamics and consequences of training large language models and recommend that researchers remain cognizant of the ramifications of developing such technologies.",
  "keywords": [
    "work",
    "bias fairness",
    "social scientific research",
    "bias",
    "language",
    "bias evaluation",
    "large multilingual language models",
    "such technologies",
    "large language models",
    "modeling",
    "monolingual language models",
    "evaluation biases",
    "technologies",
    "we",
    "evaluation"
  ],
  "url": "https://aclanthology.org/2022.bigscience-1.3/",
  "provenance": {
    "collected_at": "2025-06-05 08:39:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}