{
  "id": "2022.bionlp-1.26",
  "title": "Inter-annotator agreement is not the ceiling of machine learning performance: Evidence from a comprehensive set of simulations",
  "authors": [
    "Richie, Russell  and\nGrover, Sachin  and\nTsui, Fuchiang (Rich)"
  ],
  "year": "2022",
  "venue": "Proceedings of the 21st Workshop on Biomedical Language Processing",
  "abstract": "It is commonly claimed that inter-annotator agreement (IAA) is the ceiling of machine learning (ML) performance, i.e., that the agreement between an ML systemâ€™s predictions and an annotator can not be higher than the agreement between two annotators. Although Boguslav & Cohen (2017) showed that this claim is falsified by many real-world ML systems, the claim has persisted. As a complement to this real-world evidence, we conducted a comprehensive set of simulations, and show that an ML model can beat IAA even if (and especially if) annotators are noisy and differ in their underlying classification functions, as long as the ML model is reasonably well-specified. Although the latter condition has long been elusive, leading ML models to underperform IAA, we anticipate that this condition will be increasingly met in the era of big data and deep learning. Our work has implications for (1) maximizing the value of machine learning, (2) adherence to ethical standards in computing, and (3) economical use of annotated resources, which is paramount in settings where annotation is especially expensive, like biomedical natural language processing.",
  "keywords": [
    "deep",
    "their underlying classification functions",
    "era",
    "we",
    "classification",
    "natural",
    "it",
    "biomedical natural language processing",
    "machine learning",
    "learning",
    "processing",
    "i",
    "machine learning performance evidence",
    "work",
    "specified"
  ],
  "url": "https://aclanthology.org/2022.bionlp-1.26/",
  "provenance": {
    "collected_at": "2025-06-05 08:39:53",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}