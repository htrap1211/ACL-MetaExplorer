{
  "id": "2020.iwslt-1.7",
  "title": "End-to-End Offline Speech Translation System for {IWSLT} 2020 using Modality Agnostic Meta-Learning",
  "authors": [
    "Lakumarapu, Nikhil Kumar  and\nLee, Beomseok  and\nIndurthi, Sathish Reddy  and\nHan, Hou Jeung  and\nZaidi, Mohd Abbas  and\nKim, Sangha"
  ],
  "year": "2020",
  "venue": "Proceedings of the 17th International Conference on Spoken Language Translation",
  "abstract": "In this paper, we describe the system submitted to the IWSLT 2020 Offline Speech Translation Task. We adopt the Transformer architecture coupled with the meta-learning approach to build our end-to-end Speech-to-Text Translation (ST) system. Our meta-learning approach tackles the data scarcity of the ST task by leveraging the data available from Automatic Speech Recognition (ASR) and Machine Translation (MT) tasks. The meta-learning approach combined with synthetic data augmentation techniques improves the model performance significantly and achieves BLEU scores of 24.58, 27.51, and 27.61 on IWSLT test 2015, MuST-C test, and Europarl-ST test sets respectively.",
  "keywords": [
    "transformer",
    "end",
    "model",
    "machine",
    "text",
    "bleu",
    "machine translation",
    "we",
    "learning",
    "bleu scores",
    "the transformer architecture",
    "translation",
    "speech",
    "recognition",
    "approach"
  ],
  "url": "https://aclanthology.org/2020.iwslt-1.7/",
  "provenance": {
    "collected_at": "2025-06-05 07:56:32",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}