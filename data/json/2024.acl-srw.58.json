{
  "id": "2024.acl-srw.58",
  "title": "Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models",
  "authors": [
    "Kim, Yunsoo"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
  "abstract": "Transformer model has been a de-facto standard in natural language processing. Its adaptations in other fields such as computer vision showed promising results that this architecture is a powerful neural network in representation learning regardless of the data type. This recent success has led to research in multimodal Large Language Model (LLM), which enabled us to new types of tasks and applications with multiple data types. However, multimodal LLM in the biomedical domain is primarily limited to images, text, and/or sequence data. Here I propose to work on multimodal LLM architecture for biomedical graphs such as protein structure and chemical molecules. The research hypothesis is based on the fact that clinicians and researchers in computational biology and clinical research take advantage of various information for their decision-making process. Therefore, an AI model being able to handle multiple data types should boost its ability to use diverse knowledge for improved performances in clinical applications.",
  "keywords": [
    "a powerful neural network",
    "fields",
    "llm",
    "neural",
    "natural",
    "other fields",
    "multimodal llm architecture",
    "information",
    "knowledge graphs",
    "learning",
    "sequence",
    "natural language",
    "i",
    "text",
    "transformer"
  ],
  "url": "https://aclanthology.org/2024.acl-srw.58/",
  "provenance": {
    "collected_at": "2025-06-05 10:48:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}