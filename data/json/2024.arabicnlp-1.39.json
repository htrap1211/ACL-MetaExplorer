{
  "id": "2024.arabicnlp-1.39",
  "title": "SENIT} at {A}ra{F}in{NLP}2024: trust your model or combine two",
  "authors": [
    "Nasr, Abdelmomen  and\nBen HajHmida, Moez"
  ],
  "year": "2024",
  "venue": "Proceedings of the Second Arabic Natural Language Processing Conference",
  "abstract": "We describe our submitted system to the 2024 Shared Task on The Arabic Financial NLP (Malaysha et al., 2024). We tackled Subtask 1, namely Multi-dialect Intent Detection. We used state-of-the-art pretrained contextualized text representation models and fine-tuned them according to the downstream task at hand. We started by finetuning multilingual BERT and various Arabic variants, namely MARBERTV1, MARBERTV2, and CAMeLBERT. Then, we employed an ensembling technique to improve our classification performance combining MARBERTV2 and CAMeLBERT embeddings. The findings indicate that MARBERTV2 surpassed all the other models mentioned.",
  "keywords": [
    "embeddings",
    "marbertv2",
    "nlp",
    "bert",
    "model",
    "text",
    "the arabic financial nlp",
    "marbertv2 and camelbert embeddings",
    "marbertv1",
    "we",
    "namely marbertv1 marbertv2",
    "camelbert",
    "classification",
    "our classification performance",
    "multilingual bert"
  ],
  "url": "https://aclanthology.org/2024.arabicnlp-1.39/",
  "provenance": {
    "collected_at": "2025-06-05 11:02:43",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}