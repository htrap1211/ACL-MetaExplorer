{
  "id": "2020.acl-main.185",
  "title": "Negative Training for Neural Dialogue Response Generation",
  "authors": [
    "He, Tianxing  and\nGlass, James"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Although deep learning models have brought tremendous advancements to the field of open-domain dialogue response generation, recent research results have revealed that the trained models have undesirable generation behaviors, such as malicious responses and generic (boring) responses. In this work, we propose a framework named “Negative Training” to minimize such behaviors. Given a trained model, the framework will first find generated samples that exhibit the undesirable behavior, and then use them to feed negative training signals for fine-tuning the model. Our experiments show that negative training can significantly reduce the hit rate of malicious responses, or discourage frequent responses and improve response diversity.",
  "keywords": [
    "deep learning models",
    "deep",
    "work",
    "undesirable generation behaviors",
    "generation",
    "generated samples",
    "neural",
    "the field",
    "model",
    "rate",
    "neural dialogue response generation",
    "generic",
    "generic boring responses",
    "field",
    "fine"
  ],
  "url": "https://aclanthology.org/2020.acl-main.185/",
  "provenance": {
    "collected_at": "2025-06-05 07:44:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}