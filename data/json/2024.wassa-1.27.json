{
  "id": "2024.wassa-1.27",
  "title": "LLM}s for Targeted Sentiment in News Headlines: Exploring the Descriptive-Prescriptive Dilemma",
  "authors": [
    "Juro{\\v{s}}, Jana  and\nMajer, Laura  and\nSnajder, Jan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis",
  "abstract": "News headlines often evoke sentiment by intentionally portraying entities in particular ways, making targeted sentiment analysis (TSA) of headlines a worthwhile but difficult task. Due to its subjectivity, creating TSA datasets can involve various annotation paradigms, from descriptive to prescriptive, either encouraging or limiting subjectivity. LLMs are a good fit for TSA due to their broad linguistic and world knowledge and in-context learning abilities, yet their performance depends on prompt design. In this paper, we compare the accuracy of state-of-the-art LLMs and fine-tuned encoder models for TSA of news headlines using descriptive and prescriptive datasets across several languages. Exploring the descriptiveâ€“prescriptive continuum, we analyze how performance is affected by prompt prescriptiveness, ranging from plain zero-shot to elaborate few-shot prompts. Finally, we evaluate the ability of LLMs to quantify uncertainty via calibration error and comparison to human label variation. We find that LLMs outperform fine-tuned encoders on descriptive datasets, while calibration and F1-score generally improve with increased prescriptiveness, yet the optimal level varies.",
  "keywords": [
    "fine-tuned encoders",
    "the accuracy",
    "fit",
    "prompt prescriptiveness",
    "fine-tuned encoder models",
    "we",
    "llm",
    "shot",
    "plain zero-shot",
    "subjectivity llms",
    "f1-score",
    "few-shot prompts",
    "analysis",
    "llms",
    "targeted sentiment analysis tsa"
  ],
  "url": "https://aclanthology.org/2024.wassa-1.27/",
  "provenance": {
    "collected_at": "2025-06-05 11:11:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}