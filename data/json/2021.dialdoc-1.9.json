{
  "id": "2021.dialdoc-1.9",
  "title": "Ensemble {ALBERT} and {R}o{BERT}a for Span Prediction in Question Answering",
  "authors": [
    "Bachina, Sony  and\nBalumuri, Spandana  and\nKamath S, Sowmya"
  ],
  "year": "2021",
  "venue": "Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021)",
  "abstract": "Retrieving relevant answers from heterogeneous data formats, for given for questions, is a challenging problem. The process of pinpointing relevant information suitable to answer a question is further compounded in large document collections containing documents of substantial length. This paper presents the models designed as part of our submission to the DialDoc21 Shared Task (Document-grounded Dialogue and Conversational Question Answering) for span prediction in question answering. The proposed models leverage the superior predictive power of pretrained transformer models like RoBERTa, ALBERT and ELECTRA, to identify the most relevant information in an associated passage for the next agent turn. To further enhance the performance, the models were fine-tuned on different span selection based question answering datasets like SQuAD2.0 and Natural Questions (NQ) corpus. We also explored ensemble techniques for combining multiple models to achieve enhanced performance for the task. Our team SB_NITK ranked 6th on the leaderboard for the Knowledge Identification task, and our best ensemble model achieved an Exact score of 58.58 and an F1 score of 73.39.",
  "keywords": [
    "ensemble albert",
    "roberta",
    "our best ensemble model",
    "ensemble techniques",
    "question",
    "we",
    "dialogue",
    "conversational question",
    "roberta albert",
    "ensemble",
    "natural",
    "albert",
    "pretrained transformer models",
    "information",
    "a"
  ],
  "url": "https://aclanthology.org/2021.dialdoc-1.9/",
  "provenance": {
    "collected_at": "2025-06-05 08:16:43",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}