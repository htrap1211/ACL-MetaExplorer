{
  "id": "2020.acl-demos.12",
  "title": "Multilingual Universal Sentence Encoder for Semantic Retrieval",
  "authors": [
    "Yang, Yinfei  and\nCer, Daniel  and\nAhmad, Amin  and\nGuo, Mandy  and\nLaw, Jax  and\nConstant, Noah  and\nHernandez Abrego, Gustavo  and\nYuan, Steve  and\nTar, Chris  and\nSung, Yun-hsuan  and\nStrope, Brian  and\nKurzweil, Ray"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "We present easy-to-use retrieval focused multilingual sentence embedding models, made available on TensorFlow Hub. The models embed text from 16 languages into a shared semantic space using a multi-task trained dual-encoder that learns tied cross-lingual representations via translation bridge tasks (Chidambaram et al., 2018). The models achieve a new state-of-the-art in performance on monolingual and cross-lingual semantic retrieval (SR). Competitive performance is obtained on the related tasks of translation pair bitext retrieval (BR) and retrieval question answering (ReQA). On transfer learning tasks, our multilingual embeddings approach, and in some cases exceed, the performance of English only sentence embeddings.",
  "keywords": [
    "cross",
    "embeddings",
    "a multi-task trained dual-encoder",
    "text",
    "transfer learning tasks",
    "reqa",
    "semantic retrieval",
    "tied cross-lingual representations",
    "encoder",
    "retrieval question",
    "retrieval",
    "question",
    "english only sentence embeddings",
    "semantic",
    "we"
  ],
  "url": "https://aclanthology.org/2020.acl-demos.12/",
  "provenance": {
    "collected_at": "2025-06-05 07:52:50",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}