{
  "id": "2020.acl-main.535",
  "title": "Paraphrase Generation by Learning How to Edit from Samples",
  "authors": [
    "Kazemnejad, Amirhossein  and\nSalehi, Mohammadreza  and\nSoleymani Baghshah, Mahdieh"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Neural sequence to sequence text generation has been proved to be a viable approach to paraphrase generation. Despite promising results, paraphrases generated by these models mostly suffer from lack of quality and diversity. To address these problems, we propose a novel retrieval-based method for paraphrase generation. Our model first retrieves a paraphrase pair similar to the input sentence from a pre-defined index. With its novel editor module, the model then paraphrases the input sequence by editing it using the extracted relations between the retrieved pair of sentences. In order to have fine-grained control over the editing process, our model uses the newly introduced concept of Micro Edit Vectors. It both extracts and exploits these vectors using the attention mechanism in the Transformer architecture. Experimental results show the superiority of our paraphrase generation method in terms of both automatic metrics, and human evaluation of relevance, grammaticality, and diversity of generated paraphrases.",
  "keywords": [
    "paraphrase generation",
    "we",
    "text generation",
    "human evaluation",
    "neural",
    "generated paraphrases",
    "it",
    "a novel retrieval-based method",
    "retrieval",
    "sequence",
    "our paraphrase generation method",
    "text",
    "metrics",
    "both automatic metrics",
    "transformer"
  ],
  "url": "https://aclanthology.org/2020.acl-main.535/",
  "provenance": {
    "collected_at": "2025-06-05 07:49:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}