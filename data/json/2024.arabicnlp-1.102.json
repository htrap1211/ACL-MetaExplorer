{
  "id": "2024.arabicnlp-1.102",
  "title": "mu{NER}a at {W}ojood{NER} 2024: Multi-tasking {NER} Approach",
  "authors": [
    "Alotaibi, Nouf  and\nAlhomoud, Haneen  and\nMurayshid, Hanan  and\nAlshammari, Waad  and\nAlshalawi, Nouf  and\nAlkhereyf, Sakhar"
  ],
  "year": "2024",
  "venue": "Proceedings of the Second Arabic Natural Language Processing Conference",
  "abstract": "This paper presents our system “muNERa”, submitted to the WojoodNER 2024 shared task at the second ArabicNLP conference. We participated in two subtasks, the flat and nested fine-grained NER sub-tasks (1 and 2). muNERa achieved first place in the nested NER sub-task and second place in the flat NER sub-task. The system is based on the TANL framework (CITATION),by using a sequence-to-sequence structured language translation approach to model both tasks. We utilize the pre-trained AraT5v2-base model as the base model for the TANL framework. The best-performing muNERa model achieves 91.07% and 90.26% for the F-1 scores on the test sets for the nested and flat subtasks, respectively.",
  "keywords": [
    "munera",
    "ner",
    "language",
    "model",
    "our system munera",
    "-",
    "the second arabicnlp conference",
    "the wojoodner",
    "the best-performing munera model",
    "mu ner",
    "we",
    "sequence",
    "pre",
    "the flat ner",
    "a"
  ],
  "url": "https://aclanthology.org/2024.arabicnlp-1.102/",
  "provenance": {
    "collected_at": "2025-06-05 11:03:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}