{
  "id": "2020.acl-main.244",
  "title": "Pretrained Transformers Improve Out-of-Distribution Robustness",
  "authors": [
    "Hendrycks, Dan  and\nLiu, Xiaoyuan  and\nWallace, Eric  and\nDziedzic, Adam  and\nKrishnan, Rishabh  and\nSong, Dawn"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Although pretrained Transformers such as BERT achieve high accuracy on in-distribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformersâ€™ performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness.",
  "keywords": [
    "work",
    "pretrained transformers",
    "bag",
    "transformers",
    "substantially smaller pretrained transformers",
    "nlp",
    "bert",
    "the generalization",
    "high accuracy",
    "lstms",
    "pretrained transformers performance declines",
    "generalization",
    "we",
    "seven nlp datasets",
    "accuracy"
  ],
  "url": "https://aclanthology.org/2020.acl-main.244/",
  "provenance": {
    "collected_at": "2025-06-05 07:45:29",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}