{
  "id": "2022.acl-long.491",
  "title": "Incorporating Hierarchy into Text Encoder: a Contrastive Learning Approach for Hierarchical Text Classification",
  "authors": [
    "Wang, Zihan  and\nWang, Peiyi  and\nHuang, Lianzhe  and\nSun, Xin  and\nWang, Houfeng"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Hierarchical text classification is a challenging subtask of multi-label classification due to its complex label hierarchy. Existing methods encode text and label hierarchy separately and mix their representations for classification, where the hierarchy remains unchanged for all input text. Instead of modeling them separately, in this work, we propose Hierarchy-guided Contrastive Learning (HGCLR) to directly embed the hierarchy into a text encoder. During training, HGCLR constructs positive samples for input text under the guidance of the label hierarchy. By pulling together the input text and its positive sample, the text encoder can learn to generate the hierarchy-aware text representation independently. Therefore, after training, the HGCLR enhanced text encoder can dispense with the redundant hierarchy. Extensive experiments on three benchmark datasets verify the effectiveness of HGCLR.",
  "keywords": [
    "work",
    "hierarchical",
    "text",
    "encode",
    "multi-label classification",
    "text encoder",
    "a text encoder",
    "encoder",
    "the hierarchy",
    "the hierarchy-aware text representation",
    "hierarchy-guided contrastive learning hgclr",
    "hierarchy",
    "the label hierarchy",
    "we",
    "learning"
  ],
  "url": "https://aclanthology.org/2022.acl-long.491/",
  "provenance": {
    "collected_at": "2025-06-05 08:30:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}