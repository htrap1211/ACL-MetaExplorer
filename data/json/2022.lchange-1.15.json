{
  "id": "2022.lchange-1.15",
  "title": "Roadblocks in Gender Bias Measurement for Diachronic Corpora",
  "authors": [
    "Alshahrani, Saied  and\nWali, Esma  and\nR Alshamsan, Abdullah  and\nChen, Yan  and\nMatthews, Jeanna"
  ],
  "year": "2022",
  "venue": "Proceedings of the 3rd Workshop on Computational Approaches to Historical Language Change",
  "abstract": "The use of word embeddings is an important NLP technique for extracting meaningful conclusions from corpora of human text. One important question that has been raised about word embeddings is the degree of gender bias learned from corpora. Bolukbasi et al. (2016) proposed an important technique for quantifying gender bias in word embeddings that, at its heart, is lexically based and relies on sets of highly gendered word pairs (e.g., mother/father and madam/sir) and a list of professions words (e.g., doctor and nurse). In this paper, we document problems that arise with this method to quantify gender bias in diachronic corpora. Focusing on Arabic and Chinese corpora, in particular, we document clear changes in profession words used over time and, somewhat surprisingly, even changes in the simpler gendered defining set word pairs. We further document complications in languages such as Arabic, where many words are highly polysemous/homonymous, especially female professions words.",
  "keywords": [
    "gender bias measurement",
    "bias",
    "al",
    "question",
    "we",
    "an important nlp technique",
    "word",
    "et",
    "text",
    "word embeddings",
    "madam",
    "embeddings",
    "nlp",
    "human",
    "gender bias"
  ],
  "url": "https://aclanthology.org/2022.lchange-1.15/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:08",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}