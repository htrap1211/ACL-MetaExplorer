{
  "id": "2023.acl-long.329",
  "title": "Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination",
  "authors": [
    "Fei, Hao  and\nLiu, Qian  and\nZhang, Meishan  and\nZhang, Min  and\nChua, Tat-Seng"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "In this work, we investigate a more realistic unsupervised multimodal machine translation (UMMT) setup, inference-time image-free UMMT, where the model is trained with source-text image pairs, and tested with only source-text inputs. First, we represent the input images and texts with the visual and language scene graphs (SG), where such fine-grained vision-language features ensure a holistic understanding of the semantics. To enable pure-text input during inference, we devise a visual scene hallucination mechanism that dynamically generates pseudo visual SG from the given textual SG. Several SG-pivoting based learning objectives are introduced for unsupervised translation training. On the benchmark Multi30K data, our SG-based method outperforms the best-performing baseline by significant BLEU scores on the task and setup, helping yield translations with better completeness, relevance and fluency without relying on paired images. Further in-depth analyses reveal how our model advances in the task setting.",
  "keywords": [
    "objectives",
    "significant bleu scores",
    "yield",
    "the semantics",
    "bleu",
    "we",
    "graph",
    "yield translations",
    "training",
    "translation",
    "semantics",
    "visual",
    "text",
    "work",
    "language"
  ],
  "url": "https://aclanthology.org/2023.acl-long.329/",
  "provenance": {
    "collected_at": "2025-06-05 09:39:53",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}