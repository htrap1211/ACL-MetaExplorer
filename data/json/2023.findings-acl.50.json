{
  "id": "2023.findings-acl.50",
  "title": "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors",
  "authors": [
    "Zhang, Kai  and\nJimenez Gutierrez, Bernal  and\nSu, Yu"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instruction-tuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to REâ€™s low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al. 2022). To address this limitation, we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets. Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA.",
  "keywords": [
    "even advanced instruction-tuned llms",
    "extraction",
    "series",
    "question",
    "we",
    "llm",
    "shot",
    "instruction",
    "zero-shot relation extractors",
    "six llms",
    "information",
    "strong zero-shot baselines",
    "nlp tasks",
    "fine-tuning large language models",
    "llms"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.50/",
  "provenance": {
    "collected_at": "2025-06-05 09:53:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}