{
  "id": "2023.findings-acl.357",
  "title": "Frustratingly Easy Label Projection for Cross-lingual Transfer",
  "authors": [
    "Chen, Yang  and\nJiang, Chao  and\nRitter, Alan  and\nXu, Wei"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Translating training data into many languages has emerged as a practical solution for improving cross-lingual transfer. For tasks that involve span-level annotations, such as information extraction or question answering, an additional label projection step is required to map annotated spans onto the translated texts. Recently, a few efforts have utilized a simple mark-then-translate method to jointly perform translation and projection by inserting special markers around the labeled spans in the original sentence. However, as far as we are aware, no empirical analysis has been conducted on how this approach compares to traditional annotation projection based on word alignment. In this paper, we present an extensive empirical study across 57 languages and three tasks (QA, NER, and Event Extraction) to evaluate the effectiveness and limitations of both methods, filling an important gap in the literature. Experimental results show that our optimized version of mark-then-translate, which we call EasyProject, is easily applied to many languages and works surprisingly well, outperforming the more complex word alignment-based methods. We analyze several key factors that affect the end-task performance, and show EasyProject works well because it can accurately preserve label span boundaries after translation. We will publicly release all our code and data.",
  "keywords": [
    "code",
    "end",
    "extraction",
    "question",
    "we",
    "training",
    "translation",
    "cross",
    "it",
    "information",
    "word",
    "transfer",
    "analysis",
    "ner",
    "word alignment"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.357/",
  "provenance": {
    "collected_at": "2025-06-05 09:58:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}