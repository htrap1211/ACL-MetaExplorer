{
  "id": "2024.sdp-1.23",
  "title": "Simulating Expert Discussions with Multi-agent for Enhanced Scientific Problem Solving",
  "authors": [
    "Li, Ziyue  and\nChang, Yuan  and\nLe, Xiaoqiu"
  ],
  "year": "2024",
  "venue": "Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024)",
  "abstract": "Large Language Models (LLMs) have shown remarkable potential across various domains, yet their application in addressing complex scientific problems remains a formidable challenge. This paper presents a novel methodology to augment the problem-solving capabilities of LLMs by assigning them roles as domain-specific experts. By simulating a panel of experts, each LLM is tasked with delivering professional and cautious responses to scientific inquiries. Our approach involves querying multiple LLMs and assessing the consistency of their responses. High agreement among the LLMs suggests greater confidence in the proposed solution, whereas discrepancies prompt a collaborative discussion among the LLMs to reach a consensus. This method emulates real-world scientific problem-solving processes, fostering a more reliable and robust mechanism for LLMs to tackle scientific questions. Our experimental results show that assigning roles to multiple LLMs as domain-specific experts significantly improves their accuracy and reliability in solving scientific problems. This framework has the potential to advance the application of AI in scientific research, enhancing its effectiveness and trustworthiness.",
  "keywords": [
    "scientific questions",
    "the llms",
    "complex scientific problems",
    "scientific problems",
    "llm",
    "enhanced scientific problem",
    "scientific inquiries",
    "inquiries",
    "scientific research",
    "multiple llms",
    "discrepancies",
    "scientific",
    "llms",
    "-",
    "large language models llms"
  ],
  "url": "https://aclanthology.org/2024.sdp-1.23/",
  "provenance": {
    "collected_at": "2025-06-05 11:09:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}