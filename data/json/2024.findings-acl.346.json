{
  "id": "2024.findings-acl.346",
  "title": "Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models",
  "authors": [
    "Park, Jun-Hyung  and\nLee, Mingyu  and\nKim, Junho  and\nLee, SangKeun"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples are subsequently distilled into small language models to enhance their contextualization capability. Extensive evaluations show that COCONUT considerably improves commonsense reasoning performance across diverse benchmarks, models, and settings, exhibiting its flexibility and universality in generating contextualized commonsense knowledge. Notably,COCONUT consistently outperforms the state-of-the-art technique by an average of 5.8%.",
  "keywords": [
    "transformers",
    "knowledge",
    "language",
    "model",
    "evaluations",
    "language models",
    "a large language model",
    "we",
    "largelanguage models",
    "graph",
    "small language models",
    "state",
    "the-art",
    "high-quality contextualization",
    "diverse benchmarks models"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.346/",
  "provenance": {
    "collected_at": "2025-06-05 10:53:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}