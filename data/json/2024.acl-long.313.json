{
  "id": "2024.acl-long.313",
  "title": "PRP}-Graph: Pairwise Ranking Prompting to {LLM}s with Graph Aggregation for Effective Text Re-ranking",
  "authors": [
    "Luo, Jian  and\nChen, Xuanang  and\nHe, Ben  and\nSun, Le"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Pairwise Ranking Prompting (PRP) demonstrates impressive effectiveness in zero-shot document re-ranking tasks with large language models (LLMs). However, in the existing methods, PRP only outputs the same label for the comparison results of different confidence intervals without considering the uncertainty of pairwise comparison, which implies an underutilization of the generation probability information of LLMs. To bridge this gap, we propose PRP-Graph, a novel pairwise re-ranking approach, based on a refined scoring PRP unit that exploits the output probabilities of target labels to capture the degree of certainty of the comparison results. Specifically, the PRP-Graph consists of two stages, namely ranking graph construction and ranking graph aggregation. Extensive experiments conducted on the BEIR benchmark demonstrate the superiority of our approach over existing PRP-based methods. Comprehensive analysis reveals that the PRP-Graph displays strong robustness towards the initial ranking order and delivers exceptional re-ranking results with acceptable efficiency. Our code and data are available at https://github.com/Memelank/PRP-Graph.",
  "keywords": [
    "code",
    "efficiency",
    "we",
    "graph",
    "llm",
    "shot",
    "the generation probability information",
    "information",
    "zero-shot document",
    "analysis",
    "llms",
    "the output probabilities",
    "text",
    "language",
    "generation"
  ],
  "url": "https://aclanthology.org/2024.acl-long.313/",
  "provenance": {
    "collected_at": "2025-06-05 10:38:36",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}