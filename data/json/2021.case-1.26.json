{
  "id": "2021.case-1.26",
  "title": "CASE} 2021 Task 2 Socio-political Fine-grained Event Classification using Fine-tuned {R}o{BERT}a Document Embeddings",
  "authors": [
    "Kent, Samantha  and\nKrumbiegel, Theresa"
  ],
  "year": "2021",
  "venue": "Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)",
  "abstract": "We present our submission to Task 2 of the Socio-political and Crisis Events Detection Shared Task at the CASE @ ACL-IJCNLP 2021 workshop. The task at hand aims at the fine-grained classification of socio-political events. Our best model was a fine-tuned RoBERTa transformer model using document embeddings. The corpus consisted of a balanced selection of sub-events extracted from the ACLED event dataset. We achieved a macro F-score of 0.923 and a micro F-score of 0.932 during our preliminary experiments on a held-out test set. The same model also performed best on the shared task test data (weighted F-score = 0.83). To analyze the results we calculated the topic compactness of the commonly misclassified events and conducted an error analysis.",
  "keywords": [
    "embeddings",
    "transformer",
    "the fine-grained classification",
    "fine-tuned r o bert",
    "roberta",
    "bert",
    "model",
    "ijcnlp",
    "topic",
    "-",
    "document embeddings",
    "we",
    "a document embeddings",
    "the commonly misclassified events",
    "analysis"
  ],
  "url": "https://aclanthology.org/2021.case-1.26/",
  "provenance": {
    "collected_at": "2025-06-05 08:16:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}