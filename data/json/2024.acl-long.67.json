{
  "id": "2024.acl-long.67",
  "title": "B}eam{A}gg{R}: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering",
  "authors": [
    "Chu, Zheng  and\nChen, Jingchang  and\nChen, Qianglong  and\nWang, Haotian  and\nZhu, Kun  and\nDu, Xiyuan  and\nYu, Weijiang  and\nLiu, Ming  and\nQin, Bing"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities.Nevertheless, they still suffer from factual errors when tackling knowledge-intensive tasks.Retrieval-augmented reasoning represents a promising approach.However, significant challenges still persist, including inaccurate and insufficient retrieval for complex questions, as well as difficulty in integrating multi-source knowledge.To address this, we propose Beam Aggregation Reasoning (BeamAggR), a reasoning framework for knowledge-intensive multi-hop QA.BeamAggR explores and prioritizes promising answers at each hop of question.Concretely, we parse the complex questions into trees, which include atom and composite questions, followed by bottom-up reasoning.For atomic questions, the LLM conducts reasoning on multi-source knowledge to get answer candidates.For composite questions, the LLM combines beam candidates, explores multiple reasoning paths through probabilistic aggregation, and prioritizes the most promising trajectory.Extensive experiments on four open-domain multi-hop reasoning datasets show that our method significantly outperforms SOTA methods by 8.5%.Furthermore, our analysis reveals that BeamAggR elicits better knowledge collaboration and answer aggregation.",
  "keywords": [
    "question",
    "we",
    "llm",
    "retrieval-augmented reasoning",
    "answer",
    "retrieval",
    "inaccurate and insufficient retrieval",
    "strong reasoning capabilities",
    "analysis",
    "llms",
    "the llm",
    "large language models llms",
    "insufficient",
    "knowledge",
    "language"
  ],
  "url": "https://aclanthology.org/2024.acl-long.67/",
  "provenance": {
    "collected_at": "2025-06-05 10:35:12",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}