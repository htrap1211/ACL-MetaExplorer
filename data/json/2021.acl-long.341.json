{
  "id": "2021.acl-long.341",
  "title": "RADDLE}: An Evaluation Benchmark and Analysis Platform for Robust Task-oriented Dialog Systems",
  "authors": [
    "Peng, Baolin  and\nLi, Chunyuan  and\nZhang, Zhu  and\nZhu, Chenguang  and\nLi, Jinchao  and\nGao, Jianfeng"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "For task-oriented dialog systems to be maximally useful, it must be able to process conversations in a way that is (1) generalizable with a small number of training examples for new task domains, and (2) robust to user input in various styles, modalities, or domains. In pursuit of these goals, we introduce the RADDLE benchmark, a collection of corpora and tools for evaluating the performance of models across a diverse set of domains. By including tasks with limited training data, RADDLE is designed to favor and encourage models with a strong generalization ability. RADDLE also includes a diagnostic checklist that facilitates detailed robustness analysis in aspects such as language variations, speech errors, unseen entities, and out-of-domain utterances. We evaluate recent state-of-the-art systems based on pre-training and fine-tuning, and find that grounded pre-training on heterogeneous dialog corpora performs better than training a separate model per domain. Adversarial training is also proposed to improve model robustness against noisy inputs. Overall, existing models are less than satisfactory in robustness evaluation, which suggests opportunities for future improvement.",
  "keywords": [
    "robustness evaluation",
    "opportunities",
    "conversations",
    "generalizable",
    "we",
    "task-oriented dialog systems",
    "training",
    "it",
    "robust task-oriented dialog systems",
    "an evaluation benchmark",
    "analysis",
    "tuning",
    "pre-training and fine-tuning",
    "generalization",
    "fine"
  ],
  "url": "https://aclanthology.org/2021.acl-long.341/",
  "provenance": {
    "collected_at": "2025-06-05 08:03:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}