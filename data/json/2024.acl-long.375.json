{
  "id": "2024.acl-long.375",
  "title": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation",
  "authors": [
    "Yang, Yuan  and\nXiong, Siheng  and\nPayani, Ali  and\nShareghi, Ehsan  and\nFekri, Faramarz"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Advancements in logical reasoning, utilizing LLMs to convert natural language into logical symbolism, combined with the use of external theorem provers, have repositioned the symbolic approach as a central point of interest. The main challenge within this paradigm lies in the LLMsâ€™ capability to accurately translate natural language (NL) statements into first-order-logic (FOL) expressions. Although LLMs have shown notable success, there remains a gap in understanding the limitations and challenges they encounter in NL-FOL translation. This is primarily due to the absence of datasets and evaluation test beds at the required fine-grained level. We present MALLS, a dataset of 28K diverse and verified sentence-level NL-FOL pairs collected from GPT4. We utilize a combined strategy of FOL rule parsing, human annotation, and automatic filtering to ensure quality. We also present LogicLLaMA, a LLaMA2-7B/13B fine-tuned on MALLS for NL-FOL translation, which can be used standalone or to correct previously generated rules by GPT3.5 after being further fine-tuned via a novel reinforcement learning with human feedback (RLHF) framework. We benchmark a wide range of LLMs on MALLS and previous datasets, highlighting weaknesses in them in NL-FOL translation and demonstrating the advantages of MALLS. We also show that LogicLLaMA achieves GPT4-level performance and can generalize to other datasets. Project repo is available at https://github.com/gblackout/LogicLLaMA",
  "keywords": [
    "feedback",
    "the llms capability",
    "we",
    "first-order logic translation advancements",
    "gpt3",
    "translation",
    "natural",
    "rlhf",
    "verified",
    "learning",
    "natural language",
    "llms",
    "nl-fol translation",
    "a novel reinforcement learning",
    "previously generated rules"
  ],
  "url": "https://aclanthology.org/2024.acl-long.375/",
  "provenance": {
    "collected_at": "2025-06-05 10:39:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}