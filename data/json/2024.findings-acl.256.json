{
  "id": "2024.findings-acl.256",
  "title": "R}ul{E}: Knowledge Graph Reasoning with Rule Embedding",
  "authors": [
    "Tang, Xiaojuan  and\nZhu, Song-Chun  and\nLiang, Yitao  and\nZhang, Muhan"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Knowledge graph reasoning is an important problem for knowledge graphs. In this paper, we propose a novel and principled framework calledRulE(stands for Rule Embedding) to effectively leverage logical rules to enhance KG reasoning. Unlike knowledge graph embedding methods, RulE learns rule embeddings from existing triplets and first-order rules by jointly representingentities,relationsandlogical rulesin a unified embedding space. Based on the learned rule embeddings, a confidence score can be calculated for each rule, reflecting its consistency with the observed triplets. This allows us to perform logical rule inference in a soft way, thus alleviating the brittleness of logic. On the other hand, RulE injects prior logical rule information into the embedding space, enriching and regularizing the entity/relation embeddings. This makes KGE alone perform better too. RulE is conceptually simple and empirically effective. We conduct extensive experiments to verify each component of RulE.Results on multiple benchmarks reveal that our model outperforms the majority of existing embedding-based and rule-based approaches.",
  "keywords": [
    "we",
    "graph",
    "rule embeddings",
    "a unified embedding space",
    "kge",
    "unified",
    "information",
    "jointly representingentities relationsandlogical rulesin",
    "knowledge graphs",
    "the learned rule embeddings",
    "representingentities",
    "soft",
    "embeddings",
    "knowledge",
    "kg"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.256/",
  "provenance": {
    "collected_at": "2025-06-05 10:52:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}