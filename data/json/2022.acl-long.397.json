{
  "id": "2022.acl-long.397",
  "title": "Pre-training to Match for Unified Low-shot Relation Extraction",
  "authors": [
    "Liu, Fangchao  and\nLin, Hongyu  and\nHan, Xianpei  and\nCao, Boxi  and\nSun, Le"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Low-shot relation extraction (RE) aims to recognize novel relations with very few or even no samples, which is critical in real scenario application. Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem to be with similar target but require totally different underlying abilities. In this paper, we propose Multi-Choice Matching Networks to unify low-shot relation extraction. To fill in the gap between zero-shot and few-shot RE, we propose the triplet-paraphrase meta-training, which leverages triplet paraphrase to pre-train zero-shot label matching ability and uses meta-learning paradigm to learn few-shot instance summarizing ability. Experimental results on three different low-shot RE tasks show that the proposed method outperforms strong baselines by a large margin, and achieve the best performance on few-shot RE leaderboard.",
  "keywords": [
    "abilities",
    "few-shot",
    "extraction",
    "totally different underlying abilities",
    "unified",
    "zero-shot",
    "train",
    "we",
    "pre",
    "shot",
    "training",
    "novel relations",
    "multi",
    "the proposed method",
    "scenario"
  ],
  "url": "https://aclanthology.org/2022.acl-long.397/",
  "provenance": {
    "collected_at": "2025-06-05 08:29:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}