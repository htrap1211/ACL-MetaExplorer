{
  "id": "2024.bionlp-1.65",
  "title": "I}gnition{I}nnovators at ``Discharge Me!'': Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries",
  "authors": [
    "Tang, An Quang  and\nZhang, Xiuzhen  and\nDinh, Minh Ngoc"
  ],
  "year": "2024",
  "venue": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
  "abstract": "This paper presents our proposed approach to the Discharge Me! shared task, collocated with the 23th Workshop on Biomedical Natural Language Processing (BioNLP). In this work, we develop an LLM-based framework for solving the Discharge Summary Documentation (DSD) task, i.e., generating the two critical target sections ‘Brief Hospital Course’ and ‘Discharge Instructions’ in the discharge summary. By streamlining the recent instruction-finetuning process on LLMs, we explore several prompting strategies for optimally adapting LLMs to specific generation task of DSD. Experimental results show that providing a clear output structure, complimented by a set of comprehensive Chain-of-Thoughts (CoT) questions, effectively improves the model’s reasoning capability, and thereby, enhancing the structural correctness and faithfulness of clinical information in the generated text. Source code is available at: https://anonymous.4open.science/r/Discharge_LLM-A233",
  "keywords": [
    "code",
    "chain",
    "we",
    "several prompting strategies",
    "instruction",
    "natural",
    "cot",
    "discharge_llm",
    "information",
    "science",
    "e",
    "https anonymous 4open science",
    "llms",
    "an llm-based framework",
    "processing"
  ],
  "url": "https://aclanthology.org/2024.bionlp-1.65/",
  "provenance": {
    "collected_at": "2025-06-05 11:04:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}