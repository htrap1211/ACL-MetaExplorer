{
  "id": "2024.acl-long.47",
  "title": "IMBUE}: Improving Interpersonal Effectiveness through Simulation and Just-in-time Feedback with Human-Language Model Interaction",
  "authors": [
    "Lin, Inna  and\nSharma, Ashish  and\nRytting, Christopher  and\nMiner, Adam  and\nSuh, Jina  and\nAlthoff, Tim"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Navigating certain communication situations can be challenging due to individuals’ lack of skills and the interference of strong emotions. However, effective learning opportunities are rarely accessible. In this work, we conduct a human-centered study that uses language models to simulate bespoke communication training and provide just-in-time feedback to support the practice and learning of interpersonal effectiveness skills. We apply the interpersonal effectiveness framework from Dialectical Behavioral Therapy (DBT), DEAR MAN, which focuses on both conversational and emotional skills. We present IMBUE, an interactive training system that provides feedback 28% more similar to experts’ feedback, compared to that generated by GPT-4. IMBUE is the first to focus on communication skills and emotion management simultaneously, incorporate experts’ domain knowledge in providing feedback, and be grounded in psychology theory. Through a randomized trial of 86 participants, we find that IMBUE’s simulation-only variant significantly improves participants’ self-efficacy (up to 17%) and reduces negative emotions (up to 25%). With IMBUE’s additional just-in-time feedback, participants demonstrate 17% improvement in skill mastery, along with greater enhancements in self-efficacy (27% more) and reduction of negative emotions (16% more) compared to simulation-only. The improvement in skill mastery is the only measure that is transferred to new and more difficult situations; situation-specific training is necessary for improving self-efficacy and emotion reduction.",
  "keywords": [
    "however effective learning opportunities",
    "feedback",
    "opportunities",
    "man",
    "we",
    "training",
    "self",
    "human-language model interaction",
    "learning",
    "reduction",
    "language models",
    "gpt-4",
    "gpt-4 imbue",
    "work",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2024.acl-long.47/",
  "provenance": {
    "collected_at": "2025-06-05 10:34:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}