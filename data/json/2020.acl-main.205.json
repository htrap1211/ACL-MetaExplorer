{
  "id": "2020.acl-main.205",
  "title": "Efficient Strategies for Hierarchical Text Classification: External Knowledge and Auxiliary Tasks",
  "authors": [
    "Rivas Rojas, Kervy  and\nBustamante, Gina  and\nOncevay, Arturo  and\nSobrevilla Cabezudo, Marco Antonio"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "In hierarchical text classification, we perform a sequence of inference steps to predict the category of a document from top to bottom of a given class taxonomy. Most of the studies have focused on developing novels neural network architectures to deal with the hierarchical structure, but we prefer to look for efficient ways to strengthen a baseline model. We first define the task as a sequence-to-sequence problem. Afterwards, we propose an auxiliary synthetic task of bottom-up-classification. Then, from external dictionaries, we retrieve textual definitions for the classes of all the hierarchyâ€™s layers, and map them into the word vector space. We use the class-definition embeddings as an additional input to condition the prediction of the next layer and in an adapted beam search. Whereas the modified search did not provide large gains, the combination of the auxiliary task and the additional input of class-definitions significantly enhance the classification accuracy. With our efficient approaches, we outperform previous studies, using a drastically reduced number of parameters, in two well-known English datasets.",
  "keywords": [
    "our efficient approaches",
    "top",
    "the modified search",
    "efficient",
    "the hierarchical structure",
    "layer",
    "we",
    "the word vector space",
    "classification",
    "neural",
    "word",
    "sequence",
    "hierarchical text classification",
    "neural network",
    "vector"
  ],
  "url": "https://aclanthology.org/2020.acl-main.205/",
  "provenance": {
    "collected_at": "2025-06-05 07:44:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}