{
  "id": "2024.alvr-1.5",
  "title": "How and where does {CLIP} process negation?",
  "authors": [
    "Quantmeyer, Vincent  and\nMosteiro, Pablo  and\nGatt, Albert"
  ],
  "year": "2024",
  "venue": "Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)",
  "abstract": "Various benchmarks have been proposed to test linguistic understanding in pre-trained vision & language (VL) models. Here we build on the existence task from the VALSE benchmark (Parcalabescu et al., 2022) which we use to test modelsâ€™ understanding of negation, a particularly interesting issue for multimodal models. However, while such VL benchmarks are useful for measuring model performance, they do not reveal anything about the internal processes through which these models arrive at their outputs in such visio-linguistic tasks. We take inspiration from the growing literature on model interpretability to explain the behaviour of VL models on the understanding of negation. Specifically, we approach these questions through an in-depth analysis of the text encoder in CLIP (Radford et al., 2021), a highly influential VL model. We localise parts of the encoder that process negation and analyse the role of attention heads in this task. Our contributions are threefold. We demonstrate how methods from the language model interpretability literature (e.g., causal tracing) can be translated to multimodal models and tasks; we provide concrete insights into how CLIP processes negation on the VALSE existence task; and we highlight inherent limitations in the VALSE dataset as a benchmark for linguistic understanding.",
  "keywords": [
    "we",
    "the encoder",
    "analysis",
    "attention heads",
    "text",
    "the text encoder",
    "process",
    "language",
    "model",
    "encoder",
    "attention",
    "pre",
    "behaviour",
    "that process negation",
    "test"
  ],
  "url": "https://aclanthology.org/2024.alvr-1.5/",
  "provenance": {
    "collected_at": "2025-06-05 11:01:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}