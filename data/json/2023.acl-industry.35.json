{
  "id": "2023.acl-industry.35",
  "title": "Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems",
  "authors": [
    "Ahuja, Sarthak  and\nKachuee, Mohammad  and\nSheikholeslami, Fatemeh  and\nLiu, Weiqing  and\nDo, Jaeyoung"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
  "abstract": "Off-Policy reinforcement learning has been the driving force for the state-of-the-art conversational AIs leading to more natural human-agent interactions and improving the user satisfaction for goal-oriented agents. However, in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the broad spectrum of applications handled by such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics has been commonly used to address this problem. In this paper, we propose method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from a real-world conversational system and actual regression incidents. The proposed method is currently deployed in our production system to protect customers against broken experiences and enable long-term policy improvements.",
  "keywords": [
    "experience continuity",
    "precision",
    "goal-oriented agents",
    "high-precision samples",
    "we",
    "force",
    "natural",
    "it",
    "a real-world conversational system",
    "policies",
    "self",
    "learning",
    "experience",
    "broken experiences",
    "reinforcement"
  ],
  "url": "https://aclanthology.org/2023.acl-industry.35/",
  "provenance": {
    "collected_at": "2025-06-05 09:52:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}