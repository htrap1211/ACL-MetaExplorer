{
  "id": "2020.acl-main.540",
  "title": "Word-level Textual Adversarial Attacking as Combinatorial Optimization",
  "authors": [
    "Zang, Yuan  and\nQi, Fanchao  and\nYang, Chenghao  and\nLiu, Zhiyuan  and\nZhang, Meng  and\nLiu, Qun  and\nSun, Maosong"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Adversarial attacks are carried out to reveal the vulnerability of deep neural networks. Textual adversarial attacking is challenging because text is discrete and a small perturbation can bring significant change to the original input. Word-level attacking, which can be regarded as a combinatorial optimization problem, is a well-studied class of textual attack methods. However, existing word-level attack models are far from perfect, largely because unsuitable search space reduction methods and inefficient optimization algorithms are employed. In this paper, we propose a novel attack model, which incorporates the sememe-based word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately. We conduct exhaustive experiments to evaluate our attack model by attacking BiLSTM and BERT on three benchmark datasets. Experimental results demonstrate that our model consistently achieves much higher attack success rates and crafts more high-quality adversarial examples as compared to baseline methods. Also, further experiments show our model has higher transferability and can bring more robustness enhancement to victim models by adversarial training. All the code and data of this paper can be obtained onhttps://github.com/thunlp/SememePSO-Attack.",
  "keywords": [
    "deep",
    "code",
    "inefficient",
    "inefficient optimization algorithms",
    "we",
    "training",
    "neural",
    "bilstm",
    "word",
    "reduction",
    "a combinatorial optimization problem",
    "combinatorial optimization adversarial attacks",
    "bert",
    "text",
    "vulnerability"
  ],
  "url": "https://aclanthology.org/2020.acl-main.540/",
  "provenance": {
    "collected_at": "2025-06-05 07:49:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}