{
  "id": "2024.acl-long.306",
  "title": "Learning Geometry-Aware Representations for New Intent Discovery",
  "authors": [
    "Tang, Kai  and\nZhao, Junbo  and\nDing, Xiao  and\nWu, Runze  and\nFeng, Lei  and\nChen, Gang  and\nWang, Haobo"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "New intent discovery (NID) is an important problem for deploying practical dialogue systems, which trains intent classifiers on a semi-supervised corpus where unlabeled user utterances contain both known and novel intents. Most existing NID algorithms place hope on the sample similarity to cluster unlabeled corpus to known or new samples. Lacking supervision on new intents, we experimentally find the intent classifier fails to fully distinguish new intents since they tend to assemble into intertwined centers.To address this problem, we propose a novel GeoID framework that learns geometry-aware representations to maximally separate all intents. Specifically, we are motivated by the recent findings on Neural Collapse (NC) in classification tasks to derive optimal intent center structure. Meanwhile, we devise a dual pseudo-labeling strategy based on optimal transport assignments and semi-supervised clustering, ensuring proper utterances-to-center arrangement.Extensive results show that our GeoID method establishes a new state-of-the-art performance, achieving a +3.49% average accuracy improvement on three standardized benchmarking datasets. We also verify its usefulness in assisting large language models for improved in-context performance.",
  "keywords": [
    "classifier",
    "classifiers",
    "we",
    "dialogue",
    "classification",
    "practical dialogue systems",
    "classification tasks",
    "neural",
    "the intent classifier",
    "semi-supervised clustering",
    "accuracy",
    "language",
    "intent classifiers",
    "large language models",
    "clustering"
  ],
  "url": "https://aclanthology.org/2024.acl-long.306/",
  "provenance": {
    "collected_at": "2025-06-05 10:38:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}