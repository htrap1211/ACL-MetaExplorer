{
  "id": "P19-1265",
  "title": "Analysis of Automatic Annotation Suggestions for Hard Discourse-Level Tasks in Expert Domains",
  "authors": [
    "Schulz, Claudia  and\nMeyer, Christian M.  and\nKiesewetter, Jan  and\nSailer, Michael  and\nBauer, Elisabeth  and\nFischer, Martin R.  and\nFischer, Frank  and\nGurevych, Iryna"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Many complex discourse-level tasks can aid domain experts in their work but require costly expert annotations for data creation. To speed up and ease annotations, we investigate the viability of automatically generated annotation suggestions for such tasks. As an example, we choose a task that is particularly hard for both humans and machines: the segmentation and classification of epistemic activities in diagnostic reasoning texts. We create and publish a new dataset covering two domains and carefully analyse the suggested annotations. We find that suggestions have positive effects on annotation speed and performance, while not introducing noteworthy biases. Envisioning suggestion models that improve with newly annotated texts, we contrast methods for continuous model adjustment and suggest the most effective setup for suggestions in future expert tasks.",
  "keywords": [
    "we",
    "classification",
    "analysis",
    "activities",
    "noteworthy biases",
    "biases",
    "work",
    "model",
    "epistemic activities",
    "automatically generated annotation suggestions",
    "the viability",
    "data creation",
    "the suggested annotations",
    "both humans",
    "viability"
  ],
  "url": "https://aclanthology.org/P19-1265/",
  "provenance": {
    "collected_at": "2025-06-05 00:36:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}