{
  "id": "P19-2012",
  "title": "Long-Distance Dependencies Don{'}t Have to Be Long: Simplifying through Provably (Approximately) Optimal Permutations",
  "authors": [
    "Bommasani, Rishi"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
  "abstract": "Neural models at the sentence level often operate on the constituent words/tokens in a way that encodes the inductive bias of processing the input in a similar fashion to how humans do. However, there is no guarantee that the standard ordering of words is computationally efficient or optimal. To help mitigate this, we consider a dependency parse as a proxy for the inter-word dependencies in a sentence and simplify the sentence with respect to combinatorial objectives imposed on the sentence-parse pair. The associated optimization results in permuted sentences that are provably (approximately) optimal with respect to minimizing dependency parse lengths and that are demonstrably simpler. We evaluate our general-purpose permutations within a fine-tuning schema for the downstream task of subjectivity analysis. Our fine-tuned baselines reflect a new state of the art for the SUBJ dataset and the permutations we introduce lead to further improvements with a 2.0% increase in classification accuracy (absolute) and a 45% reduction in classification error (relative) over the previous state of the art.",
  "keywords": [
    "bias",
    "objectives",
    "efficient",
    "we",
    "classification",
    "neural",
    "combinatorial objectives",
    "a dependency parse",
    "dependencies",
    "dependency parse lengths",
    "word",
    "a fine-tuning schema",
    "analysis",
    "long-distance dependencies",
    "reduction"
  ],
  "url": "https://aclanthology.org/P19-2012/",
  "provenance": {
    "collected_at": "2025-06-05 00:48:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}