{
  "id": "2023.acl-long.192",
  "title": "Exploring Better Text Image Translation with Multimodal Codebook",
  "authors": [
    "Lan, Zhibin  and\nYu, Jiawei  and\nLi, Xiang  and\nZhang, Wen  and\nLuan, Jian  and\nWang, Bin  and\nHuang, Degen  and\nSu, Jinsong"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Text image translation (TIT) aims to translate the source texts embedded in the image to target translations, which has a wide range of applications and thus has important research value. However, current studies on TIT are confronted with two main bottlenecks: 1) this task lacks a publicly available TIT dataset, 2) dominant models are constructed in a cascaded manner, which tends to suffer from the error propagation of optical character recognition (OCR). In this work, we first annotate a Chinese-English TIT dataset named OCRMT30K, providing convenience for subsequent studies. Then, we propose a TIT model with a multimodal codebook, which is able to associate the image with relevant texts, providing useful supplementary information for translation. Moreover, we present a multi-stage training framework involving text machine translation, image-text alignment, and TIT tasks, which fully exploits additional bilingual texts, OCR dataset and our OCRMT30K dataset to train our model. Extensive experiments and in-depth analyses strongly demonstrate the effectiveness of our proposed model and training framework.",
  "keywords": [
    "better text image translation",
    "we",
    "current",
    "training",
    "translation",
    "ocrmt30k providing convenience",
    "convenience",
    "information",
    "a cascaded manner",
    "current studies",
    "manner",
    "text",
    "work",
    "alignment",
    "model"
  ],
  "url": "https://aclanthology.org/2023.acl-long.192/",
  "provenance": {
    "collected_at": "2025-06-05 09:38:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}