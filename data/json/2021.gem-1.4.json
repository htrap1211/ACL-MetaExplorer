{
  "id": "2021.gem-1.4",
  "title": "Shades of {BLEU}, Flavours of Success: The Case of {M}ulti{WOZ",
  "authors": [
    "Nekvinda, Tom{\\'a}{\\v{s}}  and\nDu{\\v{s}}ek, Ond{\\v{r}}ej"
  ],
  "year": "2021",
  "venue": "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
  "abstract": "The MultiWOZ dataset (Budzianowski et al.,2018) is frequently used for benchmarkingcontext-to-response abilities of task-orienteddialogue systems. In this work, we identifyinconsistencies in data preprocessing and re-porting of three corpus-based metrics used onthis dataset, i.e., BLEU score and Inform &Success rates. We point out a few problemsof the MultiWOZ benchmark such as unsat-isfactory preprocessing, insufficient or under-specified evaluation metrics, or rigid database. We re-evaluate 7 end-to-end and 6 policy opti-mization models in as-fair-as-possible setups,and we show that their reported scores cannotbe directly compared. To facilitate compari-son of future systems, we release our stand-alone standardized evaluation scripts. We alsogive basic recommendations for corpus-basedbenchmarking in future works.",
  "keywords": [
    "work",
    "opti",
    "abilities",
    "end",
    "i",
    "al",
    "metrics",
    "task-orienteddialogue systems",
    "three corpus-based metrics",
    "bleu",
    "-",
    "mization",
    "orienteddialogue",
    "we",
    "evaluation"
  ],
  "url": "https://aclanthology.org/2021.gem-1.4/",
  "provenance": {
    "collected_at": "2025-06-05 08:17:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}