{
  "id": "2023.acl-long.232",
  "title": "Causal-Debias: Unifying Debiasing in Pretrained Language Models and Fine-tuning via Causal Invariant Learning",
  "authors": [
    "Zhou, Fan  and\nMao, Yuzhou  and\nYu, Liu  and\nYang, Yi  and\nZhong, Ting"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Demographic biases and social stereotypes are common in pretrained language models (PLMs), and a burgeoning body of literature focuses on removing the unwanted stereotypical associations from PLMs. However, when fine-tuning these bias-mitigated PLMs in downstream natural language processing (NLP) applications, such as sentiment classification, the unwanted stereotypical associations resurface or even get amplified. Since pretrain&fine-tune is a major paradigm in NLP applications, separating the debiasing procedure of PLMs from fine-tuning would eventually harm the actual downstream utility. In this paper, we propose a unified debiasing framework Causal-Debias to remove unwanted stereotypical associations in PLMs during fine-tuning. Specifically, CausalDebias mitigates bias from a causal invariant perspective by leveraging the specific downstream task to identify bias-relevant and labelrelevant factors. We propose that bias-relevant factors are non-causal as they should have little impact on downstream tasks, while labelrelevant factors are causal. We perform interventions on non-causal factors in different demographic groups and design an invariant risk minimization loss to mitigate bias while maintaining task performance. Experimental results on three downstream tasks show that our proposed method can remarkably reduce unwanted stereotypical associations after PLMs are finetuned, while simultaneously minimizing the impact on PLMs and downstream applications.",
  "keywords": [
    "bias",
    "these bias-mitigated plms",
    "the debiasing procedure",
    "we",
    "bias-relevant and labelrelevant factors",
    "classification",
    "fine-tuning",
    "natural",
    "unified",
    "loss",
    "pretrained language models plms",
    "nlp applications",
    "bias-relevant factors",
    "tuning",
    "processing"
  ],
  "url": "https://aclanthology.org/2023.acl-long.232/",
  "provenance": {
    "collected_at": "2025-06-05 09:38:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}