{
  "id": "2024.findings-acl.398",
  "title": "Towards Uncertainty-Aware Language Agent",
  "authors": [
    "Han, Jiuzhou  and\nBuntine, Wray  and\nShareghi, Ehsan"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrate that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens). Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscore the unreliability of verbalised confidence of LLMs as a proxy for uncertainty.",
  "keywords": [
    "we",
    "llm",
    "various llm sizes",
    "strategyqa",
    "hotpotqa",
    "core",
    "llms",
    "tuning",
    "fine",
    "agent fine-tuning",
    "language",
    "large language models",
    "great",
    "notion",
    "interaction"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.398/",
  "provenance": {
    "collected_at": "2025-06-05 10:54:02",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}