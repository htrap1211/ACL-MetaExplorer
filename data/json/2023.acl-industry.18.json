{
  "id": "2023.acl-industry.18",
  "title": "Tab-Cleaner: Weakly Supervised Tabular Data Cleaning via Pre-training for {E}-commerce Catalog",
  "authors": [
    "Cheng, Kewei  and\nLi, Xian  and\nWang, Zhengyang  and\nZhang, Chenwei  and\nHuang, Binxuan  and\nXu, Yifan Ethan  and\nDong, Xin Luna  and\nSun, Yizhou"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
  "abstract": "Product catalogs, conceptually in the form of text-rich tables, are self-reported by individual retailers and thus inevitably contain noisy facts. Verifying such textual attributes in product catalogs is essential to improve their reliability. However, popular methods for processing free-text content, such as pre-trained language models, are not particularly effective on structured tabular data since they are typically trained on free-form natural language texts. In this paper, we present Tab-Cleaner, a model designed to handle error detection over text-rich tabular data following a pre-training / fine-tuning paradigm. We train Tab-Cleaner on a real-world Amazon Product Catalog table w.r.t millions of products and show improvements over state-of-the-art methods by 16\\% on PR AUC over attribute applicability classification task and by 11\\% on PR AUC over attribute value validation task.",
  "keywords": [
    "validation",
    "attribute applicability classification task",
    "form",
    "we",
    "training",
    "classification",
    "pre-trained language models",
    "natural",
    "self",
    "rich",
    "tab-cleaner",
    "tuning",
    "pr auc",
    "text",
    "-"
  ],
  "url": "https://aclanthology.org/2023.acl-industry.18/",
  "provenance": {
    "collected_at": "2025-06-05 09:52:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}