{
  "id": "2021.acl-long.242",
  "title": "O}nline {L}earning Meets {M}achine {T}ranslation Evaluation: Finding the Best Systems with the Least Human Effort",
  "authors": [
    "Mendon{\\c{c}}a, V{\\^a}nia  and\nRei, Ricardo  and\nCoheur, Luisa  and\nSardinha, Alberto  and\nSantos, Ana L{\\'u}cia"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "In Machine Translation, assessing the quality of a large amount of automatic translations can be challenging. Automatic metrics are not reliable when it comes to high performing systems. In addition, resorting to human evaluators can be expensive, especially when evaluating multiple systems. To overcome the latter challenge, we propose a novel application of online learning that, given an ensemble of Machine Translation systems, dynamically converges to the best systems, by taking advantage of the human feedback available. Our experiments on WMTâ€™19 datasets show that our online approach quickly converges to the top-3 ranked systems for the language pairs considered, despite the lack of human feedback for many translations.",
  "keywords": [
    "ensemble",
    "automatic translations",
    "language",
    "feedback",
    "machine",
    "it",
    "human",
    "metrics",
    "machine translation",
    "machine translation systems",
    "achine t ranslation evaluation",
    "we",
    "the human feedback",
    "learning",
    "evaluation"
  ],
  "url": "https://aclanthology.org/2021.acl-long.242/",
  "provenance": {
    "collected_at": "2025-06-05 08:02:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}