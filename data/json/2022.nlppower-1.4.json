{
  "id": "2022.nlppower-1.4",
  "title": "Why only Micro-F1? Class Weighting of Measures for Relation Classification",
  "authors": [
    "Harbecke, David  and\nChen, Yuxuan  and\nHennig, Leonhard  and\nAlt, Christoph"
  ],
  "year": "2022",
  "venue": "Proceedings of NLP Power! The First Workshop on Efficient Benchmarking in NLP",
  "abstract": "Relation classification models are conventionally evaluated using only a single measure, e.g., micro-F1, macro-F1 or AUC. In this work, we analyze weighting schemes, such as micro and macro, for imbalanced datasets. We introduce a framework for weighting schemes, where existing schemes are extremes, and two new intermediate schemes. We show that reporting results of different weighting schemes better highlights strengths and weaknesses of a model.",
  "keywords": [
    "work",
    "micro-f1 macro-",
    "model",
    "class",
    "auc",
    "we",
    "only micro-f1 class weighting",
    "classification",
    "existing",
    "this work",
    "measures",
    "new",
    "schemes",
    "relation",
    "existing schemes"
  ],
  "url": "https://aclanthology.org/2022.nlppower-1.4/",
  "provenance": {
    "collected_at": "2025-06-05 08:45:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}