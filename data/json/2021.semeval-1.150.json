{
  "id": "2021.semeval-1.150",
  "title": "M}in{D} at {S}em{E}val-2021 Task 6: Propaganda Detection using Transfer Learning and Multimodal Fusion",
  "authors": [
    "Tian, Junfeng  and\nGui, Min  and\nLi, Chenliang  and\nYan, Ming  and\nXiao, Wenming"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "We describe our systems of subtask1 and subtask3 for SemEval-2021 Task 6 on Detection of Persuasion Techniques in Texts and Images. The purpose of subtask1 is to identify propaganda techniques given textual content, and the goal of subtask3 is to detect them given both textual and visual content. For subtask1, we investigate transfer learning based on pre-trained language models (PLMs) such as BERT, RoBERTa to solve data sparsity problems. For subtask3, we extract heterogeneous visual representations (i.e., face features, OCR features, and multimodal representations) and explore various multimodal fusion strategies to combine the textual and visual representations. The official evaluation shows our ensemble model ranks 1st for subtask1 and 2nd for subtask3.",
  "keywords": [
    "ensemble",
    "roberta",
    "i",
    "the official evaluation",
    "language",
    "bert",
    "model",
    "various multimodal fusion strategies",
    "our ensemble model",
    "strategies",
    "bert roberta",
    "pre-trained language models plms",
    "we",
    "learning",
    "d"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.150/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:45",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}