{
  "id": "2023.semeval-1.120",
  "title": "G}unadarma{XBRIN} at {S}em{E}val-2023 Task 12: Utilization of {SVM} and {A}fri{BERT}a for Monolingual, Multilingual, and Zero-shot Sentiment Analysis in {A}frican Languages",
  "authors": [
    "Arlim, Novitasari  and\nRiyanto, Slamet  and\nRodiah, Rodiah  and\nSiagian, Al Hafiz Akbar Maulana"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "This paper describes our participation in Task 12: AfriSenti-SemEval 2023, i.e., track 12 of subtask A, track 16 of subtask B, and track 18 of subtask C. To deal with these three tracks, we utilize Support Vector Machine (SVM) + One vs Rest, SVM + One vs Rest with SMOTE, and AfriBERTa-large models. In particular, our SVM + One vs Rest with SMOTE model could obtain the highest weighted F1-Score for tracks 16 and 18 in the evaluation phase, that is, 65.14% and 33.49%, respectively. Meanwhile, our SVM + One vs Rest model could perform better than other models for track 12 in the evaluation phase.",
  "keywords": [
    "the highest weighted f1-score",
    "sentiment",
    "afriberta-large models",
    "rest",
    "svm",
    "vector",
    "i",
    "support",
    "bert",
    "model",
    "machine",
    "the evaluation phase",
    "-",
    "we",
    "support vector machine"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.120/",
  "provenance": {
    "collected_at": "2025-06-05 10:28:15",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}