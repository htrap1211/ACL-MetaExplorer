{
  "id": "W18-3016",
  "title": "W}ord{N}et Embeddings",
  "authors": [
    "Saedi, Chakaveh  and\nBranco, Ant{\\'o}nio  and\nAnt{\\'o}nio Rodrigues, Jo{\\~a}o  and\nSilva, Jo{\\~a}o"
  ],
  "year": "2018",
  "venue": "Proceedings of the Third Workshop on Representation Learning for {NLP}",
  "abstract": "Semantic networks and semantic spaces have been two prominent approaches to represent lexical semantics. While a unified account of the lexical meaning relies on one being able to convert between these representations, in both directions, the conversion direction from semantic networks into semantic spaces started to attract more attention recently. In this paper we present a methodology for this conversion and assess it with a case study. When it is applied over WordNet, the performance of the resulting embeddings in a mainstream semantic similarity task is very good, substantially superior to the performance of word embeddings based on very large collections of texts like word2vec.",
  "keywords": [
    "embeddings",
    "a unified account",
    "et",
    "semantics",
    "it",
    "semantic networks",
    "unified",
    "wordnet",
    "the resulting embeddings",
    "we",
    "semantic",
    "attention",
    "word",
    "ord",
    "more attention"
  ],
  "url": "https://aclanthology.org/W18-3016/",
  "provenance": {
    "collected_at": "2025-06-05 00:25:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}