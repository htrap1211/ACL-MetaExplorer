{
  "id": "2020.acl-main.625",
  "title": "Language to Network: Conditional Parameter Adaptation with Natural Language Descriptions",
  "authors": [
    "Jin, Tian  and\nLiu, Zhun  and\nYan, Shengjia  and\nEichenberger, Alexandre  and\nMorency, Louis-Philippe"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Transfer learning using ImageNet pre-trained models has been the de facto approach in a wide range of computer vision tasks. However, fine-tuning still requires task-specific training data. In this paper, we proposeN3(NeuralNetworks fromNatural Language) - a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model.N3leverages language descriptions to generate parameter adaptations as well as a new task-specific classification layer for a pre-trained neural network, effectively “fine-tuning” the network for a new task using only language descriptions as input. To the best of our knowledge,N3is the first method to synthesize entire neural networks from natural language. Experimental results show thatN3can out-perform previous natural-language based zero-shot learning methods across 4 different zero-shot image classification benchmarks. We also demonstrate a simple method to help identify keywords in language descriptions leveraged byN3when synthesizing model parameters.",
  "keywords": [
    "task-specific neural networks",
    "layer",
    "a generic pre-trained model",
    "we",
    "parameter",
    "shot",
    "training",
    "classification",
    "fine-tuning",
    "neural",
    "natural",
    "learning",
    "transfer",
    "tuning",
    "a pre-trained neural network"
  ],
  "url": "https://aclanthology.org/2020.acl-main.625/",
  "provenance": {
    "collected_at": "2025-06-05 07:50:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}