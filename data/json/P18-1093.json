{
  "id": "P18-1093",
  "title": "Reasoning with Sarcasm by Reading In-Between",
  "authors": [
    "Tay, Yi  and\nLuu, Anh Tuan  and\nHui, Siu Cheung  and\nSu, Jian"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Sarcasm is a sophisticated speech act which commonly manifests on social communities such as Twitter and Reddit. The prevalence of sarcasm on the social web is highly disruptive to opinion mining systems due to not only its tendency of polarity flipping but also usage of figurative language. Sarcasm commonly manifests with a contrastive theme either between positive-negative sentiments or between literal-figurative scenarios. In this paper, we revisit the notion of modeling contrast in order to reason with sarcasm. More specifically, we propose an attention-based neural model that looks in-between instead of across, enabling it to explicitly model contrast and incongruity. We conduct extensive experiments on six benchmark datasets from Twitter, Reddit and the Internet Argument Corpus. Our proposed model not only achieves state-of-the-art performance on all datasets but also enjoys improved interpretability.",
  "keywords": [
    "an attention-based neural model",
    "language",
    "neural",
    "social communities",
    "model",
    "it",
    "communities",
    "we",
    "attention",
    "act",
    "mining",
    "incongruity",
    "that",
    "speech",
    "twitter reddit"
  ],
  "url": "https://aclanthology.org/P18-1093/",
  "provenance": {
    "collected_at": "2025-06-05 00:11:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}