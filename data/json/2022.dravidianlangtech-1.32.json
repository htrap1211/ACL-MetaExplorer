{
  "id": "2022.dravidianlangtech-1.32",
  "title": "DLRG}@{D}ravidian{L}ang{T}ech-{ACL}2022: Abusive Comment Detection in {T}amil using Multilingual Transformer Models",
  "authors": [
    "Rajalakshmi, Ratnavel  and\nDuraphe, Ankita  and\nShibani, Antonette"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages",
  "abstract": "Online Social Network has let people to connect and interact with each other. It does, however, also provide a platform for online abusers to propagate abusive content. The vast majority of abusive remarks are written in a multilingual style, which allows them to easily slip past internet inspection. This paper presents a system developed for the Shared Task on Abusive Comment Detection (Misogyny, Misandry, Homophobia, Transphobic, Xenophobia, CounterSpeech, Hope Speech) in Tamil DravidianLangTech@ACL 2022 to detect the abusive category of each comment. We approach the task with three methodologies - Machine Learning, Deep Learning and Transformer-based modeling, for two sets of data - Tamil and Tamil+English language dataset. The dataset used in our system can be accessed from the competition on CodaLab. For Machine Learning, eight algorithms were implemented, among which Random Forest gave the best result with Tamil+English dataset, with a weighted average F1-score of 0.78. For Deep Learning, Bi-Directional LSTM gave best result with pre-trained word embeddings. In Transformer-based modeling, we used IndicBERT and mBERT with fine-tuning, among which mBERT gave the best result for Tamil dataset with a weighted average F1-score of 0.7.",
  "keywords": [
    "deep",
    "mbert",
    "we",
    "lstm",
    "multilingual transformer models",
    "fine-tuning",
    "transformer-based modeling",
    "it",
    "bi-directional lstm",
    "random forest",
    "word",
    "learning",
    "ang",
    "three methodologies - machine",
    "tuning"
  ],
  "url": "https://aclanthology.org/2022.dravidianlangtech-1.32/",
  "provenance": {
    "collected_at": "2025-06-05 08:41:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}