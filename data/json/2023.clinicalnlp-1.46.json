{
  "id": "2023.clinicalnlp-1.46",
  "title": "Pre-trained language models in {S}panish for health insurance coverage",
  "authors": [
    "Aracena, Claudio  and\nRodr{\\'i}guez, Nicol{\\'a}s  and\nRocco, Victor  and\nDunstan, Jocelyn"
  ],
  "year": "2023",
  "venue": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
  "abstract": "The field of clinical natural language processing (NLP) can extract useful information from clinical text. Since 2017, the NLP field has shifted towards using pre-trained language models (PLMs), improving performance in several tasks. Most of the research in this field has focused on English text, but there are some available PLMs in Spanish. In this work, we use clinical PLMs to analyze text from admission and medical reports in Spanish for an insurance and health provider to give a probability of no coverage in a labor insurance process. Our results show that fine-tuning a PLM pre-trained with the providerâ€™s data leads to better results, but this process is time-consuming and computationally expensive. At least for this task, fine-tuning publicly available clinical PLM leads to comparable results to a custom PLM, but in less time and with fewer resources. Analyzing large volumes of insurance requests is burdensome for employers, and models can ease this task by pre-classifying reports that are likely not to have coverage. Our approach of entirely using clinical-related text improves the current models while reinforcing the idea of clinical support systems that simplify human labor but do not replace it. To our knowledge, the clinical corpus collected for this study is the largest one reported for the Spanish language.",
  "keywords": [
    "the nlp field",
    "support",
    "field",
    "we",
    "current",
    "pre-trained language models",
    "the field",
    "natural",
    "it",
    "information",
    "pre-trained language models plms",
    "processing",
    "text",
    "fine",
    "work"
  ],
  "url": "https://aclanthology.org/2023.clinicalnlp-1.46/",
  "provenance": {
    "collected_at": "2025-06-05 10:23:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}