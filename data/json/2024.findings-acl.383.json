{
  "id": "2024.findings-acl.383",
  "title": "Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models",
  "authors": [
    "Amayuelas, Alfonso  and\nWong, Kyle  and\nPan, Liangming  and\nChen, Wenhu  and\nWang, William Yang"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "This paper investigates the capabilities of Large Language Models (LLMs) in understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a new dataset with Known-Unknown Questions (KUQ) and establish a categorization framework to clarify the origins of uncertainty in such queries. Subsequently, we examine the performance of open-source LLMs, fine-tuned using this dataset, in distinguishing between known and unknown queries within open-ended question-answering scenarios. The fine-tuned models demonstrated a significant improvement, achieving a considerable increase in F1-score relative to their pre-fine-tuning state. Through a comprehensive analysis, we reveal insights into the modelsâ€™ improved uncertainty articulation and their consequent efficacy in multi-agent debates. These findings help us understand how LLMs can be trained to identify and express uncertainty, improving our knowledge of how they understand and express complex or unclear information.",
  "keywords": [
    "such queries",
    "question",
    "we",
    "queries",
    "information",
    "the capabilities",
    "their pre-fine-tuning state",
    "analysis",
    "llms",
    "known and unknown queries",
    "fine",
    "knowledge",
    "language",
    "large language models",
    "open-source llms"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.383/",
  "provenance": {
    "collected_at": "2025-06-05 10:53:50",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}