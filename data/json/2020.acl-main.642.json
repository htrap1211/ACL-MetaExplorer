{
  "id": "2020.acl-main.642",
  "title": "Aligned Dual Channel Graph Convolutional Network for Visual Question Answering",
  "authors": [
    "Huang, Qingbao  and\nWei, Jielong  and\nCai, Yi  and\nZheng, Changmeng  and\nChen, Junying  and\nLeung, Ho-fung  and\nLi, Qing"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Visual question answering aims to answer the natural language question about a given image. Existing graph-based methods only focus on the relations between objects in an image and neglect the importance of the syntactic dependency relations between words in a question. To simultaneously capture the relations between objects in an image and the syntactic dependency relations between words in a question, we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages. The DC-GCN model consists of three parts: an I-GCN module to capture the relations between objects in an image, a Q-GCN module to capture the syntactic dependency relations between words in a question, and an attention alignment module to align image representations and question representations. Experimental results show that our model achieves comparable performance with the state-of-the-art approaches.",
  "keywords": [
    "alignment",
    "language",
    "natural",
    "model",
    "-",
    "question",
    "dependency",
    "network",
    "attention",
    "we",
    "an attention alignment module",
    "visual",
    "graph",
    "the syntactic dependency relations",
    "convolutional"
  ],
  "url": "https://aclanthology.org/2020.acl-main.642/",
  "provenance": {
    "collected_at": "2025-06-05 07:50:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}