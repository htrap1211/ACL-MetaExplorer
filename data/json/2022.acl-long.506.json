{
  "id": "2022.acl-long.506",
  "title": "Evaluating Factuality in Text Simplification",
  "authors": [
    "Devaraj, Ashwin  and\nSheffield, William  and\nWallace, Byron  and\nLi, Junyi Jessy"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Automated simplification models aim to make input texts more readable. Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader. However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information. Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all. The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated. We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs. We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models.",
  "keywords": [
    "audience",
    "existing evaluation metrics",
    "summarization",
    "we",
    "heightened attention",
    "the factual accuracy",
    "information",
    "automatically simplified texts",
    "lay",
    "factual accuracy",
    "text",
    "metrics",
    "summarization models",
    "accuracy",
    "a wider audience"
  ],
  "url": "https://aclanthology.org/2022.acl-long.506/",
  "provenance": {
    "collected_at": "2025-06-05 08:31:06",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}