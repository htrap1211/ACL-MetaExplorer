{
  "id": "2022.ltedi-1.18",
  "title": "bitsa{\\_}nlp@{LT}-{EDI}-{ACL}2022: Leveraging Pretrained Language Models for Detecting Homophobia and Transphobia in Social Media Comments",
  "authors": [
    "Bhandari, Vitthal  and\nGoyal, Poonam"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",
  "abstract": "Online social networks are ubiquitous and user-friendly. Nevertheless, it is vital to detect and moderate offensive content to maintain decency and empathy. However, mining social media texts is a complex task since users donâ€™t adhere to any fixed patterns. Comments can be written in any combination of languages and many of them may be low-resource. In this paper, we present our system for the LT-EDI shared task on detecting homophobia and transphobia in social media comments. We experiment with a number of monolingual and multilingual transformer based models such as mBERT along with a data augmentation technique for tackling class imbalance. Such pretrained large models have recently shown tremendous success on a variety of benchmark tasks in natural language processing. We observe their performance on a carefully annotated, real life dataset of YouTube comments in English as well as Tamil. Our submission achieved ranks 9, 6 and 3 with a macro-averaged F1-score of 0.42, 0.64 and 0.58 in the English, Tamil and Tamil-English subtasks respectively. The code for the system has been open sourced.",
  "keywords": [
    "variety",
    "code",
    "mbert",
    "we",
    "friendly",
    "natural",
    "it",
    "a variety",
    "natural language processing",
    "a macro-averaged f1-score",
    "processing",
    "transformer",
    "language",
    "nlp",
    "class"
  ],
  "url": "https://aclanthology.org/2022.ltedi-1.18/",
  "provenance": {
    "collected_at": "2025-06-05 08:44:35",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}