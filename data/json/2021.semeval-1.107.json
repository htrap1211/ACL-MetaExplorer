{
  "id": "2021.semeval-1.107",
  "title": "Noobs at {S}emeval-2021 Task 4: Masked Language Modeling for abstract answer prediction",
  "authors": [
    "Shukla, Shikhar  and\nSarthak, Sarthak  and\nArya, Karm Veer"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "This paper presents the system developed by our team for Semeval 2021 Task 4: Reading Comprehension of Abstract Meaning. The aim of the task was to benchmark the NLP techniques in understanding the abstract concepts present in a passage, and then predict the missing word in a human written summary of the passage. We trained a Roberta-Large model trained with a masked language modeling objective. In cases where this model failed to predict one of the available options, another Roberta-Large model trained as a binary classifier was used to predict correct and incorrect options. We used passage summary generated by Pegasus model and question as inputs. Our best solution was an ensemble of these 2 systems. We achieved an accuracy of 86.22% on subtask 1 and 87.10% on subtask 2.",
  "keywords": [
    "ensemble",
    "the nlp techniques",
    "another roberta-large model",
    "roberta",
    "answer",
    "language",
    "nlp",
    "classifier",
    "model",
    "human",
    "objective",
    "a binary classifier",
    "modeling",
    "a roberta-large model",
    "an accuracy"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.107/",
  "provenance": {
    "collected_at": "2025-06-05 08:21:12",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}