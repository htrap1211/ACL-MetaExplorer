{
  "id": "2022.findings-acl.230",
  "title": "Revisiting the Effects of Leakage on Dependency Parsing",
  "authors": [
    "Krasner, Nathaniel  and\nWanner, Miriam  and\nAnastasopoulos, Antonios"
  ],
  "year": "2022",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
  "abstract": "Recent work by SÃ¸gaard (2020) showed that, treebank size aside, overlap between training and test graphs (termedleakage) explains more of the observed variation in dependency parsing performance than other explanations. In this work we revisit this claim, testing it on more models and languages. We find that it only holds for zero-shot cross-lingual settings. We then propose a more fine-grained measure of such leakage which, unlike the original measure, not only explains but also correlates with observed performance variation. Code and data are available here:https://github.com/miriamwanner/reu-nlp-project",
  "keywords": [
    "work",
    "cross",
    "code",
    "nlp",
    "it",
    "miriamwanner",
    "github com miriamwanner",
    "dependency parsing performance",
    "dependency",
    "we",
    "training",
    "zero-shot cross-lingual settings",
    "this work",
    "original",
    "overlap"
  ],
  "url": "https://aclanthology.org/2022.findings-acl.230/",
  "provenance": {
    "collected_at": "2025-06-05 08:37:57",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}