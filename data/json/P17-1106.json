{
  "id": "P17-1106",
  "title": "Visualizing and Understanding Neural Machine Translation",
  "authors": [
    "Ding, Yanzhuo  and\nLiu, Yang  and\nLuan, Huanbo  and\nSun, Maosong"
  ],
  "year": "2017",
  "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "While neural machine translation (NMT) has made remarkable progress in recent years, it is hard to interpret its internal workings due to the continuous representations and non-linearity of neural networks. In this work, we propose to use layer-wise relevance propagation (LRP) to compute the contribution of each contextual word to arbitrary hidden states in the attention-based encoder-decoder framework. We show that visualization with LRP helps to interpret the internal workings of NMT and analyze translation errors.",
  "keywords": [
    "work",
    "translation errors",
    "neural",
    "neural networks",
    "machine",
    "it",
    "neural machine translation",
    "-",
    "encoder",
    "decoder",
    "propagation",
    "the attention-based encoder-decoder framework",
    "layer",
    "attention",
    "we"
  ],
  "url": "https://aclanthology.org/P17-1106/",
  "provenance": {
    "collected_at": "2025-06-04 23:59:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}