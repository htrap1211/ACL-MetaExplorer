{
  "id": "2022.acl-long.57",
  "title": "DEAM}: Dialogue Coherence Evaluation using {AMR}-based Semantic Manipulations",
  "authors": [
    "Ghazarian, Sarik  and\nWen, Nuan  and\nGalstyan, Aram  and\nPeng, Nanyun"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Automatic evaluation metrics are essential for the rapid development of open-domain dialogue systems as they facilitate hyper-parameter tuning and comparison between models. Although recently proposed trainable conversation-level metrics have shown encouraging results, the quality of the metrics is strongly dependent on the quality of training data. Prior works mainly resort to heuristic text-level manipulations (e.g. utterances shuffling) to bootstrap incoherent conversations (negative examples) from coherent dialogues (positive examples). Such approaches are insufficient to appropriately reflect the incoherence that occurs in interactions between advanced dialogue models and humans. To tackle this problem, we propose DEAM, a Dialogue coherence Evaluation metric that relies on Abstract Meaning Representation (AMR) to apply semantic-level Manipulations for incoherent (negative) data generation. AMRs naturally facilitate the injection of various types of incoherence sources, such as coreference inconsistency, irrelevancy, contradictions, and decrease engagement, at the semantic level, thus resulting in more natural incoherent samples. Our experiments show that DEAM achieves higher correlations with human judgments compared to baseline methods on several dialog datasets by significant margins. We also show that DEAM can distinguish between coherent and incoherent dialogues generated by baseline manipulations, whereas those baseline models cannot detect incoherent examples generated by DEAM. Our results demonstrate the potential of AMR-based semantic manipulations for natural negative example generation.",
  "keywords": [
    "semantic-level manipulations",
    "conversations",
    "amr-based semantic manipulations",
    "semantic",
    "we",
    "dialogue",
    "parameter",
    "training",
    "advanced dialogue models",
    "hyper",
    "natural",
    "the metrics",
    "incoherent conversations",
    "natural negative example generation",
    "tuning"
  ],
  "url": "https://aclanthology.org/2022.acl-long.57/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:04",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}