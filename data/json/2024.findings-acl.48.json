{
  "id": "2024.findings-acl.48",
  "title": "Conversational Question Answering with Language Models Generated Reformulations over Knowledge Graph",
  "authors": [
    "Liu, Lihui  and\nHill, Blaine  and\nDu, Boxin  and\nWang, Fei  and\nTong, Hanghang"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Conversational question answering (ConvQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to understand given a conversation history, but hard for a machine to interpret, which can degrade ConvQA performance. To address this problem, we propose a reinforcement learning (RL) based model, CoRnNet, which utilizes question reformulations generated by large language models (LLMs) to improve ConvQA performance. CoRnNet adopts a teacher-student architecture where a teacher model learns question representations using human writing reformulations, and a student model to mimic the teacher modelâ€™s output via reformulations generated by LLMs. The learned question representation is then used by a RL model to locate the correct answer in a KG. Extensive experimental results show that CoRnNet outperforms state-of-the-art ConvQA models.",
  "keywords": [
    "knowledge graph conversational question",
    "knowledge",
    "reinforcement",
    "answer",
    "language",
    "natural",
    "convqa performance",
    "model",
    "machine",
    "human",
    "convqa",
    "large language models",
    "language models",
    "a reinforcement learning",
    "question"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.48/",
  "provenance": {
    "collected_at": "2025-06-05 10:49:15",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}