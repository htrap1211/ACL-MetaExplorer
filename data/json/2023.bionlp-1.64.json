{
  "id": "2023.bionlp-1.64",
  "title": "IKM}{\\_}{L}ab at {B}io{L}ay{S}umm Task 1: Longformer-based Prompt Tuning for Biomedical Lay Summary Generation",
  "authors": [
    "Wu, Yu-Hsuan  and\nLin, Ying-Jia  and\nKao, Hung-Yu"
  ],
  "year": "2023",
  "venue": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
  "abstract": "This paper describes the entry by the Intelligent Knowledge Management (IKM) Laboratory in the BioLaySumm 2023 task1. We aim to transform lengthy biomedical articles into concise, reader-friendly summaries that can be easily comprehended by the general public. We utilized a long-text abstractive summarization longformer model and experimented with several prompt methods for this task. Our entry placed 10th overall, but we were particularly proud to achieve a 3rd place score in the readability evaluation metric.",
  "keywords": [
    "tuning",
    "friendly",
    "general",
    "knowledge",
    "summaries",
    "biomedical lay summary generation",
    "prompt",
    "generation",
    "several prompt methods",
    "the general public",
    "model",
    "text",
    "metric",
    "concise reader-friendly summaries",
    "umm"
  ],
  "url": "https://aclanthology.org/2023.bionlp-1.64/",
  "provenance": {
    "collected_at": "2025-06-05 10:23:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}