{
  "id": "2021.acl-long.63",
  "title": "Discontinuous Named Entity Recognition as Maximal Clique Discovery",
  "authors": [
    "Wang, Yucheng  and\nYu, Bowen  and\nZhu, Hongsong  and\nLiu, Tingwen  and\nYu, Nan  and\nSun, Limin"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Named entity recognition (NER) remains challenging when entity mentions can be discontinuous. Existing methods break the recognition process into several sequential steps. In training, they predict conditioned on the golden intermediate results, while at inference relying on the model output of the previous steps, which introduces exposure bias. To solve this problem, we first construct a segment graph for each sentence, in which each node denotes a segment (a continuous entity on its own, or a part of discontinuous entities), and an edge links two nodes that belong to the same entity. The nodes and edges can be generated respectively in one stage with a grid tagging scheme and learned jointly using a novel architecture named Mac. Then discontinuous NER can be reformulated as a non-parametric process of discovering maximal cliques in the graph and concatenating the spans in each clique. Experiments on three benchmarks show that our method outperforms the state-of-the-art (SOTA) results, with up to 3.5 percentage points improvement on F1, and achieves 5x speedup over the SOTA model.",
  "keywords": [
    "bias",
    "f1",
    "we",
    "graph",
    "training",
    "edge",
    "mac",
    "ner",
    "then discontinuous ner",
    "process",
    "discontinuous named entity recognition",
    "model",
    "entities",
    "discontinuous entities",
    "entity recognition ner"
  ],
  "url": "https://aclanthology.org/2021.acl-long.63/",
  "provenance": {
    "collected_at": "2025-06-05 08:00:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}