{
  "id": "2022.acl-long.562",
  "title": "Multimodal Sarcasm Target Identification in Tweets",
  "authors": [
    "Wang, Jiquan  and\nSun, Lin  and\nLiu, Yi  and\nShao, Meizhi  and\nZheng, Zengwei"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Sarcasm is important to sentiment analysis on social media. Sarcasm Target Identification (STI) deserves further study to understand sarcasm in depth. However, text lacking context or missing sarcasm target makes target identification very difficult. In this paper, we introduce multimodality to STI and present Multimodal Sarcasm Target Identification (MSTI) task. We propose a novel multi-scale cross-modality model that can simultaneously perform textual target labeling and visual target detection. In the model, we extract multi-scale visual features to enrich spatial information for different sized visual sarcasm targets. We design a set of convolution networks to unify multi-scale visual features with textual features for cross-modal attention learning, and correspondingly a set of transposed convolution networks to restore multi-scale visual information. The results show that visual clues can improve the performance of TSTI by a large margin, and VSTI achieves good accuracy.",
  "keywords": [
    "sti",
    "cross",
    "model",
    "text",
    "convolution",
    "good accuracy",
    "cross-modal attention learning",
    "information",
    "attention",
    "we",
    "learning",
    "visual",
    "analysis",
    "accuracy",
    "that"
  ],
  "url": "https://aclanthology.org/2022.acl-long.562/",
  "provenance": {
    "collected_at": "2025-06-05 08:31:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}