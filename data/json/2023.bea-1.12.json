{
  "id": "2023.bea-1.12",
  "title": "Scalable and Explainable Automated Scoring for Open-Ended Constructed Response Math Word Problems",
  "authors": [
    "Hellman, Scott  and\nAndrade, Alejandro  and\nHabermehl, Kyle"
  ],
  "year": "2023",
  "venue": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
  "abstract": "Open-ended constructed response math word problems (“math plus text”, or MPT) are a powerful tool in the assessment of students’ abilities to engage in mathematical reasoning and creative thinking. Such problems ask the student to compute a value or construct an expression and then explain, potentially in prose, what steps they took and why they took them. MPT items can be scored against highly structured rubrics, and we develop a novel technique for the automated scoring of MPT items that leverages these rubrics to provide explainable scoring. We show that our approach can be trained automatically and performs well on a large dataset of 34,417 responses across 14 MPT items.",
  "keywords": [
    "abilities",
    "mpt",
    "text",
    "students abilities",
    "word",
    "we",
    "that",
    "students",
    "expression",
    "scoring",
    "approach",
    "the assessment",
    "assessment",
    "a value",
    "value"
  ],
  "url": "https://aclanthology.org/2023.bea-1.12/",
  "provenance": {
    "collected_at": "2025-06-05 10:21:25",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}