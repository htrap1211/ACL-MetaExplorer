{
  "id": "2021.acl-long.64",
  "title": "LNN}-{EL}: A Neuro-Symbolic Approach to Short-text Entity Linking",
  "authors": [
    "Jiang, Hang  and\nGurajada, Sairam  and\nLu, Qiuhao  and\nNeelam, Sumit  and\nPopa, Lucian  and\nSen, Prithviraj  and\nLi, Yunyao  and\nGray, Alexander"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Entity linking (EL) is the task of disambiguating mentions appearing in text by linking them to entities in a knowledge graph, a crucial task for text understanding, question answering or conversational systems. In the special case of short-text EL, which poses additional challenges due to limited context, prior approaches have reached good performance by employing heuristics-based methods or purely neural approaches. Here, we take a different, neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to use rules, we show that we reach competitive or better performance with SoTA black-box neural approaches. Furthermore, our framework has the benefits of extensibility and transferability. We show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even with scores resulting from previous EL methods, thus improving on such methods. As an example of improvement, on the LC-QuAD-1.0 dataset, we show more than 3% increase in F1 score relative to previous SoTA. Finally, we show that the inductive bias offered by using logic results in a set of learned rules that transfers from one dataset to another, sometimes without finetuning, while still having high accuracy.",
  "keywords": [
    "bias",
    "question",
    "el",
    "we",
    "graph",
    "neural",
    "high accuracy",
    "that the inductive bias",
    "learning",
    "bert",
    "text",
    "conversational systems",
    "accuracy",
    "embeddings",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2021.acl-long.64/",
  "provenance": {
    "collected_at": "2025-06-05 08:00:17",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}