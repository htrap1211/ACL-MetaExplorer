{
  "id": "2023.bea-1.54",
  "title": "Does {BERT} Exacerbate Gender or {L}1 Biases in Automated {E}nglish Speaking Assessment?",
  "authors": [
    "Kwako, Alexander  and\nWan, Yixin  and\nZhao, Jieyu  and\nHansen, Mark  and\nChang, Kai-Wei  and\nCai, Li"
  ],
  "year": "2023",
  "venue": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
  "abstract": "In English speaking assessment, pretrained large language models (LLMs) such as BERT can score constructed response items as accurately as human raters. Less research has investigated whether LLMs perpetuate or exacerbate biases, which would pose problems for the fairness and validity of the test. This study examines gender and native language (L1) biases in human and automated scores, using an off-the-shelf (OOS) BERT model. Analyses focus on a specific type of bias known as differential item functioning (DIF), which compares examinees of similar English language proficiency. Results show that there is a moderate amount of DIF, based on examineesâ€™ L1 background in grade band 912. DIF is higher when scored by an OOS BERT model, indicating that BERT may exacerbate this bias; however, in practical terms, the degree to which BERT exacerbates DIF is very small. Additionally, there is more DIF for longer speaking items and for older examinees, but BERT does not exacerbate these patterns of DIF.",
  "keywords": [
    "l 1 biases",
    "proficiency",
    "bias",
    "oos",
    "language",
    "background",
    "bert",
    "model",
    "human",
    "examinees l1 background",
    "large language models llms",
    "bert exacerbates",
    "an oos bert model",
    "this bias",
    "biases"
  ],
  "url": "https://aclanthology.org/2023.bea-1.54/",
  "provenance": {
    "collected_at": "2025-06-05 10:21:58",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}