{
  "id": "2023.findings-acl.740",
  "title": "An Exploratory Study on Model Compression for Text-to-{SQL",
  "authors": [
    "Sun, Shuo  and\nGao, Yuze  and\nZhang, Yuchen  and\nSu, Jian  and\nChen, Bin  and\nLin, Yingzhan  and\nSun, Shuqi"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Text-to-SQL translates user queries into SQL statements that can retrieve relevant answers from relational databases. Recent approaches to Text-to-SQL rely on pre-trained language models that are computationally expensive and technically challenging to deploy in real-world applications that require real-time or on-device processing capabilities. In this paper, we perform a focused study on the feasibility of applying recent model compression techniques to sketch-based and sequence-to-sequence Text-to-SQL models. Our results reveal that sketch-based Text-to-SQL models generally have higher inference efficiency and respond better to model compression than sequence-to-sequence models, making them ideal for real-world deployments, especially in use cases with simple SQL statements.",
  "keywords": [
    "processing",
    "language",
    "pre-trained language models",
    "model",
    "text",
    "higher inference efficiency",
    "capabilities",
    "efficiency",
    "we",
    "sequence",
    "pre",
    "time",
    "that",
    "applications",
    "techniques"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.740/",
  "provenance": {
    "collected_at": "2025-06-05 10:18:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}