{
  "id": "2022.acl-demo.25",
  "title": "T}ime{LM}s: Diachronic Language Models from {T}witter",
  "authors": [
    "Loureiro, Daniel  and\nBarbieri, Francesco  and\nNeves, Leonardo  and\nEspinosa Anke, Luis  and\nCamacho-collados, Jose"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "Despite its importance, the time variable has been largely neglected in the NLP and language model literature. In this paper, we present TimeLMs, a set of language models specialized on diachronic Twitter data. We show that a continual learning strategy contributes to enhancing Twitter-based language modelsâ€™ capacity to deal with future and out-of-distribution tweets, while making them competitive with standardized and more monolithic benchmarks. We also perform a number of qualitative analyses showing how they cope with trends and peaks in activity involving specific named entities or concept drift. TimeLMs is available at github.com/cardiffnlp/timelms.",
  "keywords": [
    "cardiffnlp",
    "language",
    "nlp",
    "model",
    "entities",
    "language models",
    "github com cardiffnlp timelms",
    "we",
    "learning",
    "time",
    "twitter-based language models capacity",
    "specific named entities",
    "monolithic",
    "activity",
    "a continual learning strategy"
  ],
  "url": "https://aclanthology.org/2022.acl-demo.25/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}