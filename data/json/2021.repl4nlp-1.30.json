{
  "id": "2021.repl4nlp-1.30",
  "title": "Entity and Evidence Guided Document-Level Relation Extraction",
  "authors": [
    "Huang, Kevin  and\nQi, Peng  and\nWang, Guangtao  and\nMa, Tengyu  and\nHuang, Jing"
  ],
  "year": "2021",
  "venue": "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)",
  "abstract": "Document-level relation extraction is a challenging task, requiring reasoning over multiple sentences to predict a set of relations in a document. In this paper, we propose a novel framework E2GRE (Entity and Evidence Guided Relation Extraction) that jointly extracts relations and the underlying evidence sentences by using large pretrained language model (LM) as input encoder. First, we propose to guide the pretrained LMâ€™s attention mechanism to focus on relevant context by using attention probabilities as additional features for evidence prediction. Furthermore, instead of feeding the whole document into pretrained LMs to obtain entity representation, we concatenate document text with head entities to help LMs concentrate on parts of the document that are more related to the head entity. Our E2GRE jointly learns relation extraction and evidence prediction effectively, showing large gains on both these tasks, which we find are highly correlated.",
  "keywords": [
    "attention probabilities",
    "input encoder",
    "language",
    "extraction",
    "model",
    "entities",
    "text",
    "encoder",
    "probabilities",
    "attention",
    "we",
    "head entities",
    "large pretrained language model",
    "entity",
    "that"
  ],
  "url": "https://aclanthology.org/2021.repl4nlp-1.30/",
  "provenance": {
    "collected_at": "2025-06-05 08:19:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}