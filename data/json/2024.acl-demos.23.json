{
  "id": "2024.acl-demos.23",
  "title": "U}ltra{E}val: A Lightweight Platform for Flexible and Comprehensive Evaluation for {LLM}s",
  "authors": [
    "He, Chaoqun  and\nLuo, Renjie  and\nHu, Shengding  and\nZhao, Ranchi  and\nZhou, Jie  and\nWu, Hanghao  and\nZhang, Jiajie  and\nHan, Xu  and\nLiu, Zhiyuan  and\nSun, Maosong"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
  "abstract": "Evaluation is pivotal for honing Large Language Models (LLMs), pinpointing their capabilities and guiding enhancements. The rapid development of LLMs calls for a lightweight and easy-to-use framework for swift evaluation deployment. However, due to the various implementation details to consider, developing a comprehensive evaluation platform is never easy. Existing platforms are often complex and poorly modularized, hindering seamless incorporation into researcherâ€™s workflows. This paper introduces UltraEval, a user-friendly evaluation framework characterized by lightweight, comprehensiveness, modularity, and efficiency. We identify and reimplement three core components of model evaluation (models, data, and metrics). The resulting composability allows for the free combination of different models, tasks, prompts, and metrics within a unified evaluation workflow. Additionally, UltraEval supports diverse models owing to a unified HTTP service and provides sufficient inference acceleration.",
  "keywords": [
    "a user-friendly evaluation framework",
    "efficiency",
    "swift evaluation deployment",
    "we",
    "llm",
    "val",
    "friendly",
    "unified",
    "sufficient",
    "core",
    "sufficient inference acceleration",
    "llms",
    "a unified evaluation workflow",
    "metrics",
    "a comprehensive evaluation platform"
  ],
  "url": "https://aclanthology.org/2024.acl-demos.23/",
  "provenance": {
    "collected_at": "2025-06-05 10:47:35",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}