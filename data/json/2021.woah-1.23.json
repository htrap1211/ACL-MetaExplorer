{
  "id": "2021.woah-1.23",
  "title": "Racist or Sexist Meme? Classifying Memes beyond Hateful",
  "authors": [
    "Zia, Haris Bin  and\nCastro, Ignacio  and\nTyson, Gareth"
  ],
  "year": "2021",
  "venue": "Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)",
  "abstract": "Memes are the combinations of text and images that are often humorous in nature. But, that may not always be the case, and certain combinations of texts and images may depict hate, referred to as hateful memes. This work presents a multimodal pipeline that takes both visual and textual features from memes into account to (1) identify the protected category (e.g. race, sex etc.) that has been attacked; and (2) detect the type of attack (e.g. contempt, slurs etc.). Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier. We employ our pipeline on the Hateful Memes Challenge dataset with additional newly created fine-grained labels for protected category and type of attack. Our best model achieves an AUROC of 0.96 for identifying the protected category, and 0.97 for detecting the type of attack. We release our code athttps://github.com/harisbinzia/HatefulMemes",
  "keywords": [
    "work",
    "code",
    "classifier",
    "model",
    "text",
    "we",
    "visual",
    "pre",
    "that",
    "logistic",
    "sex",
    "the type",
    "this work",
    "hateful memes",
    "certain"
  ],
  "url": "https://aclanthology.org/2021.woah-1.23/",
  "provenance": {
    "collected_at": "2025-06-05 08:24:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}