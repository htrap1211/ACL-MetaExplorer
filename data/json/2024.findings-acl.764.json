{
  "id": "2024.findings-acl.764",
  "title": "CIDAR}: Culturally Relevant Instruction Dataset For {A}rabic",
  "authors": [
    "Alyafeai, Zaid  and\nAlmubarak, Khalid  and\nAshraf, Ahmed  and\nAlnuhait, Deema  and\nAlshahrani, Saied  and\nAbdulrahman, Gubran  and\nAhmed, Gamil  and\nGawah, Qais  and\nSaleh, Zead  and\nGhaleb, Mustafa  and\nAli, Yousef  and\nAl-shaibani, Maged"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Instruction tuning has emerged as a prominent methodology for teaching Large Language Models (LLMs) to follow instructions. However, current instruction datasets predominantly cater to English or are derived from English-dominated LLMs, leading to inherent biases toward Western culture. This bias negatively impacts non-English languages such as Arabic and the unique culture of the Arab region. This paper addresses this limitation by introducing CIDAR, the first open Arabic instruction-tuning dataset culturally aligned by native Arabic speakers. CIDAR contains 10,000 instruction and output pairs that represent the Arab region. We discuss the cultural relevance of CIDAR via the analysis and comparison to a few models fine-tuned on other datasets. Our experiments indicate that models fine-tuned on CIDAR achieve better cultural alignment compared to those fine-tuned on 30x more data.",
  "keywords": [
    "instruction",
    "alignment",
    "tuning",
    "inherent biases",
    "bias",
    "english-dominated llms",
    "language",
    "large language models",
    "llms",
    "we",
    "better cultural alignment",
    "a rabic instruction tuning",
    "current",
    "biases",
    "analysis"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.764/",
  "provenance": {
    "collected_at": "2025-06-05 10:59:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}