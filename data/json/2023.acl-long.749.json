{
  "id": "2023.acl-long.749",
  "title": "P}a{CE}: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts",
  "authors": [
    "Li, Yunshui  and\nHui, Binyuan  and\nYin, ZhiChao  and\nYang, Min  and\nHuang, Fei  and\nLi, Yongbin"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Perceiving multi-modal information and fulfilling dialogues with humans is a long-term goal of artificial intelligence. Pre-training is commonly regarded as an effective approach for multi-modal dialogue. However, due to the limited availability of multi-modal dialogue data, there is still scarce research on multi-modal dialogue pre-training. Yet another intriguing challenge emerges from the encompassing nature of multi-modal dialogue, which involves various modalities and tasks. Moreover, new forms of tasks may arise at unpredictable points in the future. Hence, it is essential for designed multi-modal dialogue models to possess sufficient flexibility to adapt to such scenarios. This paper proposes PaCE, a unified, structured, compositional multi-modal dialogue pre-training framework. It utilizes a combination of several fundamental experts to accommodate multiple dialogue-related tasks and can be pre-trained using limited dialogue and extensive non-dialogue multi-modal data. Furthermore, we propose a progressive training method where old experts from the past can assist new experts, facilitating the expansion of their capabilities. Experimental results demonstrate that PaCE achieves state-of-the-art results on eight multi-modal dialog benchmarks.",
  "keywords": [
    "multiple dialogue-related tasks",
    "we",
    "dialogue",
    "training",
    "designed multi-modal dialogue models",
    "it",
    "limited dialogue",
    "information",
    "sufficient",
    "various modalities",
    "multi-modal dialogue",
    "-",
    "fulfilling dialogues",
    "extensive non-dialogue multi-modal data",
    "multi-modal dialogue data"
  ],
  "url": "https://aclanthology.org/2023.acl-long.749/",
  "provenance": {
    "collected_at": "2025-06-05 09:45:49",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}