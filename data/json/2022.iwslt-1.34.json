{
  "id": "2022.iwslt-1.34",
  "title": "A}pp{T}ek{'}s Submission to the {IWSLT} 2022 Isometric Spoken Language Translation Task",
  "authors": [
    "Wilken, Patrick  and\nMatusov, Evgeny"
  ],
  "year": "2022",
  "venue": "Proceedings of the 19th International Conference on Spoken Language Translation (IWSLT 2022)",
  "abstract": "To participate in the Isometric Spoken Language Translation Task of the IWSLT 2022 evaluation, constrained condition, AppTek developed neural Transformer-based systems for English-to-German with various mechanisms of length control, ranging from source-side and target-side pseudo-tokens to encoding of remaining length in characters that replaces positional encoding. We further increased translation length compliance by sentence-level selection of length-compliant hypotheses from different system variants, as well as rescoring of N-best candidates from a single system. Length-compliant back-translated and forward-translated synthetic data, as well as other parallel data variants derived from the original MuST-C training corpus were important for a good quality/desired length trade-off. Our experimental results show that length compliance levels above 90% can be reached while minimizing losses in MT quality as measured in BERT and BLEU scores.",
  "keywords": [
    "transformer",
    "language",
    "neural",
    "bert",
    "translation length compliance",
    "bleu",
    "-",
    "neural transformer-based systems",
    "we",
    "bleu scores",
    "evaluation",
    "a",
    "training",
    "translation",
    "length control"
  ],
  "url": "https://aclanthology.org/2022.iwslt-1.34/",
  "provenance": {
    "collected_at": "2025-06-05 08:43:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}