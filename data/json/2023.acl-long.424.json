{
  "id": "2023.acl-long.424",
  "title": "Answering Ambiguous Questions via Iterative Prompting",
  "authors": [
    "Sun, Weiwei  and\nCai, Hengyi  and\nChen, Hongshen  and\nRen, Pengjie  and\nChen, Zhumin  and\nde Rijke, Maarten  and\nRen, Zhaochun"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "In open-domain question answering, due to the ambiguity of questions, multiple plausible answers may exist. To provide feasible answers to an ambiguous question,one approach is to directly predict all valid answers, but this can struggle with balancing relevance and diversity. An alternative is to gather candidate answers and aggregate them, but this method can be computationally costly and may neglect dependencies among answers. In this paper, we present AmbigPrompt to address the imperfections of existing approaches to answering ambiguous questions. Specifically, we integrate an answering model with a prompting model in an iterative manner. The prompting model adaptively tracks the reading process and progressively triggers the answering model to compose distinct and relevant answers. Additionally, we develop a task-specific post-pretraining approach for both the answering model and the prompting model, which greatly improves the performance of our framework. Empirical studies on two commonly-used open benchmarks show that AmbigPrompt achieves state-of-the-art or competitive results while using less memory and having a lower inference latency than competing approaches. Additionally, AmbigPrompt also performs well in low-resource settings.",
  "keywords": [
    "a prompting model",
    "question",
    "we",
    "valid",
    "ambigprompt",
    "dependencies",
    "an iterative manner",
    "our framework empirical studies",
    "the prompting model",
    "manner",
    "process",
    "model",
    "studies",
    "this method",
    "approach"
  ],
  "url": "https://aclanthology.org/2023.acl-long.424/",
  "provenance": {
    "collected_at": "2025-06-05 09:41:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}