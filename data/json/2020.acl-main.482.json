{
  "id": "2020.acl-main.482",
  "title": "ZPR}2: Joint Zero Pronoun Recovery and Resolution using Multi-Task Learning and {BERT",
  "authors": [
    "Song, Linfeng  and\nXu, Kun  and\nZhang, Yue  and\nChen, Jianshu  and\nYu, Dong"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Zero pronoun recovery and resolution aim at recovering the dropped pronoun and pointing out its anaphoric mentions, respectively. We propose to better explore their interaction by solving both tasks together, while the previous work treats them separately. For zero pronoun resolution, we study this task in a more realistic setting, where no parsing trees or only automatic trees are available, while most previous work assumes gold trees. Experiments on two benchmarks show that joint modeling significantly outperforms our baseline that already beats the previous state of the arts.",
  "keywords": [
    "work",
    "bert",
    "modeling",
    "no parsing trees",
    "we",
    "learning",
    "bert zero pronoun recovery",
    "that",
    "most previous work",
    "multi",
    "state",
    "task",
    "interaction",
    "only automatic trees",
    "recovery"
  ],
  "url": "https://aclanthology.org/2020.acl-main.482/",
  "provenance": {
    "collected_at": "2025-06-05 07:48:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}