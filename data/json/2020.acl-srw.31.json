{
  "id": "2020.acl-srw.31",
  "title": "Building a {J}apanese Typo Dataset from {W}ikipedia{'}s Revision History",
  "authors": [
    "Tanaka, Yu  and\nMurawaki, Yugo  and\nKawahara, Daisuke  and\nKurohashi, Sadao"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
  "abstract": "User generated texts contain many typos for which correction is necessary for NLP systems to work. Although a large number of typo–correction pairs are needed to develop a data-driven typo correction system, no such dataset is available for Japanese. In this paper, we extract over half a million Japanese typo–correction pairs from Wikipedia’s revision history. Unlike other languages, Japanese poses unique challenges: (1) Japanese texts are unsegmented so that we cannot simply apply a spelling checker, and (2) the way people inputting kanji logographs results in typos with drastically different surface forms from correct ones. We address them by combining character-based extraction rules, morphological analyzers to guess readings, and various filtering methods. We evaluate the dataset using crowdsourcing and run a baseline seq2seq model for typo correction.",
  "keywords": [
    "seq2seq",
    "nlp",
    "extraction",
    "model",
    "we",
    "nlp systems",
    "a baseline seq2seq model",
    "a large number",
    "typos",
    "analyzers",
    "a spelling checker",
    "various filtering methods",
    "user",
    "wikipedia",
    "spelling"
  ],
  "url": "https://aclanthology.org/2020.acl-srw.31/",
  "provenance": {
    "collected_at": "2025-06-05 07:53:41",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}