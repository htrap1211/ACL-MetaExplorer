{
  "id": "2024.findings-acl.354",
  "title": "C}ode{I}nsight: A Curated Dataset of Practical Coding Solutions from {S}tack {O}verflow",
  "authors": [
    "Beau, Nathana{\\\"e}l  and\nCrabb{\\'e}, Benoit"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "We introduce a novel dataset tailored for code generation, aimed at aiding developers in common tasks. Our dataset provides examples that include a clarified intent, code snippets associated, and an average of three related unit tests. It encompasses a range of libraries such as Pandas, Numpy, and Regex, along with more than 70 standard libraries in Python code derived from Stack Overflow. Comprising 3,402 crafted examples by Python experts, our dataset is designed for both model finetuning and standalone evaluation. To complete unit tests evaluation, we categorize examples in order to get more fine grained analysis, enhancing the understanding of modelsâ€™ strengths and weaknesses in specific coding tasks. The examples have been refined to reduce data contamination, a process confirmed by the performance of three leading models: Mistral 7B, CodeLLAMA 13B, and Starcoder 15B. We further investigate data-contamination testing GPT-4 performance on a part of our dataset. The benchmark can be accessed at anonymized address.",
  "keywords": [
    "code",
    "we",
    "ode",
    "libraries",
    "standalone evaluation",
    "data-contamination testing gpt-4 performance",
    "it",
    "analysis",
    "unit tests evaluation",
    "i",
    "fine",
    "process",
    "generation",
    "model",
    "code generation"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.354/",
  "provenance": {
    "collected_at": "2025-06-05 10:53:26",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}