{
  "id": "2024.acl-long.125",
  "title": "L}ist{T}5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval",
  "authors": [
    "Yoon, Soyoung  and\nChoi, Eunbi  and\nKim, Jiyeon  and\nYun, Hyeongu  and\nKim, Yireun  and\nHwang, Seung-won"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and compare our model on the BEIR benchmark for zero-shot retrieval task, demonstrating that ListT5 (1) outperforms the state-of-the-art RankT5 baseline with a notable +1.3 gain in the average NDCG@10 score, (2) has an efficiency comparable to pointwise ranking models and surpasses the efficiency of previous listwise ranking models, and (3) overcomes the lost-in-the-middle problem of previous listwise rerankers. Our code, model checkpoints, and the evaluation framework will be fully open-sourced.",
  "keywords": [
    "code",
    "model",
    "the evaluation framework",
    "efficient",
    "an efficient inference framework",
    "zero-shot retrieval task",
    "the efficiency",
    "decoder",
    "retrieval",
    "train",
    "efficiency",
    "an efficiency",
    "we",
    "evaluation",
    "fusion"
  ],
  "url": "https://aclanthology.org/2024.acl-long.125/",
  "provenance": {
    "collected_at": "2025-06-05 10:36:00",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}