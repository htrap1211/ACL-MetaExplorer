{
  "id": "2023.acl-long.386",
  "title": "Fact-Checking Complex Claims with Program-Guided Reasoning",
  "authors": [
    "Pan, Liangming  and\nWu, Xiaobao  and\nLu, Xinyuan  and\nLuu, Anh Tuan  and\nWang, William Yang  and\nKan, Min-Yen  and\nNakov, Preslav"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Fact-checking real-world claims often requires collecting multiple pieces of evidence and applying complex multi-step reasoning. In this paper, we present Program-Guided Fact-Checking (ProgramFC), a novel fact-checking model that decomposes complex claims into simpler sub-tasks that can be solved using a shared library of specialized functions. We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process. Afterward, we execute the program by delegating each sub-task to the corresponding sub-task handler. This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data. We evaluate ProgramFC on two challenging fact-checking datasets and show that it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging. Our codes and data are publicly available athttps://github.com/mbzuai-nlp/ProgramFC.",
  "keywords": [
    "efficient",
    "we",
    "training",
    "it",
    "pieces",
    "-",
    "process",
    "language",
    "nlp",
    "model",
    "human",
    "large language models",
    "multiple pieces",
    "multi",
    "each sub"
  ],
  "url": "https://aclanthology.org/2023.acl-long.386/",
  "provenance": {
    "collected_at": "2025-06-05 09:40:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}