{
  "id": "2022.acl-short.72",
  "title": "Triangular Transfer: Freezing the Pivot for Triangular Machine Translation",
  "authors": [
    "Zhang, Meng  and\nLi, Liangyou  and\nLiu, Qun"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Triangular machine translation is a special case of low-resource machine translation where the language pair of interest has limited parallel data, but both languages have abundant parallel data with a pivot language. Naturally, the key to triangular machine translation is the successful exploitation of such auxiliary data. In this work, we propose a transfer-learning-based approach that utilizes all types of auxiliary data. As we train auxiliary source-pivot and pivot-target translation models, we initialize some parameters of the pivot side with a pre-trained language model and freeze them to encourage both translation models to work in the same pivot language space, so that they can be smoothly transferred to the source-target translation model. Experiments show that our approach can outperform previous ones.",
  "keywords": [
    "work",
    "language",
    "pivot-target translation models",
    "machine",
    "model",
    "triangular machine translation",
    "a pre-trained language model",
    "low-resource machine translation",
    "we",
    "transfer",
    "pre",
    "translation",
    "both translation models",
    "that",
    "this work"
  ],
  "url": "https://aclanthology.org/2022.acl-short.72/",
  "provenance": {
    "collected_at": "2025-06-05 08:33:23",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}