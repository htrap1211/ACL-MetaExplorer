{
  "id": "W19-4517",
  "title": "Ranking Passages for Argument Convincingness",
  "authors": [
    "Potash, Peter  and\nFerguson, Adam  and\nHazen, Timothy J."
  ],
  "year": "2019",
  "venue": "Proceedings of the 6th Workshop on Argument Mining",
  "abstract": "In data ranking applications, pairwise annotation is often more consistent than cardinal annotation for learning ranking models. We examine this in a case study on ranking text passages for argument convincingness. Our task is to choose text passages that provide the highest-quality, most-convincing arguments for opposing sides of a topic. Using data from a deployed system within the Bing search engine, we construct a pairwise-labeled dataset for argument convincingness that is substantially more comprehensive in topical coverage compared to existing public resources. We detail the process of extracting topical passages for queries submitted to a search engine, creating annotated sets of passages aligned to different stances on a topic, and assessing argument convincingness of passages using pairwise annotation. Using a state-of-the-art convincingness model, we evaluate several methods for using pairwise-annotated data examples to train models for ranking passages. Our results show pairwise training outperforms training that regresses to a target score for each passage. Our results also show a simple ‘win-rate’ score is a better regression target than the previously proposed page-rank target. Lastly, addressing the need to filter noisy crowd-sourced annotations when constructing a dataset, we show that filtering for transitivity within pairwise annotations is more effective than filtering based on annotation confidence measures for individual examples.",
  "keywords": [
    "rate",
    "we",
    "training",
    "queries",
    "text",
    "topic",
    "process",
    "model",
    "our task",
    "topical",
    "measures",
    "state",
    "regression",
    "a pairwise-labeled dataset",
    "annotated"
  ],
  "url": "https://aclanthology.org/W19-4517/",
  "provenance": {
    "collected_at": "2025-06-05 00:51:59",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}