{
  "id": "2023.findings-acl.363",
  "title": "Visually-Enhanced Phrase Understanding",
  "authors": [
    "Hsu, Tsu-Yuan  and\nLi, Chen-An  and\nHuang, Chao-Wei  and\nChen, Yun-Nung"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Large-scale vision-language pre-training has exhibited strong performance in various visual and textual understanding tasks. Recently, the textual encoders of multi-modal pre-trained models have been shown to generate high-quality textual representations, which often outperform models that are purely text-based, such as BERT. In this study, our objective is to utilize both textual and visual encoders of multi-modal pre-trained models to enhance language understanding tasks. We achieve this by generating an image associated with a textual prompt, thus enriching the representation of a phrase for downstream tasks. Results from experiments conducted on four benchmark datasets demonstrate that our proposed method, which leverages visually-enhanced text representations, significantly improves performance in the entity clustering task.",
  "keywords": [
    "prompt",
    "language",
    "bert",
    "a textual prompt",
    "text",
    "objective",
    "the textual encoders",
    "-",
    "clustering task",
    "we",
    "visual",
    "pre",
    "entity",
    "encoders",
    "our objective"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.363/",
  "provenance": {
    "collected_at": "2025-06-05 10:13:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}