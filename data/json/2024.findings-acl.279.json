{
  "id": "2024.findings-acl.279",
  "title": "Two-Pronged Human Evaluation of {C}hat{GPT} Self-Correction in Radiology Report Simplification",
  "authors": [
    "Yang, Ziyu  and\nCherian, Santhosh  and\nVucetic, Slobodan"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Radiology reports are highly technical documents aimed primarily at doctor-doctor communication. There has been an increasing interest in sharing those reports with patients, necessitating providing them patient-friendly simplifications of the original reports. This study explores the suitability of large language models in automatically generating those simplifications. We examine the usefulness of chain-of-thought and self-correction prompting mechanisms in this domain. We also propose a new evaluation protocol that employs radiologists and laypeople, where radiologists verify the factual correctness of simplifications, and laypeople assess simplicity and comprehension. Our experimental results demonstrate the effectiveness of self-correction prompting in producing high-quality simplifications. Our findings illuminate the preferences of radiologists and laypeople regarding text simplification, informing future research on this topic.",
  "keywords": [
    "chain",
    "patient-friendly simplifications",
    "we",
    "friendly",
    "patients",
    "self",
    "a new evaluation protocol",
    "text",
    "topic",
    "c hat gpt self-correction",
    "language",
    "thought",
    "human",
    "two-pronged human evaluation",
    "large language models"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.279/",
  "provenance": {
    "collected_at": "2025-06-05 10:52:25",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}