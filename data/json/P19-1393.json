{
  "id": "P19-1393",
  "title": "Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation",
  "authors": [
    "Wang, Cunxiang  and\nLiang, Shuailong  and\nZhang, Yue  and\nLi, Xiaonan  and\nGao, Tian"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Introducing common sense to natural language understanding systems has received increasing research attention. It remains a fundamental question on how to evaluate whether a system has the sense-making capability. Existing benchmarks measure common sense knowledge indirectly or without reasoning. In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense. In addition, a system is asked to identify the most crucial reason why a statement does not make sense. We evaluate models trained over large-scale language modeling tasks as well as human performance, showing that there are different challenges for system sense-making.",
  "keywords": [
    "knowledge",
    "language",
    "natural",
    "it",
    "human",
    "modeling",
    "question",
    "attention",
    "we",
    "large-scale language modeling tasks",
    "increasing research attention",
    "that",
    "common sense",
    "human performance",
    "sense"
  ],
  "url": "https://aclanthology.org/P19-1393/",
  "provenance": {
    "collected_at": "2025-06-05 00:40:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}