{
  "id": "2023.findings-acl.702",
  "title": "Multijugate Dual Learning for Low-Resource Task-Oriented Dialogue System",
  "authors": [
    "Li, Shimin  and\nZhang, Xiaotian  and\nZheng, Yanjun  and\nLi, Linyang  and\nQiu, Xipeng"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Dialogue data in real scenarios tend to be sparsely available, rendering data-starved end-to-end dialogue systems trained inadequately. We discover that data utilization efficiency in low-resource scenarios can be enhanced by mining alignment information uncertain utterance and deterministic dialogue state. Therefore, we innovatively implement dual learning in task-oriented dialogues to exploit the correlation of heterogeneous data. In addition, the one-to-one duality is converted into a multijugate duality to reduce the influence of spurious correlations in dual training for generalization. Without introducing additional parameters, our method could be implemented in arbitrary networks. Extensive empirical analyses demonstrate that our proposed method improves the effectiveness of end-to-end task-oriented dialogue systems under multiple benchmarks and obtains state-of-the-art results in low-resource scenarios.",
  "keywords": [
    "alignment",
    "end",
    "data utilization efficiency",
    "dialogues",
    "information",
    "generalization",
    "deterministic dialogue state",
    "efficiency",
    "we",
    "learning",
    "dialogue",
    "task-oriented dialogues",
    "mining",
    "training",
    "multijugate dual learning"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.702/",
  "provenance": {
    "collected_at": "2025-06-05 10:18:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}