{
  "id": "2023.acl-long.716",
  "title": "BUMP}: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics",
  "authors": [
    "Ma, Liang  and\nCao, Shuyang  and\nLogan IV, Robert L  and\nLu, Di  and\nRan, Shihao  and\nZhang, Ke  and\nTetreault, Joel  and\nJaimes, Alejandro"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The proliferation of automatic faithfulness metrics for summarization has produced a need for benchmarks to evaluate them. While existing benchmarks measure the correlation with human judgements of faithfulness on model-generated summaries, they are insufficient for diagnosing whether metrics are: 1) consistent, i.e., indicate lower faithfulness as errors are introduced into a summary, 2) effective on human-written texts, and 3) sensitive to different error types (as summaries can contain multiple errors). To address these needs, we present a benchmark of unfaithful minimal pairs (BUMP), a dataset of 889 human-written, minimally different summary pairs, where a single error is introduced to a summary from the CNN/DailyMail dataset to produce an unfaithful summary. We find BUMP complements existing benchmarks in a number of ways: 1) the summaries in BUMP are harder to discriminate and less probable under SOTA summarization models, 2) unlike non-pair-based datasets, BUMP can be used to measure the consistency of metrics, and reveals that the most discriminative metrics tend not to be the most consistent, and 3) unlike datasets containing generated summaries with multiple errors, BUMP enables the measurement of metricsâ€™ performance on individual error types.",
  "keywords": [
    "model-generated summaries",
    "automatic faithfulness metrics",
    "summarization",
    "we",
    "the cnn dailymail",
    "generated summaries",
    "faithfulness metrics",
    "cnn",
    "sota summarization models",
    "the summaries",
    "e",
    "i",
    "metrics",
    "the most discriminative metrics",
    "insufficient"
  ],
  "url": "https://aclanthology.org/2023.acl-long.716/",
  "provenance": {
    "collected_at": "2025-06-05 09:45:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}