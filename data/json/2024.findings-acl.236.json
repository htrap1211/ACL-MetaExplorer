{
  "id": "2024.findings-acl.236",
  "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
  "authors": [
    "Messina, Pablo  and\nVidal, Rene  and\nParra, Denis  and\nSoto, Alvaro  and\nAraujo, Vladimir"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality factual statements from free-text radiology reports in order to improve the representations of text encoders and, consequently, their performance on various downstream tasks.In the first stage, we propose aFact Extractorthat leverages large language models (LLMs) to identify factual statements from well-curated domain-specific datasets. In the second stage, we introduce aFact Encoder(CXRFE) based on a BERT model fine-tuned with objective functions designed to improve its representations using the extracted factual data. Our framework also includes a new embedding-based metric (CXRFEScore) for evaluating chest X-ray text generation systems, leveraging both stages of our approach. Extensive evaluations show that our fact extractor and encoder outperform current state-of-the-art methods in tasks such as sentence ranking, natural language inference, and label extraction from radiology reports. Additionally, our metric proves to be more robust and effective than existing metrics commonly used in the radiology report generation literature. The code of this project is available athttps://github.com/PabloMessina/CXR-Fact-Encoder.",
  "keywords": [
    "code",
    "extraction",
    "we",
    "fields",
    "current",
    "afact encoder cxrfe",
    "natural",
    "learning",
    "specialized fields",
    "text encoders",
    "bert",
    "metric",
    "text",
    "objective",
    "metrics"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.236/",
  "provenance": {
    "collected_at": "2025-06-05 10:51:50",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}