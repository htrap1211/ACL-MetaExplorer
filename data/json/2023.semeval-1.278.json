{
  "id": "2023.semeval-1.278",
  "title": "ROZAM} at {S}em{E}val 2023 Task 9: Multilingual Tweet Intimacy Analysis",
  "authors": [
    "Rostamkhani, Mohammadmostafa  and\nZamaninejad, Ghazal  and\nEetemadi, Sauleh"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "We build a model using large multilingual pretrained language model XLM-T for regression task and fine-tune it on the MINT (Multilingual INTmacy) analysis dataset which covers 6 languages for training and 4 languages for testing zero-shot performance of the model. The dataset was annotated and the annotations are intimacy scores. We experiment with several deep learning architectures to predict intimacy score. To achieve optimal performance we modify several model settings including loss function, number and type of layers. In total, we ran 16 end-to-end experiments. Our best system achieved a Pearson Correlation score of 0.52.",
  "keywords": [
    "deep",
    "val",
    "zero-shot performance",
    "end",
    "language",
    "em",
    "model",
    "several deep learning",
    "loss",
    "loss function number",
    "fine",
    "we",
    "learning",
    "function",
    "analysis"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.278/",
  "provenance": {
    "collected_at": "2025-06-05 10:30:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}