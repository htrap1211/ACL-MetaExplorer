{
  "id": "W19-5302",
  "title": "Results of the {WMT}19 Metrics Shared Task: Segment-Level and Strong {MT} Systems Pose Big Challenges",
  "authors": [
    "Ma, Qingsong  and\nWei, Johnny  and\nBojar, Ond{\\v{r}}ej  and\nGraham, Yvette"
  ],
  "year": "2019",
  "venue": "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
  "abstract": "This paper presents the results of the WMT19 Metrics Shared Task. Participants were asked to score the outputs of the translations systems competing in the WMT19 News Translation Task with automatic metrics. 13 research groups submitted 24 metrics, 10 of which are reference-less “metrics” and constitute submissions to the joint task with WMT19 Quality Estimation Task, “QE as a Metric”. In addition, we computed 11 baseline metrics, with 8 commonly applied baselines (BLEU, SentBLEU, NIST, WER, PER, TER, CDER, and chrF) and 3 reimplementations (chrF+, sacreBLEU-BLEU, and sacreBLEU-chrF). Metrics were evaluated on the system level, how well a given metric correlates with the WMT19 official manual ranking, and segment level, how well the metric correlates with human judgements of segment quality. This year, we use direct assessment (DA) as our only form of manual evaluation.",
  "keywords": [
    "reference",
    "sacrebleu",
    "reference-less metrics",
    "sacrebleu-chrf",
    "translation",
    "metric",
    "human",
    "wer",
    "metrics",
    "bleu",
    "manual evaluation",
    "form",
    "the wmt19 metrics",
    "ter",
    "we"
  ],
  "url": "https://aclanthology.org/W19-5302/",
  "provenance": {
    "collected_at": "2025-06-05 01:54:44",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}