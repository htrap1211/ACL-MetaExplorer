{
  "id": "2024.acl-long.439",
  "title": "M}eme{G}uard: An {LLM} and {VLM}-based Framework for Advancing Content Moderation via Meme Intervention",
  "authors": [
    "Jha, Prince  and\nJain, Raghav  and\nMandal, Konika  and\nChadha, Aman  and\nSaha, Sriparna  and\nBhattacharyya, Pushpak"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content, neglecting the widespread influence of multimodal content like memes. Addressing this gap, we presentMemeGuard, a comprehensive framework leveraging Large Language Models (LLMs) and Visual Language Models (VLMs) for meme intervention.MemeGuardharnesses a specially fine-tuned VLM,VLMeme, for meme interpretation, and a multimodal knowledge selection and ranking mechanism (MKS) for distilling relevant knowledge. This knowledge is then employed by a general-purpose LLM to generate contextually appropriate interventions. Another key contribution of this work is theInterveningCyberbullying inMultimodalMemes (ICMM)dataset, a high-quality, labeled dataset featuring toxic memes and their corresponding human-annotated interventions. We leverageICMMto testMemeGuard, demonstrating its proficiency in generating relevant and effective responses to toxic memes. redDisclaimer:This paper contains harmful content that may be disturbing to some readers.",
  "keywords": [
    "eme",
    "we",
    "a general-purpose llm",
    "current",
    "llm",
    "its proficiency",
    "visual",
    "visual language models",
    "llms",
    "text",
    "large language models llms",
    "work",
    "proficiency",
    "general",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2024.acl-long.439/",
  "provenance": {
    "collected_at": "2025-06-05 10:40:20",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}