{
  "id": "2023.findings-acl.353",
  "title": "Rethinking Document-Level Relation Extraction: A Reality Check",
  "authors": [
    "Li, Jing  and\nWang, Yequan  and\nZhang, Shuai  and\nZhang, Min"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Recently, numerous efforts have continued to push up performance boundaries of document-level relation extraction (DocRE) and have claimed significant progress in DocRE. In this paper, we do not aim at proposing a novel model for DocRE. Instead, we take a closer look at the field to see if these performance gains are actually true. By taking a comprehensive literature review and a thorough examination of popular DocRE datasets, we find that these performance gains are achieved upon a strong or even untenable assumption in common: all named entities are perfectly localized, normalized, and typed in advance. Next, we construct four types of entity mention attacks to examine the robustness of typical DocRE models by behavioral probing. We also have a close check on model usability in a more realistic setting. Our findings reveal that most of current DocRE models are vulnerable to entity mention attacks and difficult to be deployed in real-world end-user NLP applications. Our study calls more attentions for future research to stop simplifying problem setups, and to model DocRE in the wild rather than in an unrealistic Utopian world.",
  "keywords": [
    "end",
    "real-world end-user nlp applications",
    "extraction",
    "attentions",
    "field",
    "a comprehensive literature review",
    "we",
    "performance boundaries",
    "current",
    "the field",
    "more attentions",
    "common all named entities",
    "vulnerable",
    "nlp",
    "model"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.353/",
  "provenance": {
    "collected_at": "2025-06-05 09:58:12",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}