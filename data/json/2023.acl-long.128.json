{
  "id": "2023.acl-long.128",
  "title": "What Makes Pre-trained Language Models Better Zero-shot Learners?",
  "authors": [
    "Lu, Jinghui  and\nZhu, Dongsheng  and\nHan, Weidong  and\nZhao, Rui  and\nMac Namee, Brian  and\nTan, Fei"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Current methods for prompt learning in zero-shot scenarios widely rely on a development set with sufficient human-annotated data to select the best-performing prompt template a posteriori. This is not ideal because in a real-world zero-shot scenario of practical relevance, no labelled data is available. Thus, we propose a simple yet effective method for screening reasonable prompt templates in zero-shot text classification: Perplexity Selection (Perplection). We hypothesize that language discrepancy can be used to measure the efficacy of prompt templates, and thereby develop a substantiated perplexity-based scheme allowing for forecasting the performance of prompt templates in advance. Experiments show that our method leads to improved prediction performance in a realistic zero-shot setting, eliminating the need for any labelled examples.",
  "keywords": [
    "zero-shot scenarios",
    "reasonable prompt templates",
    "prompt learning",
    "prompt",
    "language",
    "learners",
    "pre-trained language models",
    "a realistic zero-shot setting",
    "a substantiated perplexity-based scheme",
    "prompt templates",
    "text",
    "human",
    "the best-performing prompt template",
    "perplexity",
    "sufficient human-annotated data"
  ],
  "url": "https://aclanthology.org/2023.acl-long.128/",
  "provenance": {
    "collected_at": "2025-06-05 09:37:05",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}