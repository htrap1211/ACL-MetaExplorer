{
  "id": "2021.acl-long.156",
  "title": "Hierarchical Context-aware Network for Dense Video Event Captioning",
  "authors": [
    "Ji, Lei  and\nGuo, Xianglin  and\nHuang, Haoyang  and\nChen, Xilin"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Dense video event captioning aims to generate a sequence of descriptive captions for each event in a long untrimmed video. Video-level context provides important information and facilities the model to generate consistent and less redundant captions between events. In this paper, we introduce a novel Hierarchical Context-aware Network for dense video event captioning (HCN) to capture context from various aspects. In detail, the model leverages local and global context with different mechanisms to jointly learn to generate coherent captions. The local context module performs full interaction between neighbor frames and the global context module selectively attends to previous or future events. According to our extensive experiment on both Youcook2 and Activitynet Captioning datasets, the video-level HCN model outperforms the event-level context-agnostic model by a large margin. The code is available athttps://github.com/KirkGuo/HCN.",
  "keywords": [
    "code",
    "hierarchical",
    "model",
    "facilities",
    "hierarchical context-aware network",
    "information",
    "network",
    "we",
    "sequence",
    "kirkguo",
    "coherent",
    "our extensive experiment",
    "descriptive captions",
    "important information",
    "global"
  ],
  "url": "https://aclanthology.org/2021.acl-long.156/",
  "provenance": {
    "collected_at": "2025-06-05 08:01:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}