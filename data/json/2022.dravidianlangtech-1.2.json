{
  "id": "2022.dravidianlangtech-1.2",
  "title": "A Dataset for Detecting Humor in {T}elugu Social Media Text",
  "authors": [
    "Bellamkonda, Sriphani  and\nLohakare, Maithili  and\nPatel, Shaswat"
  ],
  "year": "2022",
  "venue": "Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages",
  "abstract": "Increased use of online social media sites has given rise to tremendous amounts of user generated data. Social media sites have become a platform where users express and voice their opinions in a real-time environment. Social media sites such as Twitter limit the number of characters used to express a thought in a tweet, leading to increased use of creative, humorous and confusing language in order to convey the message. Due to this, automatic humor detection has become a difficult task, especially for low-resource languages such as the Dravidian languages. Humor detection has been a well studied area for resource rich languages due to the availability of rich and accurate data. In this paper, we have attempted to solve this issue by working on low-resource languages, such as, Telugu, a Dravidian language, by collecting and annotating Telugu tweets and performing automatic humor detection on the collected data. We experimented on the corpus using various transformer models such as Multilingual BERT, Multilingual DistillBERT and XLM-RoBERTa to establish a baseline classification system. We concluded that XLM-RoBERTa was the best-performing model and it achieved an F1-score of 0.82 with 81.5% accuracy.",
  "keywords": [
    "distillbert",
    "roberta",
    "multilingual bert multilingual distillbert",
    "we",
    "various transformer models",
    "classification",
    "it",
    "rich",
    "xlm-roberta",
    "81 5 accuracy",
    "a baseline classification system",
    "an f1-score",
    "bert",
    "text",
    "a well studied area"
  ],
  "url": "https://aclanthology.org/2022.dravidianlangtech-1.2/",
  "provenance": {
    "collected_at": "2025-06-05 08:41:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}