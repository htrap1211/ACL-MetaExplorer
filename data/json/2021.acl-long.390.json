{
  "id": "2021.acl-long.390",
  "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision",
  "authors": [
    "Sun, Si  and\nQian, Yingzhuo  and\nLiu, Zhenghao  and\nXiong, Chenyan  and\nZhang, Kaitao  and\nBao, Jie  and\nLiu, Zhiyuan  and\nBennett, Paul"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a large scale of in-domain relevance training signals, which are not always available in real-world ranking scenarios. To democratize the benefits of Neu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method that generalizes Neu-IR models from label-rich source domains to few-shot target domains. Drawing on source-domain massive relevance supervision, MetaAdaptRank contrastively synthesizes a large number of weak supervision signals for target domains and meta-learns to reweight these synthetic “weak” data based on their benefits to the target-domain ranking accuracy of Neu-IR models. Experiments on three TREC benchmarks in the web, news, and biomedical domains show that MetaAdaptRank significantly improves the few-shot ranking accuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives from both its contrastive weak data synthesis and meta-reweighted data selection. The code and data of this paper can be obtained fromhttps://github.com/thunlp/MetaAdaptRank.",
  "keywords": [
    "code",
    "neu",
    "few-shot text",
    "shot",
    "training",
    "neural",
    "few-shot target domains",
    "retrieval",
    "information",
    "neural information retrieval neu",
    "rich",
    "learning",
    "the few-shot ranking accuracy",
    "text",
    "accuracy"
  ],
  "url": "https://aclanthology.org/2021.acl-long.390/",
  "provenance": {
    "collected_at": "2025-06-05 08:04:39",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}