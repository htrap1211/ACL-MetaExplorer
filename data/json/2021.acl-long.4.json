{
  "id": "2021.acl-long.4",
  "title": "H}ate{C}heck: Functional Tests for Hate Speech Detection Models",
  "authors": [
    "R{\\\"o}ttger, Paul  and\nVidgen, Bertie  and\nNguyen, Dong  and\nWaseem, Zeerak  and\nMargetts, Helen  and\nPierrehumbert, Janet"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Detecting online hate is a difficult task that even state-of-the-art models struggle with. Typically, hate speech detection models are evaluated by measuring their performance on held-out test data using metrics such as accuracy and F1 score. However, this approach makes it difficult to identify specific model weak points. It also risks overestimating generalisable model performance due to increasingly well-evidenced systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, we introduce HateCheck, a suite of functional tests for hate speech detection models. We specify 29 model functionalities motivated by a review of previous research and a series of interviews with civil society stakeholders. We craft test cases for each functionality and validate their quality through a structured annotation process. To illustrate HateCheckâ€™s utility, we test near-state-of-the-art transformer models as well as two popular commercial models, revealing critical model weaknesses.",
  "keywords": [
    "functionalities",
    "a review",
    "29 model functionalities",
    "series",
    "we",
    "interviews",
    "it",
    "generalisable",
    "h",
    "metrics",
    "generalisable model performance",
    "civil society stakeholders",
    "biases",
    "society",
    "accuracy"
  ],
  "url": "https://aclanthology.org/2021.acl-long.4/",
  "provenance": {
    "collected_at": "2025-06-05 07:59:29",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}