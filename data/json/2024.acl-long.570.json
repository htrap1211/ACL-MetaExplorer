{
  "id": "2024.acl-long.570",
  "title": "LLM}s in the Imaginarium: Tool Learning through Simulated Trial and Error",
  "authors": [
    "Wang, Boshi  and\nFang, Hao  and\nEisner, Jason  and\nVan Durme, Benjamin  and\nSu, Yu"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained. We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice. We propose a biologically inspired method for tool-augmented LLMs, simulated trial and error (STE), that orchestrates three key mechanisms for successful tool use behaviors in the biological system: trial and error, imagination, and memory. Specifically, STE leverages an LLM’s ‘imagination’ to simulate plausible scenarios for using a tool, after which the LLM interacts with the tool to learn from its execution feedback. Both short-term and long-term memory are employed to improve the depth and breadth of the exploration, respectively. Comprehensive experiments on ToolBench show that STE substantially improves tool learning for LLMs under both in-context learning and fine-tuning settings, bringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform GPT-4. We also show effective continual learning of tools via a simple experience replay strategy.",
  "keywords": [
    "feedback",
    "rate",
    "an llm",
    "we",
    "llm",
    "it",
    "information",
    "boost",
    "understudied",
    "learning",
    "fine-tuning settings",
    "llms",
    "ste",
    "tuning",
    "an llm s imagination"
  ],
  "url": "https://aclanthology.org/2024.acl-long.570/",
  "provenance": {
    "collected_at": "2025-06-05 10:42:10",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}