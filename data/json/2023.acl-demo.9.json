{
  "id": "2023.acl-demo.9",
  "title": "O}pen{SLU}: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding",
  "authors": [
    "Qin, Libo  and\nChen, Qiguang  and\nXu, Xiao  and\nFeng, Yunlong  and\nChe, Wanxiang"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
  "abstract": "Spoken Language Understanding (SLU) is one of the core components of a task-oriented dialogue system, which aims to extract the semantic meaning of user queries (e.g., intents and slots). In this work, we introduce OpenSLU, an open-source toolkit to provide a unified, modularized, and extensible toolkit for spoken language understanding. Specifically, OpenSLU unifies 10 SLU models for both single-intent and multi-intent scenarios, which support both non-pretrained and pretrained models simultaneously. Additionally, OpenSLU is highly modularized and extensible by decomposing the model architecture, inference, and learning process into reusable modules, which allows researchers to quickly set up SLU experiments with highly flexible configurations. OpenSLU is implemented based on PyTorch, and released athttps://github.com/LightChen233/OpenSLU.",
  "keywords": [
    "work",
    "process",
    "language",
    "model",
    "unified",
    "semantic",
    "we",
    "dialogue",
    "learning",
    "a task-oriented dialogue system",
    "the semantic meaning",
    "pen",
    "core",
    "this work",
    "multi"
  ],
  "url": "https://aclanthology.org/2023.acl-demo.9/",
  "provenance": {
    "collected_at": "2025-06-05 09:50:42",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}