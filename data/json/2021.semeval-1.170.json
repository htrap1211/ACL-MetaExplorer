{
  "id": "2021.semeval-1.170",
  "title": "CSECU}-{DSG} at {S}em{E}val-2021 Task 7: Detecting and Rating Humor and Offense Employing Transformers",
  "authors": [
    "Sultana, Afrin  and\nAyman, Nabila  and\nChy, Abu Nowshed"
  ],
  "year": "2021",
  "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)",
  "abstract": "With the emerging trends of using online platforms, peoples are increasingly interested in express their opinion through humorous texts. Identifying and rating humorous texts poses unique challenges to NLP due to subjective phenomena i.e. humor may vary to gender, profession, age, and classes of people. Besides, words with multiple senses, cultural domain, and pragmatic competence also need to be considered. A humorous text may be offensive to others. To address these challenges SemEval-2021 introduced a HaHackathon task focusing on detecting and rating humorous and offensive texts. This paper describes our participation in this task. We employed a stacked embedding and fine-tuned transformer models based classification and regression approach from the features from GPT2 medium, BERT, and RoBERTa transformer models. Besides, we utilized the fine-tuned BERT and RoBERTa models to examine the performances. Our method achieved competitive performances in this task.",
  "keywords": [
    "transformers",
    "roberta",
    "gpt2",
    "we",
    "classification",
    "i",
    "bert",
    "text",
    "roberta transformer models",
    "age",
    "transformer",
    "gpt2 medium bert",
    "performances",
    "approach",
    "gender"
  ],
  "url": "https://aclanthology.org/2021.semeval-1.170/",
  "provenance": {
    "collected_at": "2025-06-05 08:22:01",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}