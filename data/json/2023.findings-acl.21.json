{
  "id": "2023.findings-acl.21",
  "title": "On Evaluating and Mitigating Gender Biases in Multilingual Settings",
  "authors": [
    "Vashishtha, Aniket  and\nAhuja, Kabir  and\nSitaram, Sunayana"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "While understanding and removing gender biases in language models has been a long-standing problem in Natural Language Processing, prior research work has primarily been limited to English. In this work, we investigate some of the challenges with evaluating and mitigating biases in multilingual settings which stem from a lack of existing benchmarks and resources for bias evaluation beyond English especially for non-western context. In this paper, we first create a benchmark for evaluating gender biases in pre-trained masked language models by extending DisCo to different Indian languages using human annotations. We extend various debiasing methods to work beyond English and evaluate their effectiveness for SOTA massively multilingual models on our proposed metric. Overall, our work highlights the challenges that arise while studying social biases in multilingual settings and provides resources as well as mitigation techniques to take a step toward scaling to more languages.",
  "keywords": [
    "work",
    "pre-trained masked language models",
    "bias",
    "processing",
    "language",
    "bias evaluation",
    "natural",
    "metric",
    "social biases",
    "human",
    "various debiasing methods",
    "language models",
    "gender biases",
    "we",
    "natural language processing"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.21/",
  "provenance": {
    "collected_at": "2025-06-05 09:53:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}