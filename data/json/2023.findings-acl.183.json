{
  "id": "2023.findings-acl.183",
  "title": "Quantifying Train-Evaluation Overlap with Nearest Neighbors",
  "authors": [
    "Kambhatla, Gauri  and\nNguyen, Thuy  and\nChoi, Eunsol"
  ],
  "year": "2023",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
  "abstract": "Characterizing benchmark datasets is crucial to interpreting model performance. In this work, we study train-evaluation overlap as a measure of an individual datasetâ€™s adequacy to evaluate model generalization over a wide range of datasets. We quantify the overlap with a simple novel metric based on a nearest neighbors approach between the training and evaluation sets. We identify nearest training examples for each evaluation example by mapping instances with generic and task-specific embedding methods. Our study on eleven classification and extractive QA tasks reveals a wide range of train-evaluation overlap, and we show that the data collection method of the dataset and the difficulty of the task may play a role in the amount of overlap. Lastly, we use our nearest neighbor analysis to identify challenging or potentially mislabeled examples. Our analysis quantifies train-evaluation overlap, providing insights for constructing datasets to study generalization.",
  "keywords": [
    "work",
    "quantifies",
    "model",
    "metric",
    "train-evaluation overlap",
    "generic",
    "generalization",
    "train",
    "model generalization",
    "extractive qa tasks",
    "we",
    "eleven classification",
    "evaluation",
    "classification",
    "analysis"
  ],
  "url": "https://aclanthology.org/2023.findings-acl.183/",
  "provenance": {
    "collected_at": "2025-06-05 09:55:47",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}