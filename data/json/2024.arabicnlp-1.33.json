{
  "id": "2024.arabicnlp-1.33",
  "title": "rematchka at {A}rabic{NLU}2024: Evaluating Large Language Models for {A}rabic Word Sense and Location Sense Disambiguation",
  "authors": [
    "Abdel-Salam, Reem"
  ],
  "year": "2024",
  "venue": "Proceedings of the Second Arabic Natural Language Processing Conference",
  "abstract": "Natural Language Understanding (NLU) plays a vital role in Natural Language Processing (NLP) by facilitating semantic interactions. Arabic, with its diverse morphology, poses a challenge as it allows multiple interpretations of words, leading to potential misunderstandings and errors in NLP applications. In this paper, we present our approach for tackling Arabic NLU shared tasks for word sense disambiguation (WSD) and location mention disambiguation (LMD). Various approaches have been investigated from zero-shot inference of large language models (LLMs) to fine-tuning of pre-trained language models (PLMs). The best approach achieved 57% on WSD task ranking third place, while for the LMD task, our best systems achieved 94% MRR@1 ranking first place.",
  "keywords": [
    "tuning",
    "processing",
    "language",
    "zero-shot inference",
    "pre-trained language models",
    "natural",
    "nlp",
    "it",
    "large language models",
    "location",
    "semantic",
    "word",
    "we",
    "pre",
    "nlp applications"
  ],
  "url": "https://aclanthology.org/2024.arabicnlp-1.33/",
  "provenance": {
    "collected_at": "2025-06-05 11:02:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}