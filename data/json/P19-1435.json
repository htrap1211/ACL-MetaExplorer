{
  "id": "P19-1435",
  "title": "Selection Bias Explorations and Debias Methods for Natural Language Sentence Matching Datasets",
  "authors": [
    "Zhang, Guanhua  and\nBai, Bing  and\nLiang, Jian  and\nBai, Kun  and\nChang, Shiyu  and\nYu, Mo  and\nZhu, Conghui  and\nZhao, Tiejun"
  ],
  "year": "2019",
  "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Natural Language Sentence Matching (NLSM) has gained substantial attention from both academics and the industry, and rich public datasets contribute a lot to this process. However, biased datasets can also hurt the generalization performance of trained models and give untrustworthy evaluation results. For many NLSM datasets, the providers select some pairs of sentences into the datasets, and this sampling procedure can easily bring unintended pattern, i.e., selection bias. One example is the QuoraQP dataset, where some content-independent naive features are unreasonably predictive. Such features are the reflection of the selection bias and termed as the “leakage features.” In this paper, we investigate the problem of selection bias on six NLSM datasets and find that four out of them are significantly biased. We further propose a training and evaluation framework to alleviate the bias. Experimental results on QuoraQP suggest that the proposed framework can improve the generalization ability of trained models, and give more trustworthy evaluation results for real-world adoptions.",
  "keywords": [
    "bias",
    "the generalization ability",
    "we",
    "selection bias",
    "however biased datasets",
    "training",
    "natural",
    "the bias experimental results",
    "rich",
    "biased",
    "i",
    "selection bias explorations",
    "debias methods",
    "generalization",
    "the generalization performance"
  ],
  "url": "https://aclanthology.org/P19-1435/",
  "provenance": {
    "collected_at": "2025-06-05 00:41:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}