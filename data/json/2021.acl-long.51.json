{
  "id": "2021.acl-long.51",
  "title": "Structurizing Misinformation Stories via Rationalizing Fact-Checks",
  "authors": [
    "Jiang, Shan  and\nWilson, Christo"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Misinformation has recently become a well-documented matter of public concern. Existing studies on this topic have hitherto adopted a coarse concept of misinformation, which incorporates a broad spectrum of story types ranging from political conspiracies to misinterpreted pranks. This paper aims to structurize these misinformation stories by leveraging fact-check articles. Our intuition is that key phrases in a fact-check article that identify the misinformation type(s) (e.g., doctored images, urban legends) also act as rationales that determine the verdict of the fact-check (e.g., false). We experiment on rationalized models with domain knowledge as weak supervision to extract these phrases as rationales, and then cluster semantically similar rationales to summarize prevalent misinformation types. Using archived fact-checks from Snopes.com, we identify ten types of misinformation stories. We discuss how these types have evolved over the last ten years and compare their prevalence between the 2016/2020 US presidential elections and the H1N1/COVID-19 pandemics.",
  "keywords": [
    "conspiracies",
    "we",
    "political conspiracies",
    "these misinformation stories",
    "public concern existing studies",
    "misinformation stories",
    "topic",
    "stories",
    "semantically similar rationales",
    "knowledge",
    "studies",
    "a broad spectrum",
    "supervision",
    "ten types",
    "coarse"
  ],
  "url": "https://aclanthology.org/2021.acl-long.51/",
  "provenance": {
    "collected_at": "2025-06-05 08:00:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}