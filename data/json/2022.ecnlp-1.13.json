{
  "id": "2022.ecnlp-1.13",
  "title": "Product Answer Generation from Heterogeneous Sources: A New Benchmark and Best Practices",
  "authors": [
    "Shen, Xiaoyu  and\nBarlacchi, Gianni  and\nDel Tredici, Marco  and\nCheng, Weiwei  and\nByrne, Bill  and\nGispert, Adri{\\`a}"
  ],
  "year": "2022",
  "venue": "Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5)",
  "abstract": "It is of great value to answer product questions based on heterogeneous information sources available on web product pages, e.g., semi-structured attributes, text descriptions, user-provided contents, etc. However, these sources have different structures and writing styles, which poses challenges for (1) evidence ranking, (2) source selection, and (3) answer generation. In this paper, we build a benchmark with annotations for both evidence selection and answer generation covering 6 information sources. Based on this benchmark, we conduct a comprehensive study and present a set of best practices. We show that all sources are important and contribute to answering questions. Handling all sources within one single model can produce comparable confidence scores across sources and combining multiple sources for training always helps, even for sources with totally different structures. We further propose a novel data augmentation method to iteratively create training samples for answer generation, which achieves close-to-human performance with only a few thousandannotations. Finally, we perform an in-depth error analysis of model predictions and highlight the challenges for future research.",
  "keywords": [
    "we",
    "training",
    "answer",
    "it",
    "information",
    "answer generation",
    "analysis",
    "text",
    "3 answer generation",
    "generation",
    "model",
    "human",
    "great",
    "future research",
    "error"
  ],
  "url": "https://aclanthology.org/2022.ecnlp-1.13/",
  "provenance": {
    "collected_at": "2025-06-05 08:42:16",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}