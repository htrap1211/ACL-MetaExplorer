{
  "id": "2024.findings-acl.938",
  "title": "Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs",
  "authors": [
    "Wang, Dingmin  and\nZhao, Jinman  and\nPei, Hengzhi  and\nTan, Samson  and\nZha, Sheng"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Handling drafty partial code remains a notable challenge in real-time code suggestion applications. Previous work has demonstrated shortcomings of large language models of code (CodeLLMs) in completing partial code with potential bugs. In this study, we view partial code as implementation hints and fine-tune CodeLLMs to jointly rewrite and complete partial code into functional full programs. We explore two strategies: one-pass generation and multi-pass iterative refinement. We construct new training and testing datasets using semantic-altering code transformations and iterative self-generations.We conduct comprehensive experiments over three representative open-sourced CodeLLMs â€“ InCoder, CodeGen, and StarCoder.Results show that CodeLLMs fine-tuned using our approach achieve superior pass rates compared to the previous baselines across existing and newly-created benchmarks, effectively handle both potentially buggy and clean code, and largely preserve the integrity of the original partial implementations. We further present findings on the properties of the potential bugs we tested and on the design choices of our methods.",
  "keywords": [
    "fine-tuning language models",
    "code",
    "semantic",
    "we",
    "training",
    "iterative self-generations",
    "self",
    "properties",
    "two strategies",
    "strategies",
    "code codellms",
    "generations",
    "fine",
    "the properties",
    "work"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.938/",
  "provenance": {
    "collected_at": "2025-06-05 11:01:23",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}