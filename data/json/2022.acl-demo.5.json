{
  "id": "2022.acl-demo.5",
  "title": "A}nn{IE}: An Annotation Platform for Constructing Complete Open Information Extraction Benchmark",
  "authors": [
    "Friedrich, Niklas  and\nGashteovski, Kiril  and\nYu, Mingying  and\nKotnis, Bhushan  and\nLawrence, Carolin  and\nNiepert, Mathias  and\nGlava{\\v{s}}, Goran"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
  "abstract": "Open Information Extraction (OIE) is the task of extracting facts from sentences in the form of relations and their corresponding arguments in schema-free manner. Intrinsic performance of OIE systems is difficult to measure due to the incompleteness of existing OIE benchmarks: ground truth extractions do not group all acceptable surface realizations of the same fact that can be extracted from a sentence. To measure performance of OIE systems more realistically, it is necessary to manually annotate complete facts (i.e., clusters of all acceptable surface realizations of the same fact) from input sentences. We propose AnnIE: an interactive annotation platform that facilitates such challenging annotation tasks and supports creation of complete fact-oriented OIE evaluation benchmarks. AnnIE is modular and flexible in order to support different use case scenarios (i.e., benchmarks covering different types of facts) and different languages. We use AnnIE to build two complete OIE benchmarks: one with verb-mediated facts and another with facts encompassing named entities. We evaluate several OIE systems on our complete benchmarks created with AnnIE. We publicly release AnnIE (and all gold datasets generated with it) under non-restrictive license.",
  "keywords": [
    "extraction",
    "form",
    "we",
    "it",
    "information",
    "schema-free manner intrinsic performance",
    "manner",
    "oie",
    "oie systems",
    "i",
    "annie",
    "two complete oie benchmarks",
    "named entities",
    "entities",
    "several oie systems"
  ],
  "url": "https://aclanthology.org/2022.acl-demo.5/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:22",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}