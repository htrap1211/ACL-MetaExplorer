{
  "id": "2023.semeval-1.64",
  "title": "LT} at {S}em{E}val-2023 Task 1: Effective Zero-Shot Visual Word Sense Disambiguation Approaches using External Knowledge Sources",
  "authors": [
    "Schneider, Florian  and\nBiemann, Chris"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "The objective of the SemEval-2023 Task 1: Visual Word Sense Disambiguation (VWSD) is to identify the image illustrating the indented meaning of a target word and some minimal additional context. The omnipresence of textual and visual data in the task strongly suggests the utilization of the recent advances in multi-modal machine learning, i.e., pretrained visiolinguistic models (VLMs). Often referred to as foundation models due to their strong performance on many vision-language downstream tasks, these models further demonstrate powerful zero-shot capabilities. In this work, we utilize various pertained VLMs in a zero-shot fashion for multiple approaches using external knowledge sources to enrich the contextual information. Further, we evaluate our methods on the final test data and extensively analyze the suitability of different knowledge sources, the influence of training data, model sizes, multi-linguality, and different textual prompting strategies. Although we are not among the best-performing systems (rank 20 of 56), our experiments described in this work prove competitive results. Moreover, we aim to contribute meaningful insights and propel multi-modal machine learning tasks like VWSD.",
  "keywords": [
    "we",
    "shot",
    "training",
    "powerful zero-shot capabilities",
    "the objective",
    "information",
    "e",
    "word",
    "visual",
    "i",
    "objective",
    "strategies",
    "-",
    "work",
    "knowledge"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.64/",
  "provenance": {
    "collected_at": "2025-06-05 10:27:30",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}