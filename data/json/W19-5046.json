{
  "id": "W19-5046",
  "title": "DUT}-{NLP} at {MEDIQA} 2019: An Adversarial Multi-Task Network to Jointly Model Recognizing Question Entailment and Question Answering",
  "authors": [
    "Zhou, Huiwei  and\nLi, Xuefei  and\nYao, Weihong  and\nLang, Chengkun  and\nNing, Shixian"
  ],
  "year": "2019",
  "venue": "Proceedings of the 18th BioNLP Workshop and Shared Task",
  "abstract": "In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks. AMTN utilizes a pre-trained BioBERT model and an Interactive Transformer to learn the shared semantic representations across different task through parameter sharing mechanism. Meanwhile, an adversarial training strategy is introduced to separate the private features of each task from the shared representations. Experiments on BioNLP 2019 RQE and QA Shared Task datasets show that our model benefits from the shared representations of both tasks provided by multi-task learning and adversarial training, and obtains significant improvements upon the single-task models.",
  "keywords": [
    "transformer",
    "a pre-trained biobert model",
    "nlp",
    "bionlp 2019 rqe",
    "an interactive transformer",
    "model",
    "the shared semantic representations",
    "qa tasks",
    "mediqa",
    "bionlp",
    "question",
    "semantic",
    "network",
    "we",
    "biobert"
  ],
  "url": "https://aclanthology.org/W19-5046/",
  "provenance": {
    "collected_at": "2025-06-05 00:56:56",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}