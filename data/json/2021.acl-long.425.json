{
  "id": "2021.acl-long.425",
  "title": "Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims",
  "authors": [
    "Sheng, Qiang  and\nCao, Juan  and\nZhang, Xueyao  and\nLi, Xirong  and\nZhong, Lei"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "False claims that have been previously fact-checked can still spread on social media. To mitigate their continual spread, detecting previously fact-checked claims is indispensable. Given a claim, existing works focus on providing evidence for detection by reranking candidate fact-checking articles (FC-articles) retrieved by BM25. However, these performances may be limited because they ignore the following characteristics of FC-articles: (1) claims are often quoted to describe the checked events, providing lexical information besides semantics; (2) sentence templates to introduce or debunk claims are common across articles, providing pattern information. Models that ignore the two aspects only leverage semantic relevance and may be misled by sentences that describe similar but irrelevant events. In this paper, we propose a novel reranker, MTM (Memory-enhanced Transformers for Matching) to rank FC-articles using key sentences selected with event (lexical and semantic) and pattern information. For event information, we propose a ROUGE-guided Transformer which is finetuned with regression of ROUGE. For pattern information, we generate pattern vectors for matching with sentences. By fusing event and pattern information, we select key sentences to represent an article and then predict if the article fact-checks the given claim using the claim, key sentences, and patterns. Experiments on two real-world datasets show that MTM outperforms existing methods. Human evaluation proves that MTM can capture key sentences for explanations.",
  "keywords": [
    "transformers",
    "semantic",
    "we",
    "a rouge-guided transformer",
    "human evaluation",
    "semantics",
    "information",
    "pattern vectors",
    "-",
    "rouge",
    "semantic relevance",
    "transformer",
    "semantics 2 sentence templates",
    "human",
    "vectors"
  ],
  "url": "https://aclanthology.org/2021.acl-long.425/",
  "provenance": {
    "collected_at": "2025-06-05 08:05:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}