{
  "id": "W19-3713",
  "title": "Multilingual Named Entity Recognition Using Pretrained Embeddings, Attention Mechanism and {NCRF",
  "authors": [
    "Emelyanov, Anton  and\nArtemova, Ekaterina"
  ],
  "year": "2019",
  "venue": "Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing",
  "abstract": "In this paper we tackle multilingual named entity recognition task. We use the BERT Language Model as embeddings with bidirectional recurrent network, attention, and NCRF on the top. We apply multilingual BERT only as embedder without any fine-tuning. We test out model on the dataset of the BSNLP shared task, which consists of texts in Bulgarian, Czech, Polish and Russian languages.",
  "keywords": [
    "embeddings",
    "pretrained embeddings attention mechanism",
    "bidirectional recurrent network attention",
    "tuning",
    "language",
    "bsnlp",
    "bert",
    "model",
    "any fine-tuning",
    "the bsnlp",
    "attention",
    "network",
    "we",
    "recurrent",
    "entity"
  ],
  "url": "https://aclanthology.org/W19-3713/",
  "provenance": {
    "collected_at": "2025-06-05 00:58:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}