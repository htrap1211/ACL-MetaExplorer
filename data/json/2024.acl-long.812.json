{
  "id": "2024.acl-long.812",
  "title": "P}sy{S}afe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",
  "authors": [
    "Zhang, Zaibin  and\nZhang, Yongting  and\nLi, Lijun  and\nGao, Hongzhi  and\nWang, Lijun  and\nLu, Huchuan  and\nZhao, Feng  and\nQiao, Yu  and\nShao, Jing"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. In this paper, we explore these concerns through the innovative lens of agent psychology, revealing that the dark psychological states of agents constitute a significant threat to safety.To tackle these concerns, we propose a comprehensive framework (PsySafe) grounded in agent psychology, focusing on three key areas: firstly, identifying how dark personality traits in agents can lead to risky behaviors; secondly, evaluating the safety of multi-agent systems from the psychological and behavioral perspectives, and thirdly, devising effective strategies to mitigate these risks.Our experiments reveal several intriguing phenomena, such as the collective dangerous behaviors among agents, agents’ self-reflection when engaging in dangerous behavior, and the correlation between agents’ psychological assessments and dangerous behaviors. We anticipate that our framework and observations will provide valuable insights for further research into the safety of multi-agent systems. We make our data and code publicly accessible at https://github.com/AI4Good24/PsySafe.",
  "keywords": [
    "code",
    "we",
    "profound capabilities",
    "self",
    "strategies",
    "effective strategies",
    "language",
    "large language models",
    "capabilities",
    "evaluation",
    "states",
    "malicious purposes",
    "multi",
    "the safety issues",
    "dangerous behavior"
  ],
  "url": "https://aclanthology.org/2024.acl-long.812/",
  "provenance": {
    "collected_at": "2025-06-05 10:45:29",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}