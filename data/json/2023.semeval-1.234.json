{
  "id": "2023.semeval-1.234",
  "title": "TH}i{FLY} Research at {S}em{E}val-2023 Task 7: A Multi-granularity System for {CTR}-based Textual Entailment and Evidence Retrieval",
  "authors": [
    "Zhou, Yuxuan  and\nJin, Ziyu  and\nLi, Meiwei  and\nLi, Miao  and\nLiu, Xien  and\nYou, Xinxin  and\nWu, Ji"
  ],
  "year": "2023",
  "venue": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
  "abstract": "The NLI4CT task aims to entail hypotheses based on Clinical Trial Reports (CTRs) and retrieve the corresponding evidence supporting the justification. This task poses a significant challenge, as verifying hypotheses in the NLI4CT task requires the integration of multiple pieces of evidence from one or two CTR(s) and the application of diverse levels of reasoning, including textual and numerical. To address these problems, we present a multi-granularity system for CTR-based textual entailment and evidence retrieval in this paper. Specifically, we construct a Multi-granularity Inference Network (MGNet) that exploits sentence-level and token-level encoding to handle both textual entailment and evidence retrieval tasks. Moreover, we enhance the numerical inference capability of the system by leveraging a T5-based model, SciFive, which is pre-trained on the medical corpus. Model ensembling and a joint inference method are further utilized in the system to increase the stability and consistency of inference. The system achieves f1-scores of 0.856 and 0.853 on textual entailment and evidence retrieval tasks, resulting in the best performance on both subtasks. The experimental results corroborate the effectiveness of our proposed method.",
  "keywords": [
    "multiple pieces",
    "we",
    "token",
    "retrieval",
    "pieces",
    "i",
    "evidence retrieval tasks",
    "evidence retrieval",
    "model",
    "network",
    "f1-scores",
    "multi",
    "effectiveness",
    "ctr -based textual entailment",
    "corpus"
  ],
  "url": "https://aclanthology.org/2023.semeval-1.234/",
  "provenance": {
    "collected_at": "2025-06-05 10:29:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}