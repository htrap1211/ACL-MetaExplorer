{
  "id": "2020.iwslt-1.17",
  "title": "U}niversity of {T}sukuba{'}s Machine Translation System for {IWSLT}20 Open Domain Translation Task",
  "authors": [
    "Cui, Hongyi  and\nWei, Yizhen  and\nIida, Shohei  and\nUtsuro, Takehito  and\nNagata, Masaaki"
  ],
  "year": "2020",
  "venue": "Proceedings of the 17th International Conference on Spoken Language Translation",
  "abstract": "In this paper, we introduce University of Tsukuba’s submission to the IWSLT20 Open Domain Translation Task. We participate in both Chinese→Japanese and Japanese→Chinese directions. For both directions, our machine translation systems are based on the Transformer architecture. Several techniques are integrated in order to boost the performance of our models: data filtering, large-scale noised training, model ensemble, reranking and postprocessing. Consequently, our efforts achieve 33.0 BLEU scores for Chinese→Japanese translation and 32.3 BLEU scores for Japanese→Chinese translation.",
  "keywords": [
    "ensemble",
    "transformer",
    "our machine translation systems",
    "japanese chinese translation",
    "32 3 bleu scores",
    "machine",
    "model",
    "chinese japanese translation",
    "33 0 bleu scores",
    "bleu",
    "we",
    "the transformer architecture",
    "training",
    "translation",
    "sukuba"
  ],
  "url": "https://aclanthology.org/2020.iwslt-1.17/",
  "provenance": {
    "collected_at": "2025-06-05 07:56:40",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}