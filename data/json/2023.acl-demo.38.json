{
  "id": "2023.acl-demo.38",
  "title": "ESP}net-{ST}-v2: Multipurpose Spoken Language Translation Toolkit",
  "authors": [
    "Yan, Brian  and\nShi, Jiatong  and\nTang, Yun  and\nInaguma, Hirofumi  and\nPeng, Yifan  and\nDalmia, Siddharth  and\nPol{\\'a}k, Peter  and\nFernandes, Patrick  and\nBerrebbi, Dan  and\nHayashi, Tomoki  and\nZhang, Xiaohui  and\nNi, Zhaoheng  and\nHira, Moto  and\nMaiti, Soumi  and\nPino, Juan  and\nWatanabe, Shinji"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
  "abstract": "ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) â€“ each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available athttps://github.com/espnet/espnet.",
  "keywords": [
    "variety",
    "language translation toolkits",
    "language",
    "text",
    "-",
    "decoders",
    "we",
    "attention",
    "ctc attention",
    "time",
    "a wide variety",
    "translation",
    "speech",
    "a revamp",
    "-v2"
  ],
  "url": "https://aclanthology.org/2023.acl-demo.38/",
  "provenance": {
    "collected_at": "2025-06-05 09:51:08",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}