{
  "id": "2024.iwslt-1.27",
  "title": "The {KIT} Speech Translation Systems for {IWSLT} 2024 Dialectal and Low-resource Track",
  "authors": [
    "Li, Zhaolin  and\nYavuz Ugan, Enes  and\nLiu, Danni  and\nMullov, Carlos  and\nAnh Dinh, Tu  and\nKoneru, Sai  and\nWaibel, Alexander  and\nNiehues, Jan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
  "abstract": "This paper presents KITâ€™s submissions to the IWSLT 2024 dialectal and low-resource track. In this work, we build systems for translating into English from speech in Maltese, Bemba, and two Arabic dialects Tunisian and North Levantine. Under the unconstrained condition, we leverage the pre-trained multilingual models by fine-tuning them for the target language pairs to address data scarcity problems in this track. We build cascaded and end-to-end speech translation systems for different language pairs and show the cascaded system brings slightly better overall performance. Besides, we find utilizing additional data resources boosts speech recognition performance but slightly harms machine translation performance in cascaded systems. Lastly, we show that Minimum Bayes Risk is effective in improving speech translation performance by combining the cascaded and end-to-end systems, bringing a consistent improvement of around 1 BLUE point.",
  "keywords": [
    "work",
    "end",
    "language",
    "machine",
    "machine translation performance",
    "speech translation performance",
    "fine",
    "we",
    "pre",
    "translation",
    "speech",
    "recognition",
    "dialectal",
    "bayes",
    "this work"
  ],
  "url": "https://aclanthology.org/2024.iwslt-1.27/",
  "provenance": {
    "collected_at": "2025-06-05 11:06:52",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}