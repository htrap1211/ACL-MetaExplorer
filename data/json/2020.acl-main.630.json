{
  "id": "2020.acl-main.630",
  "title": "t{BERT}: Topic Models and {BERT} Joining Forces for Semantic Similarity Detection",
  "authors": [
    "Peinelt, Nicole  and\nNguyen, Dong  and\nLiakata, Maria"
  ],
  "year": "2020",
  "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
  "abstract": "Semantic similarity detection is a fundamental task in natural language understanding. Adding topic information has been useful for previous feature-engineered semantic similarity models as well as neural models for other tasks. There is currently no standard way of combining topics with pretrained contextual representations such as BERT. We propose a novel topic-informed BERT-based architecture for pairwise semantic similarity detection and show that our model improves performance over strong neural baselines across a variety of English language datasets. We find that the addition of topics to BERT helps particularly with resolving domain-specific cases.",
  "keywords": [
    "variety",
    "language",
    "neural",
    "natural",
    "bert",
    "model",
    "topic",
    "t bert topic models",
    "information",
    "pairwise semantic similarity detection",
    "semantic",
    "we",
    "a variety",
    "a fundamental task",
    "the addition"
  ],
  "url": "https://aclanthology.org/2020.acl-main.630/",
  "provenance": {
    "collected_at": "2025-06-05 07:50:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}