{
  "id": "2024.acl-short.67",
  "title": "Self-Augmented In-Context Learning for Unsupervised Word Translation",
  "authors": [
    "Li, Yaoyiran  and\nKorhonen, Anna  and\nVuli{\\'c}, Ivan"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  "abstract": "Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of ‘traditional’ mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages. To address this challenge with LLMs, we propose self-augmented in-context learning (SAIL) for unsupervised BLI: starting from a zero-shot prompt, SAIL iteratively induces a set of high-confidence word translation pairs for in-context learning (ICL) from an LLM, which it then reapplies to the same LLM in the ICL fashion. Our method shows substantial gains over zero-shot prompting of LLMs on two established BLI benchmarks spanning a wide range of language pairs, also outperforming mapping-based baselines across the board. In addition to achieving state-of-the-art unsupervised BLI performance, we also conduct comprehensive analyses on SAIL and discuss its limitations.",
  "keywords": [
    "few-shot setups",
    "an llm",
    "the same llm",
    "zero-shot prompting",
    "we",
    "no seed translation pairs",
    "llm",
    "shot",
    "translation",
    "unsupervised word translation",
    "it",
    "self",
    "word",
    "learning",
    "llms"
  ],
  "url": "https://aclanthology.org/2024.acl-short.67/",
  "provenance": {
    "collected_at": "2025-06-05 10:47:07",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}