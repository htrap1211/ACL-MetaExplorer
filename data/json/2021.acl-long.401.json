{
  "id": "2021.acl-long.401",
  "title": "Data Augmentation with Adversarial Training for Cross-Lingual {NLI",
  "authors": [
    "Dong, Xin  and\nZhu, Yaxin  and\nFu, Zuohui  and\nXu, Dongkuan  and\nde Melo, Gerard"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Due to recent pretrained multilingual representation models, it has become feasible to exploit labeled data from one language to train a cross-lingual model that can then be applied to multiple new languages. In practice, however, we still face the problem of scarce labeled data, leading to subpar results. In this paper, we propose a novel data augmentation strategy for better cross-lingual natural language inference by enriching the data to reflect more diversity in a semantically faithful way. To this end, we propose two methods of training a generative model to induce synthesized examples, and then leverage the resulting data using an adversarial training regimen for more robustness. In a series of detailed experiments, we show that this fruitful combination leads to substantial gains in cross-lingual inference.",
  "keywords": [
    "cross",
    "generative",
    "a generative model",
    "a series",
    "end",
    "language",
    "natural",
    "model",
    "it",
    "series",
    "we",
    "a semantically faithful way",
    "training",
    "that",
    "cross-lingual inference"
  ],
  "url": "https://aclanthology.org/2021.acl-long.401/",
  "provenance": {
    "collected_at": "2025-06-05 08:04:48",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}