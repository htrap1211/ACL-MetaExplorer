{
  "id": "2021.acl-short.109",
  "title": "Embracing Ambiguity: {S}hifting the Training Target of {NLI} Models",
  "authors": [
    "Meissner, Johannes Mario  and\nThumwanit, Napat  and\nSugawara, Saku  and\nAizawa, Akiko"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
  "abstract": "Natural Language Inference (NLI) datasets contain examples with highly ambiguous labels. While many research works do not pay much attention to this fact, several recent efforts have been made to acknowledge and embrace the existence of ambiguity, such as UNLI and ChaosNLI. In this paper, we explore the option of training directly on the estimated label distribution of the annotators in the NLI task, using a learning loss based on this ambiguity distribution instead of the gold-labels. We prepare AmbiNLI, a trial dataset obtained from readily available sources, and show it is possible to reduce ChaosNLI divergence scores when finetuning on this data, a promising first step towards learning how to capture linguistic ambiguity. Additionally, we show that training on the same amount of data but targeting the ambiguity distribution instead of gold-labels can result in models that achieve higher performance and learn better representations for downstream tasks.",
  "keywords": [
    "much attention",
    "language",
    "natural",
    "it",
    "loss",
    "attention",
    "we",
    "training",
    "that",
    "promising",
    "trial",
    "a promising first step",
    "the same amount",
    "task",
    "annotators"
  ],
  "url": "https://aclanthology.org/2021.acl-short.109/",
  "provenance": {
    "collected_at": "2025-06-05 08:08:34",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}