{
  "id": "2024.findings-acl.956",
  "title": "Can {LLM}s Speak For Diverse People? Tuning {LLM}s via Debate to Generate Controllable Controversial Statements",
  "authors": [
    "Li, Ming  and\nChen, Jiuhai  and\nChen, Lichang  and\nZhou, Tianyi"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Making LLMs speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. However, existing LLMs lack sufficient controllability to the stance of their generated content, which often contains inconsistent, neutral, or biased statements. In this paper, we improve the controllability of LLMs in generating statements supporting an argument the user defined in the prompt. We find that multi-round debates between two LLMs with opposite stances generate higher-quality and more salient statements for each, which are important training data to improve the controllability of LLMs. Motivated by this, we develop a novel debate & tuning (“DEBATUNE”) pipeline finetuning LLMs to generate the statements obtained via debate. To examine DEBATUNE, we curate the largest dataset of debate topics so far, which covers 710 controversial topics and corresponding arguments for each topic. Evaluations by the GPT-4 judge with a novel controversy controllability metric show that LLMs’ capability of generating diverse perspectives is significantly improved by DEBATUNE. Moreover, such controllability can be generalized to unseen topics, generating high-quality statements supporting controversial arguments.",
  "keywords": [
    "each topic evaluations",
    "we",
    "sufficient controllability",
    "llm",
    "training",
    "two llms",
    "the gpt-4 judge",
    "sufficient",
    "biased",
    "llms",
    "tuning",
    "prompt",
    "metric",
    "topic",
    "gpt-4"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.956/",
  "provenance": {
    "collected_at": "2025-06-05 11:01:38",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}