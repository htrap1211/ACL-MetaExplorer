{
  "id": "2024.acl-long.526",
  "title": "Robust Singing Voice Transcription Serves Synthesis",
  "authors": [
    "Li, Ruiqi  and\nZhang, Yu  and\nWang, Yongqi  and\nHong, Zhiqing  and\nHuang, Rongjie  and\nZhao, Zhou"
  ],
  "year": "2024",
  "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Note-level Automatic Singing Voice Transcription (AST) converts singing recordings into note sequences, facilitating the automatic annotation of singing datasets for Singing Voice Synthesis (SVS) applications. Current AST methods, however, struggle with accuracy and robustness when used for practical annotation. This paper presents ROSVOT, the first robust AST model that serves SVS, incorporating a multi-scale framework that effectively captures coarse-grained note information and ensures fine-grained frame-level segmentation, coupled with an attention-based pitch decoder for reliable pitch prediction. We also established a comprehensive annotation-and-training pipeline for SVS to test the model in real-world settings. Experimental findings reveal that the proposed model achieves state-of-the-art transcription accuracy with either clean or noisy inputs. Moreover, when trained on enlarged, automatically annotated datasets, the SVS model outperforms its baseline, affirming the capability for practical application. Audio samples are available at https://rosvot.github.io. Codes can be found at https://github.com/RickyL-2000/ROSVOT.",
  "keywords": [
    "ast",
    "we",
    "current",
    "training",
    "decoder",
    "information",
    "an attention-based pitch decoder",
    "accuracy",
    "model",
    "attention",
    "multi",
    "state",
    "the automatic annotation",
    "settings",
    "framework"
  ],
  "url": "https://aclanthology.org/2024.acl-long.526/",
  "provenance": {
    "collected_at": "2025-06-05 10:41:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}