{
  "id": "2021.acl-long.517",
  "title": "On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study",
  "authors": [
    "Kaushik, Divyansh  and\nKiela, Douwe  and\nLipton, Zachary C.  and\nYih, Wen-tau"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "In adversarial data collection (ADC), a human workforce interacts with a model in real time, attempting to produce examples that elicit incorrect predictions. Researchers hope that models trained on these more challenging datasets will rely less on superficial patterns, and thus be less brittle. However, despite ADCâ€™s intuitive appeal, it remains unclear when training on adversarial datasets produces more robust models. In this paper, we conduct a large-scale controlled study focused on question answering, assigning workers at random to compose questions either (i) adversarially (with a model in the loop); or (ii) in the standard fashion (without a model). Across a variety of models and datasets, we find that models trained on adversarial data usually perform better on other adversarial datasets but worse on a diverse collection of out-of-domain evaluation sets. Finally, we provide a qualitative analysis of adversarial (vs standard) data, identifying key differences and offering guidance for future research.",
  "keywords": [
    "variety",
    "question",
    "we",
    "training",
    "it",
    "a variety",
    "analysis",
    "s",
    "random",
    "model",
    "human",
    "evaluation",
    "time",
    "future research",
    "a large-scale controlled study"
  ],
  "url": "https://aclanthology.org/2021.acl-long.517/",
  "provenance": {
    "collected_at": "2025-06-05 08:06:21",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}