{
  "id": "2024.privatenlp-1.18",
  "title": "A Privacy-preserving Approach to Ingest Knowledge from Proprietary Web-based to Locally Run Models for Medical Progress Note Generation",
  "authors": [
    "Soni, Sarvesh  and\nDemner-Fushman, Dina"
  ],
  "year": "2024",
  "venue": "Proceedings of the Fifth Workshop on Privacy in Natural Language Processing",
  "abstract": "Clinical documentation is correlated with increasing clinician burden, leading to the rise of automated methods to generate medical notes. Due to the sensitive nature of patient electronic health records (EHRs), locally run models are preferred for a variety of reasons including privacy, bias, and cost. However, most open-source locally run models (including medical-specific) are much smaller with limited input context size compared to the more powerful closed-source large language models (LLMs) generally available through web APIs (Application Programming Interfaces). In this paper, we propose a framework to harness superior reasoning capabilities and medical knowledge from closed-source online LLMs in a privacy-preserving manner and seamlessly incorporate it into locally run models. Specifically, we leverage a web-based model to distill the vast patient information available in EHRs into a clinically relevant subset without sending sensitive patient health information online and use this distilled knowledge to generate progress notes by a locally run model. Our ablation results indicate that the proposed framework improves the performance of the Mixtral model on progress note generation by 4.6 points on ROUGE (a text-matching based metric) and 7.56 points on MEDCON F1 (a metric that measures the clinical concepts overlap).",
  "keywords": [
    "variety",
    "bias",
    "privacy bias",
    "proprietary web",
    "progress note generation",
    "we",
    "it",
    "information",
    "a variety",
    "sensitive patient health information",
    "manner",
    "llms",
    "metric",
    "text",
    "medcon f1"
  ],
  "url": "https://aclanthology.org/2024.privatenlp-1.18/",
  "provenance": {
    "collected_at": "2025-06-05 11:09:14",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}