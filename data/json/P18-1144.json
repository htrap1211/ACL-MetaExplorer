{
  "id": "P18-1144",
  "title": "C}hinese {NER} Using Lattice {LSTM",
  "authors": [
    "Zhang, Yue  and\nYang, Jie"
  ],
  "year": "2018",
  "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "We investigate a lattice-structured LSTM model for Chinese NER, which encodes a sequence of input characters as well as all potential words that match a lexicon. Compared with character-based methods, our model explicitly leverages word and word sequence information. Compared with word-based methods, lattice LSTM does not suffer from segmentation errors. Gated recurrent cells allow our model to choose the most relevant characters and words from a sentence for better NER results. Experiments on various datasets show that lattice LSTM outperforms both word-based and character-based LSTM baselines, achieving the best results.",
  "keywords": [
    "ner",
    "model",
    "chinese ner",
    "a lattice-structured lstm model",
    "information",
    "word",
    "we",
    "sequence",
    "lstm",
    "better ner results experiments",
    "recurrent",
    "lattice lstm",
    "word-based methods lattice lstm",
    "that",
    "hinese"
  ],
  "url": "https://aclanthology.org/P18-1144/",
  "provenance": {
    "collected_at": "2025-06-05 00:12:55",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}