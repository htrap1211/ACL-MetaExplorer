{
  "id": "2022.ecnlp-1.27",
  "title": "Can Pretrained Language Models Generate Persuasive, Faithful, and Informative Ad Text for Product Descriptions?",
  "authors": [
    "Koto, Fajri  and\nLau, Jey Han  and\nBaldwin, Timothy"
  ],
  "year": "2022",
  "venue": "Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5)",
  "abstract": "For any e-commerce service, persuasive, faithful, and informative product descriptions can attract shoppers and improve sales. While not all sellers are capable of providing such interesting descriptions, a language generation system can be a source of such descriptions at scale, and potentially assist sellers to improve their product descriptions. Most previous work has addressed this task based on statistical approaches (Wang et al., 2017), limited attributes such as titles (Chen et al., 2019; Chan et al., 2020), and focused on only one product type (Wang et al., 2017; Munigala et al., 2018; Hong et al., 2021). In this paper, we jointly train image features and 10 text attributes across 23 diverse product types, with two different target text types with different writing styles: bullet points and paragraph descriptions. Our findings suggest that multimodal training with modern pretrained language models can generate fluent and persuasive advertisements, but are less faithful and informative, especially out of domain.",
  "keywords": [
    "work",
    "language",
    "generation",
    "text",
    "a language generation system",
    "language models",
    "we",
    "modern pretrained language models",
    "et al",
    "training",
    "fluent",
    "most previous work",
    "styles",
    "paragraph descriptions",
    "task"
  ],
  "url": "https://aclanthology.org/2022.ecnlp-1.27/",
  "provenance": {
    "collected_at": "2025-06-05 08:42:27",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}