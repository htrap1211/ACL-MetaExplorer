{
  "id": "2021.acl-long.217",
  "title": "T}ext2{E}vent: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction",
  "authors": [
    "Lu, Yaojie  and\nLin, Hongyu  and\nXu, Jin  and\nHan, Xianpei  and\nTang, Jialong  and\nLi, Annan  and\nSun, Le  and\nLiao, Meng  and\nChen, Shaoyi"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
  "abstract": "Event extraction is challenging due to the complex structure of event records and the semantic gap between text and event. Traditional methods usually extract event records by decomposing the complex structure prediction task into multiple subtasks. In this paper, we propose Text2Event, a sequence-to-structure generation paradigm that can directly extract events from the text in an end-to-end manner. Specifically, we design a sequence-to-structure network for unified event extraction, a constrained decoding algorithm for event knowledge injection during inference, and a curriculum learning algorithm for efficient model learning. Experimental results show that, by uniformly modeling all tasks in a single model and universally predicting different labels, our method can achieve competitive performance using only record-level annotations in both supervised learning and transfer learning settings.",
  "keywords": [
    "knowledge",
    "end",
    "generation",
    "extraction",
    "model",
    "text",
    "efficient",
    "modeling",
    "unified",
    "the semantic gap",
    "efficient model",
    "semantic",
    "we",
    "sequence",
    "network"
  ],
  "url": "https://aclanthology.org/2021.acl-long.217/",
  "provenance": {
    "collected_at": "2025-06-05 08:02:19",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}