{
  "id": "2022.acl-tutorials.3",
  "title": "Knowledge-Augmented Methods for Natural Language Processing",
  "authors": [
    "Zhu, Chenguang  and\nXu, Yichong  and\nRen, Xiang  and\nLin, Bill Yuchen  and\nJiang, Meng  and\nYu, Wenhao"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts",
  "abstract": "Knowledge in natural language processing (NLP) has been a rising trend especially after the advent of large scale pre-trained models. NLP models with attention to knowledge can i) access unlimited amount of external information; ii) delegate the task of storing knowledge from its parameter space to knowledge sources; iii) obtain up-to-date information; iv) make prediction results more explainable via selected knowledge. In this tutorial, we will introduce the key steps in integrating knowledge into NLP, including knowledge grounding from text, knowledge representation and fusing. In addition, we will introduce recent state-of-the-art applications in fusing knowledge into language understanding, language generation and commonsense reasoning.",
  "keywords": [
    "knowledge",
    "processing",
    "i",
    "language",
    "language generation",
    "generation",
    "natural language processing knowledge",
    "nlp",
    "natural",
    "text",
    "information",
    "attention",
    "we",
    "pre",
    "parameter"
  ],
  "url": "https://aclanthology.org/2022.acl-tutorials.3/",
  "provenance": {
    "collected_at": "2025-06-05 08:34:44",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}