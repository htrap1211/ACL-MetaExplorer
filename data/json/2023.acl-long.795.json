{
  "id": "2023.acl-long.795",
  "title": "I}ndic{MT} Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for {I}ndian Languages",
  "authors": [
    "Sai B, Ananya  and\nDixit, Tanay  and\nNagarajan, Vignesh  and\nKunchukuttan, Anoop  and\nKumar, Pratyush  and\nKhapra, Mitesh M.  and\nDabre, Raj"
  ],
  "year": "2023",
  "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "The rapid growth of machine translation (MT) systems necessitates meta-evaluations of evaluation metrics to enable selection of those that best reflect MT quality. Unfortunately, most meta-evaluation studies focus on European languages, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from them, and to date, there are no such systematic studies focused solely on English to Indian language MT. This paper fills this gap through a Multidimensional Quality Metric (MQM) dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems. We evaluate 16 metrics and show that, pre-trained metrics like COMET have the highest correlations with annotator scores as opposed to n-gram metrics like BLEU. We further leverage our MQM annotations to develop an Indic-COMET metric and show that it outperforms COMET counterparts in both human scores correlations and robustness scores in Indian languages. Additionally, we show that the Indic-COMET can outperform COMET on some unseen Indian languages. We hope that our dataset and analysis will facilitate further research in Indic MT evaluation.",
  "keywords": [
    "bleu",
    "meta-evaluations",
    "machine translation",
    "we",
    "16 metrics",
    "translation",
    "it",
    "meta-evaluate machine translation metrics",
    "n-gram metrics",
    "analysis",
    "i",
    "metric",
    "metrics",
    "evaluation metrics",
    "eval"
  ],
  "url": "https://aclanthology.org/2023.acl-long.795/",
  "provenance": {
    "collected_at": "2025-06-05 09:46:28",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}