{
  "id": "2020.challengehml-1.8",
  "title": "AI} {S}ensing for Robotics using Deep Learning based Visual and Language Modeling",
  "authors": [
    "Singh, Yuvaram  and\nJV, Kameshwar Rao"
  ],
  "year": "2020",
  "venue": "Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)",
  "abstract": "An artificial intelligence(AI) system should be capable of processing the sensory inputs to extract both task-specific and general information about its environment. However, most of the existing algorithms extract only task specific information. In this work, an innovative approach to address the problem of processing visual sensory data is presented by utilizing convolutional neural network (CNN). It recognizes and represents the physical and semantic nature of the surrounding in both human readable and machine processable format. This work utilizes the image captioning model to capture the semantics of the input image and a modular design to generate a probability distribution for semantic topics. It gives any autonomous system the ability to process visual information in a human-like way and generates more insights which are hardly possible with a conventional algorithm. Here a model and data collection method are proposed.",
  "keywords": [
    "deep",
    "the semantics",
    "semantic",
    "convolutional",
    "neural",
    "cnn",
    "semantics",
    "it",
    "semantic topics",
    "information",
    "format",
    "learning",
    "visual",
    "convolutional neural network cnn",
    "work"
  ],
  "url": "https://aclanthology.org/2020.challengehml-1.8/",
  "provenance": {
    "collected_at": "2025-06-05 07:55:11",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}