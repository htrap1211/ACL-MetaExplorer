{
  "id": "2021.acl-demo.34",
  "title": "E}xplaina{B}oard: An Explainable Leaderboard for {NLP",
  "authors": [
    "Liu, Pengfei  and\nFu, Jinlan  and\nXiao, Yang  and\nYuan, Weizhe  and\nChang, Shuaichen  and\nDai, Junqi  and\nLiu, Yixin  and\nYe, Zihuiwen  and\nNeubig, Graham"
  ],
  "year": "2021",
  "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations",
  "abstract": "With the rapid development of NLP research, leaderboards have emerged as one tool to track the performance of various systems on various NLP tasks. They are effective in this goal to some extent, but generally present a rather simplistic one-dimensional view of the submitted systems, communicated only through holistic accuracy numbers. In this paper, we present a new conceptualization and implementation of NLP evaluation: the ExplainaBoard, which in addition to inheriting the functionality of the standard leaderboard, also allows researchers to (i) diagnose strengths and weaknesses of a single system (e.g. what is the best-performing system bad at?) (ii) interpret relationships between multiple systems. (e.g. where does system A outperform system B? What if we combine systems A, B and C?) and (iii) examine prediction results closely (e.g. what are common errors made by multiple systems or in what contexts do particular errors occur?). So far, ExplainaBoard covers more than 400 systems, 50 datasets, 40 languages, and 12 tasks. We not only released an online platform at the website but also make our evaluation tool an API with MIT Licence at Github and PyPi that allows users to conveniently assess their models offline. We additionally release all output files from systems that we have run or collected to motivate “output-driven” research in the future.",
  "keywords": [
    "our evaluation tool",
    "we",
    "nlp research leaderboards",
    "holistic accuracy numbers",
    "i",
    "nlp evaluation",
    "dimensional",
    "accuracy",
    "nlp",
    "view",
    "various nlp tasks",
    "evaluation",
    "this goal",
    "all output files",
    "the standard leaderboard"
  ],
  "url": "https://aclanthology.org/2021.acl-demo.34/",
  "provenance": {
    "collected_at": "2025-06-05 08:09:57",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}