{
  "id": "2024.findings-acl.314",
  "title": "S}truct{E}val: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
  "authors": [
    "Cao, Boxi  and\nRen, Mengjie  and\nLin, Hongyu  and\nHan, Xianpei  and\nZhang, Feng  and\nZhan, Junfeng  and\nSun, Le"
  ],
  "year": "2024",
  "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
  "abstract": "Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggle to discern whether a model genuinely possesses the required capabilities or merely memorizes/guesses the answers to specific questions. To this end, this paper proposes a novel evaluation framework referred to as StructEval. Starting from an atomic test objective, StructEval deepens and broadens the evaluation by conducting a structured assessment across multiple cognitive levels and critical concepts, and therefore offers a comprehensive, robust and consistent evaluations for large language models. Experiments on three widely-used benchmarks demonstrate that StructEval serves as a reliable tool for resisting the risk of data contamination, and reducing the interference of potential biases, thereby providing a more reliable and consistent conclusion regarding model capabilities. Our framework also sheds light on the design of future principled and trustworthy LLM evaluation protocols.",
  "keywords": [
    "end",
    "current",
    "llm",
    "potential biases",
    "val",
    "truct",
    "the required capabilities",
    "model capabilities",
    "objective",
    "current evaluations",
    "biases",
    "language",
    "model",
    "evaluations",
    "large language models experiments"
  ],
  "url": "https://aclanthology.org/2024.findings-acl.314/",
  "provenance": {
    "collected_at": "2025-06-05 10:52:54",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}