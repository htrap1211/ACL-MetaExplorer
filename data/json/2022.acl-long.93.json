{
  "id": "2022.acl-long.93",
  "title": "F}rugal{S}core: Learning Cheaper, Lighter and Faster Evaluation Metrics for Automatic Text Generation",
  "authors": [
    "Kamal Eddine, Moussa  and\nShang, Guokan  and\nTixier, Antoine  and\nVazirgiannis, Michalis"
  ],
  "year": "2022",
  "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  "abstract": "Fast and reliable evaluation metrics are key to R&D progress. While traditional natural language generation metrics are fast, they are not very reliable. Conversely, new metrics based on large pretrained language models are much more reliable, but require significant computational resources. In this paper, we propose FrugalScore, an approach to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance. Experiments with BERTScore and MoverScore on summarization and translation show that FrugalScore is on par with the original metrics (and sometimes better), while having several orders of magnitude less parameters and running several times faster. On average over all learned metrics, tasks, and variants, FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35 times less parameters than the original metrics. We make our trained metrics publicly available, to benefit the entire NLP community and in particular researchers and practitioners with limited resources.",
  "keywords": [
    "summarization",
    "we",
    "the entire nlp community",
    "translation",
    "bertscore",
    "natural",
    "all learned metrics tasks",
    "core",
    "the original metrics",
    "our trained metrics",
    "automatic text generation",
    "metric",
    "text",
    "metrics",
    "par"
  ],
  "url": "https://aclanthology.org/2022.acl-long.93/",
  "provenance": {
    "collected_at": "2025-06-05 08:25:33",
    "source": "ACL Anthology",
    "version": "1.0"
  }
}